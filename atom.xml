<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Li Ting</title>
  
  
  <link href="https://liting1024.github.io/atom.xml" rel="self"/>
  
  <link href="https://liting1024.github.io/"/>
  <updated>2022-08-05T09:16:21.000Z</updated>
  <id>https://liting1024.github.io/</id>
  
  <author>
    <name>李挺</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>VisTransformer</title>
    <link href="https://liting1024.github.io/2022/08/05/VisTransformer/"/>
    <id>https://liting1024.github.io/2022/08/05/VisTransformer/</id>
    <published>2022-08-05T09:16:21.000Z</published>
    <updated>2022-08-05T09:16:21.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>将图片切割为N个patch。</p><p>现有的自注意力在图片中的应用，一般是直接替换CNN中的部分，或者和CNN一起用，总之Transformer在图片上还是依赖卷积的，但实际上不需要依赖。</p><p>VisTransformer在大规模数据做训练，迁移到小数据集上时，效果会很好。</p><h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>现有的Bert就是在大规模数据做训练，迁移到小数据集上微调模型。由于Transformer的高效性和可扩展性，这样的方案随着数据增多性能还没有饱和（没有过拟合）。</p><p>Transformer用于视觉的难点：将2D图片变成1D的序列，如果直接将像素拉长，对于224x224的图片，拉长后变成224x224=50176，而Bert的序列只有512。</p><ol><li>因此一般是将经过卷积或者ResNet后的特征图拉长；</li><li>也有的是将图片分为高度H和宽度W两个维度，分别做Transformer；</li><li>还有的是在一个局部窗口里拉长做自注意力。</li><li>由于没有优化，这些方案都无法用于大规模数据、模型。ViT则是划分patch，每一个patch当做一个单词</li></ol><p>CNN具有归纳偏置的特点，比如桌子和椅子大概率是在一起的，再比如先平移再卷积和先做卷积再平移（同样的输入同样的卷积核）得到的特征是一样的，这个特点可以保证CNN有一定的先验信息，在相对少的数据上就有很好的效果。Transformer没有这样的归纳偏置的特点，因此在大规模数据集上的效果会比CNN更好。</p><p>第一步将图片打成patch（对224x224x3使用16x16的patch_size会得到14x14=196个patch，每个patch是16x16x3=768），变成一个序列，由于图片不能打乱顺序，但Transformer是会两两都做self-attention，因此加入了位置信息position embedding（作者发现对位置编码用1D编码即1.2.3和2D编码即11.12.13差不多），生成一个一个token。</p><p>在开始加入特征字符cls（形状为1x768，位置为0）是一个可学习的特征，最后可以作为Transformer的输出（图像的整体特征）。</p><p>第二步经过线性投射层（实际上是768x768的全连接层），上一步的输入为196x768，乘完全连接层的768x768的矩阵，得到196x768的矩阵，加上cls得到197x768。</p><p>第三步用cls经过MLP做分类任务</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Abstract&quot;&gt;&lt;a href=&quot;#Abstract&quot; class=&quot;headerlink&quot; title=&quot;Abstract&quot;&gt;&lt;/a&gt;Abstract&lt;/h1&gt;&lt;p&gt;将图片切割为N个patch。&lt;/p&gt;
&lt;p&gt;现有的自注意力在图片中的应用，一般是直接替换CN</summary>
      
    
    
    
    <category term="机器学习" scheme="https://liting1024.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="读论文" scheme="https://liting1024.github.io/tags/%E8%AF%BB%E8%AE%BA%E6%96%87/"/>
    
  </entry>
  
  <entry>
    <title>Bert</title>
    <link href="https://liting1024.github.io/2022/07/10/Bert/"/>
    <id>https://liting1024.github.io/2022/07/10/Bert/</id>
    <published>2022-07-10T03:50:01.000Z</published>
    <updated>2022-07-10T03:50:01.000Z</updated>
    
    <content type="html"><![CDATA[<p>Deep Bidirectional 深的双向的Transformer</p><p>Deep：</p><p>Bert_BASE:Layer = 12, Hidden = 768, Head = 12, Total Parameters = 110M</p><p>Bert_LARGE:Layer = 24, Hidden = 1024, Head = 16, Total Parameters = 340M</p><p>Bert是只有编码器的Transformer，对比于Transformer: Layer = 6, Hidden = 2048, Head = 8，是个浅而宽，说明Bert这样深而窄的模型效果更好(和CV领域的总体结论基本一致)。</p><p>Bidirectional：</p><p>Bert直接引用了Transformer架构中的Encoder模块，并舍弃了Decoder模块,  这样便自动拥有了双向编码能力和强大的特征提取能力。</p><h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>设计训练深的双向的表示，使用无标号数据，联合左右上下文信息。训练好的Bert只要加一个额外输出层就可以用于其他NLP任务。相比GPT虽然使用了Transformer但只用了左边的单向信息，而ELMo是基于双向RNN的架构用于下游任务时需要调整。</p><h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>预训练赋能NLP有两类，一种是句子层面的任务，建模句子之间的关系或情绪识别，另一种是词层面的任务例如实体命名识别，需要输出词层面的的信息。</p><p>预训练一般有两种，一种是提取特征例如ELMo，另一种是将原模型少部分参数做微调例如GPT。这两种方法都是使用相同的目标函数，即单向的语言模型（给一个词预测下一个词），</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Deep Bidirectional 深的双向的Transformer&lt;/p&gt;
&lt;p&gt;Deep：&lt;/p&gt;
&lt;p&gt;Bert_BASE:Layer = 12, Hidden = 768, Head = 12, Total Parameters = 110M&lt;/p&gt;
&lt;p&gt;Ber</summary>
      
    
    
    
    <category term="机器学习" scheme="https://liting1024.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="读论文" scheme="https://liting1024.github.io/tags/%E8%AF%BB%E8%AE%BA%E6%96%87/"/>
    
  </entry>
  
  <entry>
    <title>GCN</title>
    <link href="https://liting1024.github.io/2022/07/09/GCN/"/>
    <id>https://liting1024.github.io/2022/07/09/GCN/</id>
    <published>2022-07-09T08:06:46.000Z</published>
    <updated>2022-07-09T08:06:46.000Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://distill.pub/2021/gnn-intro/" target="_blank" rel="noopener">A Gentle Introduction to Graph Neual Networks 综述</a></p><p>大部分数据类型都可以表示成图，但同样在图上做优化会很困难</p><p>行与列之间可以相互交换</p><p>顶点、边、全局三种图的属性分别做MLP</p><p>GCN用k层，每层看节点的一个邻居节点</p><p>可以加入attention，由于图中邻居节点可以随意打乱顺序，权重对于位置不敏感，而是取决于两个顶点向量之间的关系，而不是顶点的位置</p><p>在图上做卷积，相当于直接将图的邻接矩阵和另一个向量做乘法。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;a href=&quot;https://distill.pub/2021/gnn-intro/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;A Gentle Introduction to Graph Neual Networks 综述&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;</summary>
      
    
    
    
    <category term="机器学习" scheme="https://liting1024.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="读论文" scheme="https://liting1024.github.io/tags/%E8%AF%BB%E8%AE%BA%E6%96%87/"/>
    
  </entry>
  
  <entry>
    <title>ResNet</title>
    <link href="https://liting1024.github.io/2022/07/09/ResNet/"/>
    <id>https://liting1024.github.io/2022/07/09/ResNet/</id>
    <published>2022-07-09T04:07:57.000Z</published>
    <updated>2022-07-09T04:07:57.000Z</updated>
    
    
    
    
    <category term="机器学习" scheme="https://liting1024.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="读论文" scheme="https://liting1024.github.io/tags/%E8%AF%BB%E8%AE%BA%E6%96%87/"/>
    
  </entry>
  
  <entry>
    <title>研究写作的艺术</title>
    <link href="https://liting1024.github.io/2022/07/01/%E5%86%99%E4%BD%9C%E7%9A%84%E8%89%BA%E6%9C%AF/"/>
    <id>https://liting1024.github.io/2022/07/01/%E5%86%99%E4%BD%9C%E7%9A%84%E8%89%BA%E6%9C%AF/</id>
    <published>2022-07-01T12:33:35.000Z</published>
    <updated>2022-07-01T12:33:35.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="研究、研究者和读者"><a href="#研究、研究者和读者" class="headerlink" title="研究、研究者和读者"></a>研究、研究者和读者</h1><p>研究是指收集信息回答一个疑问来解决一个问题。</p><p>给自己和读者都创建一个角色给作者和读者建立联系。</p><h1 id="提出问题、解决问题"><a href="#提出问题、解决问题" class="headerlink" title="提出问题、解决问题"></a>提出问题、解决问题</h1><h1 id="提出论点"><a href="#提出论点" class="headerlink" title="提出论点"></a>提出论点</h1><h1 id="阐述论点"><a href="#阐述论点" class="headerlink" title="阐述论点"></a>阐述论点</h1>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;研究、研究者和读者&quot;&gt;&lt;a href=&quot;#研究、研究者和读者&quot; class=&quot;headerlink&quot; title=&quot;研究、研究者和读者&quot;&gt;&lt;/a&gt;研究、研究者和读者&lt;/h1&gt;&lt;p&gt;研究是指收集信息回答一个疑问来解决一个问题。&lt;/p&gt;
&lt;p&gt;给自己和读者都创建一个角</summary>
      
    
    
    
    
    <category term="读论文" scheme="https://liting1024.github.io/tags/%E8%AF%BB%E8%AE%BA%E6%96%87/"/>
    
  </entry>
  
  <entry>
    <title>nvm和node版本管理</title>
    <link href="https://liting1024.github.io/2022/06/23/nvm%E5%92%8Cnode%E7%89%88%E6%9C%AC%E7%AE%A1%E7%90%86/"/>
    <id>https://liting1024.github.io/2022/06/23/nvm%E5%92%8Cnode%E7%89%88%E6%9C%AC%E7%AE%A1%E7%90%86/</id>
    <published>2022-06-23T13:21:04.000Z</published>
    <updated>2022-06-23T13:21:04.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="nvm"><a href="#nvm" class="headerlink" title="nvm"></a>nvm</h1><p><a href="https://www.mzh.ren/使用nvm对node版本进行控制.html" target="_blank" rel="noopener">https://www.mzh.ren/使用nvm对node版本进行控制.html</a></p><p>本地和全局npm的区别<a href="https://wenku.baidu.com/view/347da36db007e87101f69e3143323968011cf4d5.html" target="_blank" rel="noopener">https://wenku.baidu.com/view/347da36db007e87101f69e3143323968011cf4d5.html</a></p><p>nrm</p><p><a href="https://www.csdn.net/tags/OtTaUgwsMDQ5OC1ibG9n.html" target="_blank" rel="noopener">https://www.csdn.net/tags/OtTaUgwsMDQ5OC1ibG9n.html</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;nvm&quot;&gt;&lt;a href=&quot;#nvm&quot; class=&quot;headerlink&quot; title=&quot;nvm&quot;&gt;&lt;/a&gt;nvm&lt;/h1&gt;&lt;p&gt;&lt;a href=&quot;https://www.mzh.ren/使用nvm对node版本进行控制.html&quot; target=&quot;_blank</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>Transformer</title>
    <link href="https://liting1024.github.io/2022/06/18/Transformer/"/>
    <id>https://liting1024.github.io/2022/06/18/Transformer/</id>
    <published>2022-06-18T07:31:04.000Z</published>
    <updated>2022-06-18T07:31:04.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>主流的序列转录模型（给一句英文生成一句中文）依赖于复杂的循环或卷积NN，使用Encoder和Decoder。性能最好的模型都会在Encoder和Decoder之间用注意力机制，本文仅使用简单的注意力机制架构，而不是循环或卷积NN。</p><p>最初用于NLP，后面用于图像等，都很有效。</p><h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>输入、输出中结构化信息较多时，使用编解码器架构会比较有效。</p><p>RNN中对第t个词计算一个$h_t$和$h_{t-1}$决定，因此时序过程难以并行（GPU上性能会比较差），且对于长序列无法存储过多$h_t$，早期的信息在后期会丢掉。</p><p>Attention这个思想已经在编解码器架构中使用。</p><p>新提出的Transformer不再使用RNN而是纯基于注意力机制。</p><h1 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h1><p>这里说了一些和Transformer结构类似或思想相关的模型。</p><p>CNN只能看到比较小的矩阵，无法看到整个序列的信息，但优点是有多输出通道，Transformer用Multi-Head Attention多头注意力机制模拟多通道。</p><p>模型结构图如下：</p><p><img src="https://cdn.jsdelivr.net/gh/liting1024/PicImage/PicgoGithub/image-20220704160110101.png" alt="image-20220704160110101"></p><h1 id="Model-Architecture"><a href="#Model-Architecture" class="headerlink" title="Model Architecture"></a>Model Architecture</h1><p>编码器的输出是z向量，其中$Z_t$是第t个词的向量表示，编码器的输出作为解码器的输入，解码器的输出为$y_m$，即一个一个的生成，在得到y1后才能得到y2，因此是一个auto-regressive自回归模型，即输入就是输出。 </p><p>把self-attention自注意力和point-wise堆叠起来重复N次。</p><ul><li><p>输入：对单词进行embedding</p></li><li><p>编码器（图中左侧）：用六个层堆叠起来的。每层里面有两个子层，第一个子层是多头注意力机制，第二个子层是MLP（图中的simple,position-wise fully connected <strong>feed-forward network</strong>），每个子层用一个残差连接，即LayerNorm(x+Sublayer(x))。每层输出维度都是512，方便进行残差连接，不同于CNN的设计。</p></li><li><p>解码器（图中右侧）：自回归，当前的输入是上一个时刻的输出。解码器同样是用六个层堆叠。每层里面三个子层，第一个是带masked的多头注意力机制，是由于注意力机制每次可以看到所有的输入，用掩码防止在预测第t时刻的输出时看不到t时刻之后的输入。</p></li><li><p>输出：标准的神经网络输出，依次通过线性层和Softmax</p></li></ul><h2 id="Attention"><a href="#Attention" class="headerlink" title="Attention"></a>Attention</h2><p>注意力函数是将一个query和一些key-value对映射成输出的函数，这里的query、key、value、output都是向量。输出是value的加权和，每个value的权重是由value对应的key和query求相似度得到的。</p><h3 id="Scaled-Dot-Product-Attention"><a href="#Scaled-Dot-Product-Attention" class="headerlink" title="Scaled Dot-Product Attention"></a>Scaled Dot-Product Attention</h3><p>缩放点积注意力机制最简单的一种Attention。</p><p>query和key的长度都是$d_k$，value长度为$d_v$。</p><ul><li>权重的计算：对query和key做内积，内积值越大相似度越高，越小则说明两个向量正交，即没有相似度。将得到的内积除以$\sqrt{d_k}$（防止数据过大或过小导致softmax的结果分散到两端，最终导致梯度较小），然后通过Softmax得到n个权重。实际运算中，Q为query的矩阵，K为key的矩阵</li></ul><p>$$<br>Attention(Q,K,V)=softmax(\frac{QK^T}{ \sqrt{d_k}})V<br>$$</p><p><img src="https://cdn.jsdelivr.net/gh/liting1024/PicImage/PicgoGithub/image-20220704173849211.png" alt="image-20220704173849211"></p><ul><li>mask：在计算第t时刻的输出时，不应该使用$K_t$以及之后的值，但在注意力机制中会计算出所有的K，所以需要将$K_t$以及之后的值换成非常大的负数（-1e10），这个负数在经过softmax的指数运算后会变成0。</li></ul><h3 id="多头注意力机制"><a href="#多头注意力机制" class="headerlink" title="多头注意力机制"></a>多头注意力机制</h3><p>先用线性层将query、key、value投影到低维度，然后做8次缩放点积注意力计算。这里多次投影、点积计算，类似于多输出通道。<br>$$<br>MultiHead(Q,K,V)=Concat(head_1,…,head_h)W^{Output}<br>$$</p><p>$$<br>head_i=Attention(QW_i^Q,KW_i^K,VW_i^V)<br>$$</p><p>TODO: 需要细读设计原因和投影</p><h3 id="网络的输入输出（三个Attention的作用）"><a href="#网络的输入输出（三个Attention的作用）" class="headerlink" title="网络的输入输出（三个Attention的作用）"></a>网络的输入输出（三个Attention的作用）</h3><p> TODO：48min</p><h2 id="前馈网络"><a href="#前馈网络" class="headerlink" title="前馈网络"></a>前馈网络</h2><p>结构：线性层 -&gt; ReLU -&gt; 线性层</p><p>两个线性层分别将512投影成2048，然后再将2048投影回512</p><h2 id="Positional-Encoding"><a href="#Positional-Encoding" class="headerlink" title="Positional Encoding"></a>Positional Encoding</h2><p>在输入时就加入某一时刻的信息保证模型中带入时序信息。</p><h1 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h1><h2 id="Flowformer"><a href="#Flowformer" class="headerlink" title="Flowformer"></a><a href="https://t.bilibili.com/676736788413284374?share_source=pc_native" target="_blank" rel="noopener">Flowformer</a></h2><p>虽然可以完成通用关系（image、language、time series、agent trajectory）的建模，但在self-attention的点积计算中，对数据是两两进行计算（比如image任务中每两两图片进行计算），如果是针对长序列计算代价过大。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Abstract&quot;&gt;&lt;a href=&quot;#Abstract&quot; class=&quot;headerlink&quot; title=&quot;Abstract&quot;&gt;&lt;/a&gt;Abstract&lt;/h1&gt;&lt;p&gt;主流的序列转录模型（给一句英文生成一句中文）依赖于复杂的循环或卷积NN，使用Encoder和</summary>
      
    
    
    
    <category term="机器学习" scheme="https://liting1024.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="读论文" scheme="https://liting1024.github.io/tags/%E8%AF%BB%E8%AE%BA%E6%96%87/"/>
    
  </entry>
  
  <entry>
    <title>【项目详情】DateMinder</title>
    <link href="https://liting1024.github.io/2022/06/07/DateMinder/"/>
    <id>https://liting1024.github.io/2022/06/07/DateMinder/</id>
    <published>2022-06-07T14:02:06.000Z</published>
    <updated>2022-06-07T14:02:06.000Z</updated>
    
    <content type="html"><![CDATA[<p>概述：一款基于人工智能与云开发技术，为用户提供物品保质期记录提醒，与物品清单共享的小程序。</p><p>贡献：</p><ul><li>CLIP模型：使用Websocket动态更新清单。使用CLIP模型进行识别，并探究了Bert文本特征融合策略对检索的影响。</li><li>共享清单：使用 diff-match-patch 算法解决并发带来的多用户共同修改的冲突问题，使用高性能NoSQL，设计数据库权限划分，提高读写速度。</li></ul><h1 id="项目介绍"><a href="#项目介绍" class="headerlink" title="项目介绍"></a>项目介绍</h1><p>​    在生活中我们使用的大部分物品都有保质期，而我们往往难以做到清楚地记住每样物品的过期时间。导致在期限内未被使用而被浪费扔掉、或是由于使用过期产品对身心造成伤害，以及在家中，往往家庭成员无法记得其他成员购买的东西，导致重复购买同一类物品，而目前市面上的其他产品都不能很好的解决这些问题。</p><p>​    基于以上几种情况，我们开发的Date Minder——是一款基于人工智能与云开发技术，为用户提供物品保质期记录提醒，与物品清单共享的小程序。</p><p>​    我们希望通过数字化技术解决这一系列问题，为大家创造一个绿色、健康的生活环境，Date Minder 应运而生。</p><h1 id="重点难点"><a href="#重点难点" class="headerlink" title="重点难点"></a>重点难点</h1><h2 id="共享清单"><a href="#共享清单" class="headerlink" title="共享清单"></a>共享清单</h2><p>1、使用 diff-match-patch 算法解决并发带来的多用户共同修改的冲突问题。</p><p>2、使用高性能NoSQL，提高读写速度。</p><p>3、设计数据库权限划分。</p><p>4、使用Websocket动态更新清单。</p><h2 id="物品识别模型-CLIP"><a href="#物品识别模型-CLIP" class="headerlink" title="物品识别模型 - CLIP"></a>物品识别模型 - CLIP</h2><p>​    CLIP的模型采用的是经典的双塔结构，对于图片域和文本域有着不同的图片编码器（Image Encoder）和文本编码器（Text Encoder）。其中文本编码器采用了经典的Transformer结构，而图片编码器则采用了两种：第一种是改进后的ResNet，作者选择用基于注意力的池化层去替代ResNet的全局池化层，此处的注意力机制同样是与Transformer类似的多头QKV注意力；作者同样采用ViT结构作为第二种图片编码器进行实验。</p><p>​    CLIP的负样本采样，采用了in-batch负采样的方法。其CLIP模型也是经典的双塔结构。此时如图所示，对图片嵌入特征和文本嵌入特征进行矩阵相乘。那么形成的打分矩阵上，对角线上都是配对的正样本对打分，而矩阵的其他元素，则是由同个batch内的图片和不配对的文本（相反亦然）组成的负样本。而后只需要对每一行和每一列求交叉熵损失，并且加和起来即形成了总损失了。其中每一行可以视为是同个图片，与同个batch内其他所有样本对的文本进行组合构成的负样本对形成的损失，而每一列自然就是同个文本，对于每个图片进行组合而构成的损失了。</p><p>​    如下图显示，考虑到以单词作为标签存在多义的情况，比如在Oxford-IIIT Pet dataset 数据集中boxer表示斗牛犬，而在其他数据集中则可能表示拳击运动；在ImageNet中，crane同时表示了起重机和鹤。这种词语的多义显然对是因为缺少对标签的上下文描述导致的。为了解决这种问题，作者在指示上下文中添加了一些提示标签类型的词语，比如A photo of a <LABEL>, a type of pet.。作者将这个方法称之为“prompt engineering”。在合适地选取了不同的指示上下文，并且将其打分进行ensemble之后。作者发现这些Tricks竟能在zero-shot实验上提高5个绝对百分位。作者通过和经过强监督学习的Resnet-50提取的特征对比，任务都是分类任务，因此作者基于Resnet-50和CLIP提取出的特征，只是训练了最后的分类器，分类结果如Fig 2.4所示。可以发现仅仅通过无监督的对比学习预训练得到的特征，即便是和强监督模型特征相比也是不分伯仲的。</p><p><img src="https://cdn.jsdelivr.net/gh/liting1024/PicImage/PicgoGithub/wps5.jpg" alt="img"> </p><p><img src="https://cdn.jsdelivr.net/gh/liting1024/PicImage/PicgoGithub/wps6.jpg" alt="img"></p><h3 id="改进：Bert文本特征不同的融合机制"><a href="#改进：Bert文本特征不同的融合机制" class="headerlink" title="改进：Bert文本特征不同的融合机制"></a>改进：Bert文本特征不同的融合机制</h3><p>​    原始CLIP模型中只返回last hidden state和pooler_output，即cls最后一层的隐藏状态。CLIP一般使用最后一层的特征作为文本特征。</p><p>​    Bert输出是一个元组类型的数据，包含四部分： last hidden state shape是(batch_size, sequence_length, hidden_size)，hidden_size=768,它是模型最后一层的隐藏状态。    </p><p>​    pooler_output：shape是(batch_size, hidden_size)，这是序列的第一个token (cls) 的最后一层的隐藏状态，它是由线性层和Tanh激活函数进一步处理的，这个输出不是对输入的语义内容的一个很好的总结，对于整个输入序列的隐藏状态序列的平均化或池化可以更好的表示一句话。hidden_states：这是输出的一个可选项，如果输出，需要指定config.output_hidden_states=True,它是一个元组，含有13个元素，第一个元素可以当做是embedding，其余12个元素是各层隐藏状态的输出，每个元素的形状是(batch_size, sequence_length, hidden_size)。attentions：这也是输出的一个可选项，如果输出，需要指定config.output_attentions=True,它也是一个元组，含有12个元素，包含每的层注意力权重，用于计算self-attention heads的加权平均值。</p><p><img src="https://cdn.jsdelivr.net/gh/liting1024/PicImage/PicgoGithub/wps2.jpg" alt="img"> </p><p>​    近期发表于ICCV2021关于跨模态视频检索的研究中，作者探究了Bert不同层特征聚合对检索的影响，如CLS，Maxpolling和Average Pooling，1D-CNN，发现使用Average Pooling的特征检索结果最好，受此启发，我们复现以上方法，对CLIP的文本特征使用所有层特征Average Pooling。</p><p><img src="https://cdn.jsdelivr.net/gh/liting1024/PicImage/PicgoGithub/wps3.jpg" alt="img"></p><h2 id="OCR识别模型-StrucTexT"><a href="#OCR识别模型-StrucTexT" class="headerlink" title="OCR识别模型 - StrucTexT"></a>OCR识别模型 - StrucTexT</h2><p>​    光学字符识别（OCR）是目前应用最为广泛的视觉AI技术之一。随着OCR技术在产业应用的快速发展，现实场景对OCR提出新的需求：从感知走向认知，OCR不但需要认识文字，也要进一步理解文字。因此，识别结构化文本逐渐成为OCR产业应用的核心技术之一，旨在快速且准确地分析卡证、票据、档案图像等富视觉数据中的结构化文字信息，并对关键数据进行提取。</p><p>​    StrucTexT是一个基于双粒度表示的多模态信息提取模型。除了采用字符粒度建模文本之外，StrucTexT利用字段组织文档视觉线索，并构建字符和字段的匹配关系对齐图像与文本特征。在多模态信息表示上，StrucTexT构建文本、图像和布局的多模态特征，并提出“遮罩式视觉语言模型”，“字段长度预测”和“字段方位预测”三种自监督预训练任务促进跨模态特征交互，帮助模型学习模态间的信息关联，增强对文档的综合理解能力。另外，StrucTexT支持中英双语编码。在双粒度表征下，模型能够实现字符和字段粒度的信息抽取任务，实现灵活选型和场景适配。</p><p><img src="https://cdn.jsdelivr.net/gh/liting1024/PicImage/PicgoGithub/wps1.jpg" alt="img"> </p><p>​    我们使用预训练模型StrucTexT作为程序识别文字的模型，同时，由于模型不能直接识别保质期，我们在模型识别返回的基础上，对市面上一些常见的保质期标签进行了收集，构建正则表达式，将物品生产日期和保质期从OCR识别结果中匹配出来，自动填写。</p><h1 id="功能展示"><a href="#功能展示" class="headerlink" title="功能展示"></a>功能展示</h1><table><thead><tr><th align="center"><strong>功能名称</strong></th><th align="center"><strong>功能描述</strong></th></tr></thead><tbody><tr><td align="center">登录</td><td align="center">用户可以通过登陆界面登录小程序，来进行对物品的管理。</td></tr><tr><td align="center">AI识图</td><td align="center">支持拍照进行AI识图，识别出物品的名称及种类。</td></tr><tr><td align="center">搜索</td><td align="center">用户可以通过小程序中的搜索功能进行对物品的搜索。</td></tr><tr><td align="center">分类</td><td align="center">用户可以对录入的物品进行分类，目前有食品，药品，护肤/化妆品三类。</td></tr><tr><td align="center">过期提醒</td><td align="center">用户可以设置物品的保质日期，小程序会在保质期到期时进行提醒。</td></tr><tr><td align="center">多人数据共享</td><td align="center">本小程序支持多人之间建立不同清单实现数据共享，方便多人管理共有数据。</td></tr><tr><td align="center">保质期参考</td><td align="center">在Q&amp;A中进行常用物品保质期的展示</td></tr></tbody></table><h1 id="界面展示"><a href="#界面展示" class="headerlink" title="界面展示"></a>界面展示</h1><p>主页面</p><img src="https://cdn.jsdelivr.net/gh/liting1024/PicImage/PicgoGithub/image-20220607221017158.png" alt="image-20220607221017158" style="zoom: 50%;" /><p>添加页面</p><img src="https://cdn.jsdelivr.net/gh/liting1024/PicImage/PicgoGithub/image-20220607221924849.png" alt="image-20220607221924849" style="zoom: 33%;" /><p>共享清单</p><img src="https://cdn.jsdelivr.net/gh/liting1024/PicImage/PicgoGithub/image-20220607221854361.png" alt="image-20220607221854361" style="zoom:33%;" /><p>创建清单</p><img src="https://cdn.jsdelivr.net/gh/liting1024/PicImage/PicgoGithub/image-20220607221841071.png" alt="image-20220607221841071" style="zoom:33%;" /><p>我的界面</p><img src="https://cdn.jsdelivr.net/gh/liting1024/PicImage/PicgoGithub/image-20220607221822080.png" alt="image-20220607221822080" style="zoom:33%;" /><h1 id="项目总结"><a href="#项目总结" class="headerlink" title="项目总结"></a>项目总结</h1><p>​    加入语音输入功能可与现在市场上的智能音箱，百度旗下小度，小米旗下ai音箱等结合。还可与智能冰箱结合将Date Minder内物品信息显示在智能冰箱显示屏上。为用户生活带来更多便利。</p><p>​    坚持对软件的再开发与功能完善，未来会增设用户饮食规律提醒与建议与各类APP使用时长的健康提醒与报告，还将利用智能分析系统完善生成用户不常用物品清单功能。未来还将继续推出可以与智能家居链接的其他版本的软件。</p><p>​    从用户需求的角度，不断完善和开发新的功能，未来会不断地给用户带来新的体验和惊喜。未来的市场优势也一定属于我们。一款好的产品，不仅仅是一个工具，还将会提供一种美好的生活方式。绿色，节能，环保。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;概述：一款基于人工智能与云开发技术，为用户提供物品保质期记录提醒，与物品清单共享的小程序。&lt;/p&gt;
&lt;p&gt;贡献：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;CLIP模型：使用Websocket动态更新清单。使用CLIP模型进行识别，并探究了Bert文本特征融合策略对检索的影响。&lt;/li&gt;
</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>【项目详情】解字</title>
    <link href="https://liting1024.github.io/2022/05/27/jiezi/"/>
    <id>https://liting1024.github.io/2022/05/27/jiezi/</id>
    <published>2022-05-27T01:03:34.000Z</published>
    <updated>2022-05-27T01:03:34.000Z</updated>
    
    <content type="html"><![CDATA[<p>作品现已上架TapTap，支持篝火计划 <a href="https://www.taptap.com/app/235522" target="_blank" rel="noopener">点击链接</a></p><h1 id="创作简介"><a href="#创作简介" class="headerlink" title="创作简介"></a>创作简介</h1><h2 id="作品简介"><a href="#作品简介" class="headerlink" title="作品简介"></a>作品简介</h2><p>​    汉字文化在当下如何利用数媒游戏阵地有效发挥其文化价值和影响力，是应对互联网发展带来的表达匮乏，如提笔忘字等现象的重要论题。</p><p>​    基于此，我们团队充分挖掘汉字的结构特点和文化底蕴，设计出一款基于Unity的汉字解密游戏，游戏分为三个篇章，分别是汉字冒险、汉字竞速和汉字识解。</p><p>​    我们自主设计了丰富的故事情节并融入古典诗歌与民间神话，充满了古典韵味，弘扬了古典文化，能激发玩家的兴趣，带给玩家沉浸式游戏体验。在保证趣味性的同时，具有深刻教育意义，宣扬积极向上的价值观，玩家可以在古典文化的氛围中更好的学习和理解汉字。</p><p>​    由于汉字的复杂结构和丰富的文化底蕴，如何在紧扣《送东阳马生序》的故事背景的基础上利用汉字的结构特性进行组合和拆分以表达具象的场景和物体成为游戏设计的一大难点。通过阅读相关期刊和《宋学士全集》，对汉字的结构演变、笔画之间的形态关系和《送东阳马生序》故事情节的研究总结，设计出七个以宋濂奔走还书为主线的关卡。</p><p>​    故事情节是激发玩家兴趣必不可少的部分，如何将汉字文化与民间神话、古典诗歌结合起来形成连贯、完整的情节是一大难点。经过团队的反复讨论和研磨，我们团队为每一关卡设计了不同的情节，增加游戏整体古典韵味的同时，为游戏关卡提供了一定的线索。</p><p>​    我们设计四大系统，训练基于CNN的中文OCR模型实现游戏基本功能，同时制作了一个框架，涵盖了汉字移动过程中所产生的所有的事件，有利于我们将游戏的场景做的更大更宏观。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;作品现已上架TapTap，支持篝火计划 &lt;a href=&quot;https://www.taptap.com/app/235522&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;点击链接&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&quot;创作简介&quot;&gt;&lt;a href=&quot;#创作简介&quot;</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>CLIP</title>
    <link href="https://liting1024.github.io/2022/05/26/CLIP/"/>
    <id>https://liting1024.github.io/2022/05/26/CLIP/</id>
    <published>2022-05-26T12:43:50.000Z</published>
    <updated>2022-05-26T12:43:50.000Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://github.com/openai/CLIP" target="_blank" rel="noopener">项目GitHub链接</a></p><p><a href="https://github.com/jina-ai/clip-as-service" target="_blank" rel="noopener">在线CLIP-as-service</a></p><p><img src="https://cdn.jsdelivr.net/gh/liting1024/PicImage/PicgoGithub/CLIP.png" alt=""></p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>数据集：句子 - 图片对（将单词做成句子“A photo of a xxx”，对应图片）</p><p>优点：预训练、结构简单、在zero-shot（能够对从没见过的类别分类）上比有监督下ResNet50效果好、泛化性好。数据集大模型复杂，因此效果更好。</p><p>1、利用自然语言处理的监督信号做预训练：</p><p>输入 图片和句子的配对</p><p>通过图片编码器，Resnet或vison transformer，得到图像特征</p><p>通过文本编码器，CBOW或Text Transformer，得到文本特征</p><p>然后通过投射层，合并图片和文本多模态的特征</p><p>计算cosine相似度得到logits</p><p>用logits和labels做交叉熵，计算出图片loss和文本loss，并求平均</p><p>然后对图片和文本进行对比学习，得到文本和图片的特征</p><p>正样本：配对的图片文本对，即左图中对角线上的样本，共n个 </p><p>负样本：非对角线的元素，共$ n^2-n$ 个</p><p>数据集：OpenAI上4亿个文本和图片配对</p><p>2、用Prompt template做推理：</p><p>Prompt engineringh或Prompt ensemble</p><p>输入 图片</p><p>通过图片编码器得到特征，与每个文本特征求cos similarity</p><p>优点：得到语义特征，迁移性强（素描、动漫风格的物体都能识别出是什么）</p><p>可以应用在；目标检测（丰富检测出物体的信息）、用文本检索视频中物品出现的帧等</p><h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>​    现有模型都是通过提前定义好的标签集合（即物品类别）来预测，是有限制性的监督信号，无法识别新的类别；CLIP直接从自然语言处理中得到特征，即用爬取到的4亿图片-文本配对进行多模态的对比训练；在30个不同数据集上做预测效果都很好，比如在ImageNet上和有监督训练的ResNet-50打平手；预训练代码没开源，但模型在Github上开源了。</p><p>​    Bert、GPT、T5是在原始的文本数据上预训练一个模型，已经取得革命性成果，无论是自回归预测还是掩码完形填空的方式，都是自监督的方式，目标函数和下游任务无关，随着模型、数据、计算资源变多，性能也会变好，比如GPT-3无需特定领域的数据就能与之前精心设计的网络做对比。</p><p>​    对99年到21年工作的讨论，……，总之，有了Transformer后，出现了VirTex和ConVIRT这些和CLIP类似的工作，但这些模型由于数据和模型规模不够大，所以效果不够好；CLIP是ConVIRT的简化版，共尝试8个模型，包括Vision Transformer和ResNet，迁移学习效果和模型大小呈正相关。</p><h1 id="Approach"><a href="#Approach" class="headerlink" title="Approach"></a>Approach</h1><p>1、监督的NLP</p><p>​    NLP中原来多是基于N-gram，无法用于跨模态zero-shot工作</p><p>2、造数据集</p><p>​    现有的数据量都不够大，自己收集了WebImage Text（WIT）作为数据集</p><p>3、训练方法</p><p>​    文本用Transformer即 CBOW 或 Text Transformer，图片用CNN即ResNet或Vision Transformer ；由于同一张图有不同的文字描述，不能用预测型任务，而是对比任务，即对比文本和图片是否配对。</p><p><img src="https://cdn.jsdelivr.net/gh/liting1024/PicImage/PicgoGithub/uTools_1653485396142.png" alt=""></p><p>I为图片的输入，n为batchsize，224 * 224 * 3</p><p>T为文本的输入，由于和图片配对，batchsize也是n，l为文本序列长度</p><p>通过编码器之后得到特征，使用投射层，学习一下如何从单模态到多模态，得到用来对比的特征I_e和T_e，最后用logits（求得的余弦相似度）和 ground truth（labels）求两个交叉熵损失函数，再将两个损失函  数求平均。</p><p>ground truth 是 arange 即从1到n，这样可以使对角线（即保证1-a 2-b……）上的元素为正样本；</p><h1 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h1><h2 id="zore-shot-Transfer推理"><a href="#zore-shot-Transfer推理" class="headerlink" title="zore-shot Transfer推理"></a>zore-shot Transfer推理</h2><p>prompt：文本引导提示</p><p>由于文本的多义性且单个单词易产生歧义，将词语转化为句子“A photo of A xxx”计算出文本特征和图片特征对比，同时在句子中可以加入提示“A photo of A xxx，a type of xxx”，论文中用了80个提示模板，比如“A photo of a hard to see xxx”。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;a href=&quot;https://github.com/openai/CLIP&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;项目GitHub链接&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/jina-ai/clip-as</summary>
      
    
    
    
    <category term="机器学习" scheme="https://liting1024.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="读论文" scheme="https://liting1024.github.io/tags/%E8%AF%BB%E8%AE%BA%E6%96%87/"/>
    
  </entry>
  
  <entry>
    <title>STL</title>
    <link href="https://liting1024.github.io/2022/01/27/STL/"/>
    <id>https://liting1024.github.io/2022/01/27/STL/</id>
    <published>2022-01-27T09:25:45.000Z</published>
    <updated>2022-01-27T09:25:45.000Z</updated>
    
    <content type="html"><![CDATA[<p>[TOC]</p><h3 id="priority-queue"><a href="#priority-queue" class="headerlink" title="priority_queue"></a>priority_queue</h3><p>大根堆（top是max）优先队列</p><pre><code class="C++">priority_queue&lt;int, vector&lt;int&gt;, greater&lt;int&gt;&gt; q; // 小根堆toppush 和 popempty sizeemplace(1,1) // priority_queue&lt;PII&gt; q;// 相当于 push({1,1}) </code></pre><h3 id="deque"><a href="#deque" class="headerlink" title="deque"></a>deque</h3><p>双端队列：首尾都可以插入删除</p><p>应用：二叉树层次遍历</p><pre><code>empty()size()front() 和 back()push_front(x) 和 push_back(x)pop_front() 和 pop_back()</code></pre><h2 id="unordered"><a href="#unordered" class="headerlink" title="unordered"></a>unordered</h2><p>unordered_set, unordered_map, unordered_multiset, unordered_multimap, 哈希表</p><p>不支持 lower_bound()/upper_bound()， 迭代器的++，–</p><h2 id="set"><a href="#set" class="headerlink" title="set"></a>set</h2><p>不允许重复，升序</p><pre><code class="C++">erase(x) // 删除所有x或迭代器itcount() find() // set.find(1) == set.end() 没找到lower_bound(x) 大于等于x的最小的数的itupper_bound(x) 大于x的最下的数的it</code></pre><h3 id="multiset"><a href="#multiset" class="headerlink" title="multiset"></a>multiset</h3><p>允许重复，升序</p><h2 id="map"><a href="#map" class="headerlink" title="map"></a>map</h2><p>&lt;key, value&gt; 根据key升序，key不允许重复</p><pre><code>finderase(pair)[]lower_bound 和 upper_bound</code></pre><h3 id="multimap"><a href="#multimap" class="headerlink" title="multimap"></a>multimap</h3><p>&lt;key, value&gt; 根据key升序，key允许重复</p><h2 id="bitset"><a href="#bitset" class="headerlink" title="bitset"></a>bitset</h2><pre><code class="C++">bitset&lt;10000&gt; s;~, &amp;, |, ^&gt;&gt;, &lt;&lt;==, !=[]count()  返回有多少个1any()  判断是否至少有一个1none()  判断是否全为0set()  把所有位置成1set(k, v)  将第k位变成vreset()  把所有位变成0flip()  等价于~flip(k) 把第k位取反</code></pre><h2 id="vector"><a href="#vector" class="headerlink" title="vector"></a>vector</h2><p>支持按字典序比较运算</p><pre><code class="C++">sizeemptyclearfront 和 backpush_back 和 pop_backinsert emplace[]</code></pre><p>二维</p><pre><code>vector&lt;vector&lt;int&gt;&gt; g(N,vector&lt;int&gt;(N,-1)); // 初始化为-1（N*N大小）</code></pre><h2 id="stack"><a href="#stack" class="headerlink" title="stack"></a>stack</h2><pre><code>toppush 和 pop</code></pre><h2 id="queue"><a href="#queue" class="headerlink" title="queue"></a>queue</h2><pre><code>front 和 backpush 和 pop</code></pre><h2 id="pair"><a href="#pair" class="headerlink" title="pair"></a>pair</h2><p>升序？</p><h2 id="unique"><a href="#unique" class="headerlink" title="unique"></a>unique</h2><p>将<strong>序列中不重复的相邻元素（即与前一个数不同）</strong>放在前面，需要先排序</p><pre><code class="C++">int arr[] = {3,2,2,1,4}, n = sizeof arr/ sizeof 1;for (int a : arr) cout&lt;&lt;a&lt;&lt;&#39; &#39;;// 3 2 2 1 4 sort(arr, arr+n);// 1 2 2 3 4n = unique(arr, arr+n) - arr;for (int a : arr) cout&lt;&lt;a&lt;&lt;&#39; &#39;;// 1 2 3 4 4for (int i = 0; i &lt; n; i++) cout&lt;&lt;arr[i]&lt;&lt;&#39; &#39;;// 1 2 3 4 </code></pre><h2 id="greater"><a href="#greater" class="headerlink" title="greater"></a>greater</h2><table><thead><tr><th align="center"></th><th align="center">sort</th><th align="center">priority_queue</th></tr></thead><tbody><tr><td align="center">greater</td><td align="center">从大到小</td><td align="center">小顶堆</td></tr><tr><td align="center">less</td><td align="center">从小到大</td><td align="center">大顶堆</td></tr></tbody></table>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;[TOC]&lt;/p&gt;
&lt;h3 id=&quot;priority-queue&quot;&gt;&lt;a href=&quot;#priority-queue&quot; class=&quot;headerlink&quot; title=&quot;priority_queue&quot;&gt;&lt;/a&gt;priority_queue&lt;/h3&gt;&lt;p&gt;大根堆（top是m</summary>
      
    
    
    
    <category term="程序设计" scheme="https://liting1024.github.io/categories/%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1/"/>
    
    
    <category term="C++" scheme="https://liting1024.github.io/tags/C/"/>
    
  </entry>
  
  <entry>
    <title>ACM经验</title>
    <link href="https://liting1024.github.io/2022/01/13/ACM%E7%BB%8F%E9%AA%8C/"/>
    <id>https://liting1024.github.io/2022/01/13/ACM%E7%BB%8F%E9%AA%8C/</id>
    <published>2022-01-13T13:56:24.000Z</published>
    <updated>2022-01-13T13:56:24.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h1><pre><code class="c++">#pragma GCC optimize (&quot;O1&quot;)#pragma comment(linker, &quot;/STACK:1024000000,1024000000&quot;)//防止爆栈#include &lt;iostream&gt;#include &lt;vector&gt;#include &lt;algorithm&gt;#include &lt;iomanip&gt;#include &lt;cstring&gt;#define r(i,a,b) for(int i=a,i&lt;b;i++)using ll = long long;using namespace std;const int N=100;inline int read() {    int s = 0, w = 1;//s是数值，w是符号    char ch = getchar();    while (ch &lt; &#39;0&#39; || ch &gt; &#39;9&#39;) {//将空格、换行与符号滤去        if (ch == &#39;-&#39;) {//出现负号表示是负数            w = -1;            ch = getchar();//继续读入        }    }    while (ch &gt;= &#39;0&#39; &amp;&amp; ch &lt;= &#39;9&#39;){ //循环读取每一位的数字        s = s * 10 + ch - &#39;0&#39;;//将每一位的结果累加进s        ch = getchar();    }    return s * w;//乘上符号}int main() {    ios::sync_with_stdio(0);    cin.tie(0);}</code></pre><p>编译器优化</p><p>-O0 表示无优化状态</p><p>-O1 表示对代码进行了优化</p><p>-O2 表示减小目标文件大小</p><p>-O3 表示减小代码段及栈空间的大小</p><p>#pragma GCC optimize (“O0”)</p><p>爆栈</p><p>#pragma comment(linker, “/STACK:1024000000,1024000000”)</p><p>全局变量自动初始化</p><pre><code>ios::sync_with_stdio(false); // 关闭C++输入输出缓冲区同步cin.tie(0); // 绑定缓冲区</code></pre><p>关闭后<em>cin不能</em>与scanf,sscanf, getchar, fgets等混用,cout不能与printf,<em>puts</em>等混用</p><pre><code>使用ios...和tie 130 ms只使用ios... 676 ms只使用tie 315 ms无优化 885 ms</code></pre><h2 id="快读快出"><a href="#快读快出" class="headerlink" title="快读快出"></a>快读快出</h2><h3 id="scanf"><a href="#scanf" class="headerlink" title="scanf"></a>scanf</h3><p>scanf(“%控制格式”, &amp;变量地址); 对于数组 变量本身就是地址</p><table><thead><tr><th align="center">格式</th><th align="center">字符意义</th></tr></thead><tbody><tr><td align="center">d</td><td align="center">十进制整数</td></tr><tr><td align="center">o</td><td align="center">八进制整数</td></tr><tr><td align="center">x</td><td align="center">十六进制整数</td></tr><tr><td align="center">u</td><td align="center">无符号十进制整数</td></tr><tr><td align="center">f或e</td><td align="center">实型数(用小数形式或指数形式)</td></tr><tr><td align="center">c</td><td align="center">单个字符</td></tr><tr><td align="center">s</td><td align="center">字符串</td></tr><tr><td align="center">l/h</td><td align="center">l表示长，h表示短，Eg：lf 读入doble</td></tr><tr><td align="center">*</td><td align="center">读入不赋值，EG：*d 读入int但不赋值</td></tr><tr><td align="center">5（数字）</td><td align="center">读入宽度</td></tr><tr><td align="center">-/+</td><td align="center">左/右对齐</td></tr><tr><td align="center">#</td><td align="center">需要时给出小数点和前缀o或 0x</td></tr><tr><td align="center">空格</td><td align="center">需要时显示正负号</td></tr><tr><td align="center"></td><td align="center"></td></tr></tbody></table><p>没有精度控制 scanf(“%5.2f”,&amp;a);是非法的</p><p>要求给出变量地址 scanf(“%d”,a);是非法的</p><p>在碰到空格，TAB，回车或非法数据时认为该数据结束</p><h3 id="printf"><a href="#printf" class="headerlink" title="printf"></a>printf</h3><p>printf(“%控制格式”, 变量本身);</p><p>%a(%A)     浮点数、十六进制数字和p-(P-)记数法(C99)<br>      %c         字符<br>      %d         有符号十进制整数<br>      %f         浮点数(包括float和double)<br>      %e(%E)     浮点数指数输出[e-(E-)记数法]<br>      %g(%G)     浮点数不显无意义的零”0”<br>      %i         有符号十进制整数(与%d相同)<br>      %u         无符号十进制整数<br>      %x(%X)     十六进制整数0f(0F)   e.g.   0x1234<br>      %p         指针<br>      %%         “%”</p><h3 id="读入空格"><a href="#读入空格" class="headerlink" title="读入空格"></a>读入空格</h3><p>cin.get(x) 读入单个char</p><p>x = getchar( ) 读入单个char，对应putchar( ) 输出单个char</p><p>getline(x) 读入string</p><h3 id="内联函数read"><a href="#内联函数read" class="headerlink" title="内联函数read"></a>内联函数read</h3><p>内联是将代码内嵌到调用者代码处</p><pre><code>inline int read() {    int s = 0, w = 1;//s是数值，w是符号    char ch = getchar();    while (ch &lt; &#39;0&#39; || ch &gt; &#39;9&#39;) {//将空格、换行与符号滤去        if (ch == &#39;-&#39;) {//出现负号表示是负数            w = -1;            ch = getchar();//继续读入        }    }    while (ch &gt;= &#39;0&#39; &amp;&amp; ch &lt;= &#39;9&#39;){ //循环读取每一位的数字        s = s * 10 + ch - &#39;0&#39;;//将每一位的结果累加进s        ch = getchar();    }    return s * w;//乘上符号}</code></pre><h3 id="内联函数write"><a href="#内联函数write" class="headerlink" title="内联函数write"></a>内联函数write</h3><pre><code>void write(int v) {    if (v&lt;0) {        putchar(&#39;-&#39;);        v=-v;    }    if (v&gt;9) write(v/10);    putchar(v%10+&#39;0&#39;);}puts(&quot;&quot;); //换行 </code></pre><h1 id="位运算"><a href="#位运算" class="headerlink" title="位运算"></a>位运算</h1><p>2^n 可以用 1&lt;&lt;n 来计算</p><h2 id="异或"><a href="#异或" class="headerlink" title="异或 ^"></a>异或 ^</h2><h1 id="时间复杂度"><a href="#时间复杂度" class="headerlink" title="时间复杂度"></a>时间复杂度</h1><ol><li><span class="MathJax_Preview" style="color: inherit;"></span><span class="MathJax" id="MathJax-Element-2-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>n</mi><mo>&amp;#x2264;</mo><mn>30</mn></math>" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-10" role="math" style="width: 3.545em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.848em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.629em, 1002.848em, 2.79em, -999.997em); top: -2.494em; left: 0.003em;"><span class="mrow" id="MathJax-Span-11"><span class="mi" id="MathJax-Span-12" style="font-family: STIXGeneral-Italic;">n</span><span class="mo" id="MathJax-Span-13" style="font-family: STIXGeneral-Regular; padding-left: 0.293em;">≤</span><span class="mn" id="MathJax-Span-14" style="font-family: STIXGeneral-Regular; padding-left: 0.293em;">30</span></span><span style="display: inline-block; width: 0px; height: 2.5em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.211em; border-left-width: 0px; border-left-style: solid; width: 0px; height: 1.075em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>n</mi><mo>≤</mo><mn>30</mn></math></span></span><script type="math/tex" id="MathJax-Element-2">n \le 30</script>, 指数级别, dfs+剪枝，状态压缩dp</li><li><span class="MathJax_Preview" style="color: inherit;"></span><span class="MathJax" id="MathJax-Element-3-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>n</mi><mo>&amp;#x2264;</mo><mn>100</mn></math>" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-15" role="math" style="width: 4.184em; display: inline-block;"><span style="display: inline-block; position: relative; width: 3.371em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.629em, 1003.371em, 2.79em, -999.997em); top: -2.494em; left: 0.003em;"><span class="mrow" id="MathJax-Span-16"><span class="mi" id="MathJax-Span-17" style="font-family: STIXGeneral-Italic;">n</span><span class="mo" id="MathJax-Span-18" style="font-family: STIXGeneral-Regular; padding-left: 0.293em;">≤</span><span class="mn" id="MathJax-Span-19" style="font-family: STIXGeneral-Regular; padding-left: 0.293em;">100</span></span><span style="display: inline-block; width: 0px; height: 2.5em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.211em; border-left-width: 0px; border-left-style: solid; width: 0px; height: 1.075em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>n</mi><mo>≤</mo><mn>100</mn></math></span></span><script type="math/tex" id="MathJax-Element-3">n \le 100</script> =&gt; <span class="MathJax_Preview" style="color: inherit;"></span><span class="MathJax" id="MathJax-Element-4-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>O</mi><mo stretchy=&quot;false&quot;>(</mo><msup><mi>n</mi><mn>3</mn></msup><mo stretchy=&quot;false&quot;>)</mo></math>" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-20" role="math" style="width: 2.965em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.384em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.513em, 1002.326em, 2.848em, -999.997em); top: -2.494em; left: 0.003em;"><span class="mrow" id="MathJax-Span-21"><span class="mi" id="MathJax-Span-22" style="font-family: STIXGeneral-Italic;">O</span><span class="mo" id="MathJax-Span-23" style="font-family: STIXGeneral-Regular;">(</span><span class="msubsup" id="MathJax-Span-24"><span style="display: inline-block; position: relative; width: 0.932em; height: 0px;"><span style="position: absolute; clip: rect(3.371em, 1000.467em, 4.184em, -999.997em); top: -4.004em; left: 0.003em;"><span class="mi" id="MathJax-Span-25" style="font-family: STIXGeneral-Italic;">n</span><span style="display: inline-block; width: 0px; height: 4.01em;"></span></span><span style="position: absolute; top: -4.352em; left: 0.526em;"><span class="mn" id="MathJax-Span-26" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">3</span><span style="display: inline-block; width: 0px; height: 4.01em;"></span></span></span></span><span class="mo" id="MathJax-Span-27" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.5em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.282em; border-left-width: 0px; border-left-style: solid; width: 0px; height: 1.432em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>O</mi><mo stretchy="false">(</mo><msup><mi>n</mi><mn>3</mn></msup><mo stretchy="false">)</mo></math></span></span><script type="math/tex" id="MathJax-Element-4">O(n^3)</script>，floyd，dp，高斯消元</li><li><span class="MathJax_Preview" style="color: inherit;"></span><span class="MathJax" id="MathJax-Element-5-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>n</mi><mo>&amp;#x2264;</mo><mn>1000</mn></math>" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-28" role="math" style="width: 4.707em; display: inline-block;"><span style="display: inline-block; position: relative; width: 3.836em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.629em, 1003.836em, 2.79em, -999.997em); top: -2.494em; left: 0.003em;"><span class="mrow" id="MathJax-Span-29"><span class="mi" id="MathJax-Span-30" style="font-family: STIXGeneral-Italic;">n</span><span class="mo" id="MathJax-Span-31" style="font-family: STIXGeneral-Regular; padding-left: 0.293em;">≤</span><span class="mn" id="MathJax-Span-32" style="font-family: STIXGeneral-Regular; padding-left: 0.293em;">1000</span></span><span style="display: inline-block; width: 0px; height: 2.5em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.211em; border-left-width: 0px; border-left-style: solid; width: 0px; height: 1.075em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>n</mi><mo>≤</mo><mn>1000</mn></math></span></span><script type="math/tex" id="MathJax-Element-5">n \le 1000</script> =&gt; <span class="MathJax_Preview" style="color: inherit;"></span><span class="MathJax" id="MathJax-Element-6-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>O</mi><mo stretchy=&quot;false&quot;>(</mo><msup><mi>n</mi><mn>2</mn></msup><mo stretchy=&quot;false&quot;>)</mo></math>" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-33" role="math" style="width: 2.965em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.384em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.513em, 1002.326em, 2.848em, -999.997em); top: -2.494em; left: 0.003em;"><span class="mrow" id="MathJax-Span-34"><span class="mi" id="MathJax-Span-35" style="font-family: STIXGeneral-Italic;">O</span><span class="mo" id="MathJax-Span-36" style="font-family: STIXGeneral-Regular;">(</span><span class="msubsup" id="MathJax-Span-37"><span style="display: inline-block; position: relative; width: 0.932em; height: 0px;"><span style="position: absolute; clip: rect(3.371em, 1000.467em, 4.184em, -999.997em); top: -4.004em; left: 0.003em;"><span class="mi" id="MathJax-Span-38" style="font-family: STIXGeneral-Italic;">n</span><span style="display: inline-block; width: 0px; height: 4.01em;"></span></span><span style="position: absolute; top: -4.352em; left: 0.526em;"><span class="mn" id="MathJax-Span-39" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">2</span><span style="display: inline-block; width: 0px; height: 4.01em;"></span></span></span></span><span class="mo" id="MathJax-Span-40" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.5em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.282em; border-left-width: 0px; border-left-style: solid; width: 0px; height: 1.432em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>O</mi><mo stretchy="false">(</mo><msup><mi>n</mi><mn>2</mn></msup><mo stretchy="false">)</mo></math></span></span><script type="math/tex" id="MathJax-Element-6">O(n^2)</script>，<span class="MathJax_Preview" style="color: inherit;"></span><span class="MathJax" id="MathJax-Element-7-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>O</mi><mo stretchy=&quot;false&quot;>(</mo><msup><mi>n</mi><mn>2</mn></msup><mi>l</mi><mi>o</mi><mi>g</mi><mi>n</mi><mo stretchy=&quot;false&quot;>)</mo></math>" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-41" role="math" style="width: 5.171em; display: inline-block;"><span style="display: inline-block; position: relative; width: 4.184em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.513em, 1004.126em, 2.907em, -999.997em); top: -2.494em; left: 0.003em;"><span class="mrow" id="MathJax-Span-42"><span class="mi" id="MathJax-Span-43" style="font-family: STIXGeneral-Italic;">O</span><span class="mo" id="MathJax-Span-44" style="font-family: STIXGeneral-Regular;">(</span><span class="msubsup" id="MathJax-Span-45"><span style="display: inline-block; position: relative; width: 0.932em; height: 0px;"><span style="position: absolute; clip: rect(3.371em, 1000.467em, 4.184em, -999.997em); top: -4.004em; left: 0.003em;"><span class="mi" id="MathJax-Span-46" style="font-family: STIXGeneral-Italic;">n</span><span style="display: inline-block; width: 0px; height: 4.01em;"></span></span><span style="position: absolute; top: -4.352em; left: 0.526em;"><span class="mn" id="MathJax-Span-47" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">2</span><span style="display: inline-block; width: 0px; height: 4.01em;"></span></span></span></span><span class="mi" id="MathJax-Span-48" style="font-family: STIXGeneral-Italic;">l<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mi" id="MathJax-Span-49" style="font-family: STIXGeneral-Italic;">o</span><span class="mi" id="MathJax-Span-50" style="font-family: STIXGeneral-Italic;">g</span><span class="mi" id="MathJax-Span-51" style="font-family: STIXGeneral-Italic;">n</span><span class="mo" id="MathJax-Span-52" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.5em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.354em; border-left-width: 0px; border-left-style: solid; width: 0px; height: 1.432em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>O</mi><mo stretchy="false">(</mo><msup><mi>n</mi><mn>2</mn></msup><mi>l</mi><mi>o</mi><mi>g</mi><mi>n</mi><mo stretchy="false">)</mo></math></span></span><script type="math/tex" id="MathJax-Element-7">O(n^2logn)</script>，dp，二分，朴素版Dijkstra、朴素版Prim、Bellman-Ford</li><li><span class="MathJax_Preview" style="color: inherit;"></span><span class="MathJax" id="MathJax-Element-8-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>n</mi><mo>&amp;#x2264;</mo><mn>10000</mn></math>" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-53" role="math" style="width: 5.404em; display: inline-block;"><span style="display: inline-block; position: relative; width: 4.358em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.629em, 1004.358em, 2.79em, -999.997em); top: -2.494em; left: 0.003em;"><span class="mrow" id="MathJax-Span-54"><span class="mi" id="MathJax-Span-55" style="font-family: STIXGeneral-Italic;">n</span><span class="mo" id="MathJax-Span-56" style="font-family: STIXGeneral-Regular; padding-left: 0.293em;">≤</span><span class="mn" id="MathJax-Span-57" style="font-family: STIXGeneral-Regular; padding-left: 0.293em;">10000</span></span><span style="display: inline-block; width: 0px; height: 2.5em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.211em; border-left-width: 0px; border-left-style: solid; width: 0px; height: 1.075em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>n</mi><mo>≤</mo><mn>10000</mn></math></span></span><script type="math/tex" id="MathJax-Element-8">n \le 10000</script> =&gt; <span class="MathJax_Preview" style="color: inherit;"></span><span class="MathJax" id="MathJax-Element-9-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>O</mi><mo stretchy=&quot;false&quot;>(</mo><mi>n</mi><mo>&amp;#x2217;</mo><msqrt><mi>n</mi></msqrt><mo stretchy=&quot;false&quot;>)</mo></math>" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-58" role="math" style="width: 5.171em; display: inline-block;"><span style="display: inline-block; position: relative; width: 4.184em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.629em, 1004.126em, 2.907em, -999.997em); top: -2.494em; left: 0.003em;"><span class="mrow" id="MathJax-Span-59"><span class="mi" id="MathJax-Span-60" style="font-family: STIXGeneral-Italic;">O</span><span class="mo" id="MathJax-Span-61" style="font-family: STIXGeneral-Regular;">(</span><span class="mi" id="MathJax-Span-62" style="font-family: STIXGeneral-Italic;">n</span><span class="mo" id="MathJax-Span-63" style="font-family: STIXGeneral-Regular; padding-left: 0.235em;">∗</span><span class="msqrt" id="MathJax-Span-64" style="padding-left: 0.235em;"><span style="display: inline-block; position: relative; width: 1.222em; height: 0px;"><span style="position: absolute; clip: rect(3.371em, 1000.467em, 4.184em, -999.997em); top: -4.004em; left: 0.758em;"><span class="mrow" id="MathJax-Span-65"><span class="mi" id="MathJax-Span-66" style="font-family: STIXGeneral-Italic;">n</span></span><span style="display: inline-block; width: 0px; height: 4.01em;"></span></span><span style="position: absolute; clip: rect(3.023em, 1000.526em, 3.429em, -999.997em); top: -3.888em; left: 0.758em;"><span style="font-family: STIXGeneral-Regular;">‾</span><span style="display: inline-block; width: 0px; height: 4.01em;"></span></span><span style="position: absolute; clip: rect(2.907em, 1000.758em, 4.184em, -999.997em); top: -3.772em; left: 0.003em;"><span style="font-family: STIXVariants;">√</span><span style="display: inline-block; width: 0px; height: 4.01em;"></span></span></span></span><span class="mo" id="MathJax-Span-67" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.5em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.354em; border-left-width: 0px; border-left-style: solid; width: 0px; height: 1.361em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>O</mi><mo stretchy="false">(</mo><mi>n</mi><mo>∗</mo><msqrt><mi>n</mi></msqrt><mo stretchy="false">)</mo></math></span></span><script type="math/tex" id="MathJax-Element-9">O(n * \sqrt n)</script>，块状链表、分块、莫队</li><li><span class="MathJax_Preview" style="color: inherit;"></span><span class="MathJax" id="MathJax-Element-10-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>n</mi><mo>&amp;#x2264;</mo><mn>100000</mn></math>" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-68" role="math" style="width: 6.042em; display: inline-block;"><span style="display: inline-block; position: relative; width: 4.881em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.629em, 1004.881em, 2.79em, -999.997em); top: -2.494em; left: 0.003em;"><span class="mrow" id="MathJax-Span-69"><span class="mi" id="MathJax-Span-70" style="font-family: STIXGeneral-Italic;">n</span><span class="mo" id="MathJax-Span-71" style="font-family: STIXGeneral-Regular; padding-left: 0.293em;">≤</span><span class="mn" id="MathJax-Span-72" style="font-family: STIXGeneral-Regular; padding-left: 0.293em;">100000</span></span><span style="display: inline-block; width: 0px; height: 2.5em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.211em; border-left-width: 0px; border-left-style: solid; width: 0px; height: 1.075em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>n</mi><mo>≤</mo><mn>100000</mn></math></span></span><script type="math/tex" id="MathJax-Element-10">n \le 100000</script> =&gt; <span class="MathJax_Preview" style="color: inherit;"></span><span class="MathJax" id="MathJax-Element-11-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>O</mi><mo stretchy=&quot;false&quot;>(</mo><mi>n</mi><mi>l</mi><mi>o</mi><mi>g</mi><mi>n</mi><mo stretchy=&quot;false&quot;>)</mo></math>" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-73" role="math" style="width: 4.649em; display: inline-block;"><span style="display: inline-block; position: relative; width: 3.778em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.629em, 1003.72em, 2.907em, -999.997em); top: -2.494em; left: 0.003em;"><span class="mrow" id="MathJax-Span-74"><span class="mi" id="MathJax-Span-75" style="font-family: STIXGeneral-Italic;">O</span><span class="mo" id="MathJax-Span-76" style="font-family: STIXGeneral-Regular;">(</span><span class="mi" id="MathJax-Span-77" style="font-family: STIXGeneral-Italic;">n</span><span class="mi" id="MathJax-Span-78" style="font-family: STIXGeneral-Italic;">l<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mi" id="MathJax-Span-79" style="font-family: STIXGeneral-Italic;">o</span><span class="mi" id="MathJax-Span-80" style="font-family: STIXGeneral-Italic;">g</span><span class="mi" id="MathJax-Span-81" style="font-family: STIXGeneral-Italic;">n</span><span class="mo" id="MathJax-Span-82" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.5em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.354em; border-left-width: 0px; border-left-style: solid; width: 0px; height: 1.218em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>O</mi><mo stretchy="false">(</mo><mi>n</mi><mi>l</mi><mi>o</mi><mi>g</mi><mi>n</mi><mo stretchy="false">)</mo></math></span></span><script type="math/tex" id="MathJax-Element-11">O(nlogn)</script> =&gt; 各种sort，线段树、树状数组、set/map、heap、拓扑排序、dijkstra+heap、prim+heap、Kruskal、spfa、求凸包、求半平面交、二分、CDQ分治、整体二分、后缀数组、树链剖分、动态树</li><li><span class="MathJax_Preview" style="color: inherit;"></span><span class="MathJax" id="MathJax-Element-12-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>n</mi><mo>&amp;#x2264;</mo><mn>1000000</mn></math>" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-83" role="math" style="width: 6.681em; display: inline-block;"><span style="display: inline-block; position: relative; width: 5.404em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.629em, 1005.404em, 2.79em, -999.997em); top: -2.494em; left: 0.003em;"><span class="mrow" id="MathJax-Span-84"><span class="mi" id="MathJax-Span-85" style="font-family: STIXGeneral-Italic;">n</span><span class="mo" id="MathJax-Span-86" style="font-family: STIXGeneral-Regular; padding-left: 0.293em;">≤</span><span class="mn" id="MathJax-Span-87" style="font-family: STIXGeneral-Regular; padding-left: 0.293em;">1000000</span></span><span style="display: inline-block; width: 0px; height: 2.5em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.211em; border-left-width: 0px; border-left-style: solid; width: 0px; height: 1.075em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>n</mi><mo>≤</mo><mn>1000000</mn></math></span></span><script type="math/tex" id="MathJax-Element-12">n \le 1000000</script> =&gt; <span class="MathJax_Preview" style="color: inherit;"></span><span class="MathJax" id="MathJax-Element-13-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>O</mi><mo stretchy=&quot;false&quot;>(</mo><mi>n</mi><mo stretchy=&quot;false&quot;>)</mo></math>" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-88" role="math" style="width: 2.442em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.977em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.629em, 1001.919em, 2.848em, -999.997em); top: -2.494em; left: 0.003em;"><span class="mrow" id="MathJax-Span-89"><span class="mi" id="MathJax-Span-90" style="font-family: STIXGeneral-Italic;">O</span><span class="mo" id="MathJax-Span-91" style="font-family: STIXGeneral-Regular;">(</span><span class="mi" id="MathJax-Span-92" style="font-family: STIXGeneral-Italic;">n</span><span class="mo" id="MathJax-Span-93" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.5em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.282em; border-left-width: 0px; border-left-style: solid; width: 0px; height: 1.218em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>O</mi><mo stretchy="false">(</mo><mi>n</mi><mo stretchy="false">)</mo></math></span></span><script type="math/tex" id="MathJax-Element-13">O(n)</script>, 以及常数较小的 <span class="MathJax_Preview" style="color: inherit;"></span><span class="MathJax" id="MathJax-Element-14-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>O</mi><mo stretchy=&quot;false&quot;>(</mo><mi>n</mi><mi>l</mi><mi>o</mi><mi>g</mi><mi>n</mi><mo stretchy=&quot;false&quot;>)</mo></math>" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-94" role="math" style="width: 4.649em; display: inline-block;"><span style="display: inline-block; position: relative; width: 3.778em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.629em, 1003.72em, 2.907em, -999.997em); top: -2.494em; left: 0.003em;"><span class="mrow" id="MathJax-Span-95"><span class="mi" id="MathJax-Span-96" style="font-family: STIXGeneral-Italic;">O</span><span class="mo" id="MathJax-Span-97" style="font-family: STIXGeneral-Regular;">(</span><span class="mi" id="MathJax-Span-98" style="font-family: STIXGeneral-Italic;">n</span><span class="mi" id="MathJax-Span-99" style="font-family: STIXGeneral-Italic;">l<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mi" id="MathJax-Span-100" style="font-family: STIXGeneral-Italic;">o</span><span class="mi" id="MathJax-Span-101" style="font-family: STIXGeneral-Italic;">g</span><span class="mi" id="MathJax-Span-102" style="font-family: STIXGeneral-Italic;">n</span><span class="mo" id="MathJax-Span-103" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.5em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.354em; border-left-width: 0px; border-left-style: solid; width: 0px; height: 1.218em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>O</mi><mo stretchy="false">(</mo><mi>n</mi><mi>l</mi><mi>o</mi><mi>g</mi><mi>n</mi><mo stretchy="false">)</mo></math></span></span><script type="math/tex" id="MathJax-Element-14">O(nlogn)</script> 算法 =&gt; 单调队列、 hash、双指针扫描、并查集，kmp、AC自动机，常数比较小的 <span class="MathJax_Preview" style="color: inherit;"></span><span class="MathJax" id="MathJax-Element-15-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>O</mi><mo stretchy=&quot;false&quot;>(</mo><mi>n</mi><mi>l</mi><mi>o</mi><mi>g</mi><mi>n</mi><mo stretchy=&quot;false&quot;>)</mo></math>" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-104" role="math" style="width: 4.649em; display: inline-block;"><span style="display: inline-block; position: relative; width: 3.778em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.629em, 1003.72em, 2.907em, -999.997em); top: -2.494em; left: 0.003em;"><span class="mrow" id="MathJax-Span-105"><span class="mi" id="MathJax-Span-106" style="font-family: STIXGeneral-Italic;">O</span><span class="mo" id="MathJax-Span-107" style="font-family: STIXGeneral-Regular;">(</span><span class="mi" id="MathJax-Span-108" style="font-family: STIXGeneral-Italic;">n</span><span class="mi" id="MathJax-Span-109" style="font-family: STIXGeneral-Italic;">l<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mi" id="MathJax-Span-110" style="font-family: STIXGeneral-Italic;">o</span><span class="mi" id="MathJax-Span-111" style="font-family: STIXGeneral-Italic;">g</span><span class="mi" id="MathJax-Span-112" style="font-family: STIXGeneral-Italic;">n</span><span class="mo" id="MathJax-Span-113" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.5em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.354em; border-left-width: 0px; border-left-style: solid; width: 0px; height: 1.218em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>O</mi><mo stretchy="false">(</mo><mi>n</mi><mi>l</mi><mi>o</mi><mi>g</mi><mi>n</mi><mo stretchy="false">)</mo></math></span></span><script type="math/tex" id="MathJax-Element-15">O(nlogn)</script> 的做法：sort、树状数组、heap、dijkstra、spfa</li><li><span class="MathJax_Preview" style="color: inherit;"></span><span class="MathJax" id="MathJax-Element-16-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>n</mi><mo>&amp;#x2264;</mo><mn>10000000</mn></math>" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-114" role="math" style="width: 7.32em; display: inline-block;"><span style="display: inline-block; position: relative; width: 5.926em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.629em, 1005.926em, 2.79em, -999.997em); top: -2.494em; left: 0.003em;"><span class="mrow" id="MathJax-Span-115"><span class="mi" id="MathJax-Span-116" style="font-family: STIXGeneral-Italic;">n</span><span class="mo" id="MathJax-Span-117" style="font-family: STIXGeneral-Regular; padding-left: 0.293em;">≤</span><span class="mn" id="MathJax-Span-118" style="font-family: STIXGeneral-Regular; padding-left: 0.293em;">10000000</span></span><span style="display: inline-block; width: 0px; height: 2.5em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.211em; border-left-width: 0px; border-left-style: solid; width: 0px; height: 1.075em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>n</mi><mo>≤</mo><mn>10000000</mn></math></span></span><script type="math/tex" id="MathJax-Element-16">n \le 10000000</script> =&gt; <span class="MathJax_Preview" style="color: inherit;"></span><span class="MathJax" id="MathJax-Element-17-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>O</mi><mo stretchy=&quot;false&quot;>(</mo><mi>n</mi><mo stretchy=&quot;false&quot;>)</mo></math>" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-119" role="math" style="width: 2.442em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.977em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.629em, 1001.919em, 2.848em, -999.997em); top: -2.494em; left: 0.003em;"><span class="mrow" id="MathJax-Span-120"><span class="mi" id="MathJax-Span-121" style="font-family: STIXGeneral-Italic;">O</span><span class="mo" id="MathJax-Span-122" style="font-family: STIXGeneral-Regular;">(</span><span class="mi" id="MathJax-Span-123" style="font-family: STIXGeneral-Italic;">n</span><span class="mo" id="MathJax-Span-124" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.5em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.282em; border-left-width: 0px; border-left-style: solid; width: 0px; height: 1.218em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>O</mi><mo stretchy="false">(</mo><mi>n</mi><mo stretchy="false">)</mo></math></span></span><script type="math/tex" id="MathJax-Element-17">O(n)</script>，双指针扫描、kmp、AC自动机、线性筛素数</li><li><span class="MathJax_Preview" style="color: inherit;"></span><span class="MathJax" id="MathJax-Element-18-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>n</mi><mo>&amp;#x2264;</mo><msup><mn>10</mn><mn>9</mn></msup></math>" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-125" role="math" style="width: 4.01em; display: inline-block;"><span style="display: inline-block; position: relative; width: 3.255em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.455em, 1003.255em, 2.79em, -999.997em); top: -2.494em; left: 0.003em;"><span class="mrow" id="MathJax-Span-126"><span class="mi" id="MathJax-Span-127" style="font-family: STIXGeneral-Italic;">n</span><span class="mo" id="MathJax-Span-128" style="font-family: STIXGeneral-Regular; padding-left: 0.293em;">≤</span><span class="msubsup" id="MathJax-Span-129" style="padding-left: 0.293em;"><span style="display: inline-block; position: relative; width: 1.455em; height: 0px;"><span style="position: absolute; clip: rect(3.139em, 1000.99em, 4.184em, -999.997em); top: -4.004em; left: 0.003em;"><span class="mn" id="MathJax-Span-130" style="font-family: STIXGeneral-Regular;">10</span><span style="display: inline-block; width: 0px; height: 4.01em;"></span></span><span style="position: absolute; top: -4.411em; left: 0.99em;"><span class="mn" id="MathJax-Span-131" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">9</span><span style="display: inline-block; width: 0px; height: 4.01em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.5em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.211em; border-left-width: 0px; border-left-style: solid; width: 0px; height: 1.361em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>n</mi><mo>≤</mo><msup><mn>10</mn><mn>9</mn></msup></math></span></span><script type="math/tex" id="MathJax-Element-18">n \le 10^9</script> =&gt; <span class="MathJax_Preview" style="color: inherit;"></span><span class="MathJax" id="MathJax-Element-19-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>O</mi><mo stretchy=&quot;false&quot;>(</mo><msqrt><mi>n</mi></msqrt><mo stretchy=&quot;false&quot;>)</mo></math>" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-132" role="math" style="width: 3.313em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.674em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.629em, 1002.616em, 2.907em, -999.997em); top: -2.494em; left: 0.003em;"><span class="mrow" id="MathJax-Span-133"><span class="mi" id="MathJax-Span-134" style="font-family: STIXGeneral-Italic;">O</span><span class="mo" id="MathJax-Span-135" style="font-family: STIXGeneral-Regular;">(</span><span class="msqrt" id="MathJax-Span-136"><span style="display: inline-block; position: relative; width: 1.222em; height: 0px;"><span style="position: absolute; clip: rect(3.371em, 1000.467em, 4.184em, -999.997em); top: -4.004em; left: 0.758em;"><span class="mrow" id="MathJax-Span-137"><span class="mi" id="MathJax-Span-138" style="font-family: STIXGeneral-Italic;">n</span></span><span style="display: inline-block; width: 0px; height: 4.01em;"></span></span><span style="position: absolute; clip: rect(3.023em, 1000.526em, 3.429em, -999.997em); top: -3.888em; left: 0.758em;"><span style="font-family: STIXGeneral-Regular;">‾</span><span style="display: inline-block; width: 0px; height: 4.01em;"></span></span><span style="position: absolute; clip: rect(2.907em, 1000.758em, 4.184em, -999.997em); top: -3.772em; left: 0.003em;"><span style="font-family: STIXVariants;">√</span><span style="display: inline-block; width: 0px; height: 4.01em;"></span></span></span></span><span class="mo" id="MathJax-Span-139" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.5em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.354em; border-left-width: 0px; border-left-style: solid; width: 0px; height: 1.361em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>O</mi><mo stretchy="false">(</mo><msqrt><mi>n</mi></msqrt><mo stretchy="false">)</mo></math></span></span><script type="math/tex" id="MathJax-Element-19">O(\sqrt n)</script>，判断质数</li><li><span class="MathJax_Preview" style="color: inherit;"></span><span class="MathJax" id="MathJax-Element-20-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>n</mi><mo>&amp;#x2264;</mo><msup><mn>10</mn><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mn>18</mn></mrow></msup></math>" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-140" role="math" style="width: 4.474em; display: inline-block;"><span style="display: inline-block; position: relative; width: 3.603em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.455em, 1003.603em, 2.79em, -999.997em); top: -2.494em; left: 0.003em;"><span class="mrow" id="MathJax-Span-141"><span class="mi" id="MathJax-Span-142" style="font-family: STIXGeneral-Italic;">n</span><span class="mo" id="MathJax-Span-143" style="font-family: STIXGeneral-Regular; padding-left: 0.293em;">≤</span><span class="msubsup" id="MathJax-Span-144" style="padding-left: 0.293em;"><span style="display: inline-block; position: relative; width: 1.803em; height: 0px;"><span style="position: absolute; clip: rect(3.139em, 1000.99em, 4.184em, -999.997em); top: -4.004em; left: 0.003em;"><span class="mn" id="MathJax-Span-145" style="font-family: STIXGeneral-Regular;">10</span><span style="display: inline-block; width: 0px; height: 4.01em;"></span></span><span style="position: absolute; top: -4.411em; left: 0.99em;"><span class="texatom" id="MathJax-Span-146"><span class="mrow" id="MathJax-Span-147"><span class="mn" id="MathJax-Span-148" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">18</span></span></span><span style="display: inline-block; width: 0px; height: 4.01em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.5em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.211em; border-left-width: 0px; border-left-style: solid; width: 0px; height: 1.361em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>n</mi><mo>≤</mo><msup><mn>10</mn><mrow class="MJX-TeXAtom-ORD"><mn>18</mn></mrow></msup></math></span></span><script type="math/tex" id="MathJax-Element-20">n \le 10^{18}</script> =&gt; <span class="MathJax_Preview" style="color: inherit;"></span><span class="MathJax" id="MathJax-Element-21-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>O</mi><mo stretchy=&quot;false&quot;>(</mo><mi>l</mi><mi>o</mi><mi>g</mi><mi>n</mi><mo stretchy=&quot;false&quot;>)</mo></math>" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-149" role="math" style="width: 4.01em; display: inline-block;"><span style="display: inline-block; position: relative; width: 3.255em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.629em, 1003.197em, 2.907em, -999.997em); top: -2.494em; left: 0.003em;"><span class="mrow" id="MathJax-Span-150"><span class="mi" id="MathJax-Span-151" style="font-family: STIXGeneral-Italic;">O</span><span class="mo" id="MathJax-Span-152" style="font-family: STIXGeneral-Regular;">(</span><span class="mi" id="MathJax-Span-153" style="font-family: STIXGeneral-Italic;">l<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mi" id="MathJax-Span-154" style="font-family: STIXGeneral-Italic;">o</span><span class="mi" id="MathJax-Span-155" style="font-family: STIXGeneral-Italic;">g</span><span class="mi" id="MathJax-Span-156" style="font-family: STIXGeneral-Italic;">n</span><span class="mo" id="MathJax-Span-157" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.5em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.354em; border-left-width: 0px; border-left-style: solid; width: 0px; height: 1.218em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>O</mi><mo stretchy="false">(</mo><mi>l</mi><mi>o</mi><mi>g</mi><mi>n</mi><mo stretchy="false">)</mo></math></span></span><script type="math/tex" id="MathJax-Element-21">O(logn)</script>，最大公约数，快速幂，数位DP</li><li><span class="MathJax_Preview" style="color: inherit;"></span><span class="MathJax" id="MathJax-Element-22-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>n</mi><mo>&amp;#x2264;</mo><msup><mn>10</mn><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mn>1000</mn></mrow></msup></math>" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-158" role="math" style="width: 5.287em; display: inline-block;"><span style="display: inline-block; position: relative; width: 4.3em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.455em, 1004.3em, 2.79em, -999.997em); top: -2.494em; left: 0.003em;"><span class="mrow" id="MathJax-Span-159"><span class="mi" id="MathJax-Span-160" style="font-family: STIXGeneral-Italic;">n</span><span class="mo" id="MathJax-Span-161" style="font-family: STIXGeneral-Regular; padding-left: 0.293em;">≤</span><span class="msubsup" id="MathJax-Span-162" style="padding-left: 0.293em;"><span style="display: inline-block; position: relative; width: 2.5em; height: 0px;"><span style="position: absolute; clip: rect(3.139em, 1000.99em, 4.184em, -999.997em); top: -4.004em; left: 0.003em;"><span class="mn" id="MathJax-Span-163" style="font-family: STIXGeneral-Regular;">10</span><span style="display: inline-block; width: 0px; height: 4.01em;"></span></span><span style="position: absolute; top: -4.411em; left: 0.99em;"><span class="texatom" id="MathJax-Span-164"><span class="mrow" id="MathJax-Span-165"><span class="mn" id="MathJax-Span-166" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">1000</span></span></span><span style="display: inline-block; width: 0px; height: 4.01em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.5em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.211em; border-left-width: 0px; border-left-style: solid; width: 0px; height: 1.361em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>n</mi><mo>≤</mo><msup><mn>10</mn><mrow class="MJX-TeXAtom-ORD"><mn>1000</mn></mrow></msup></math></span></span><script type="math/tex" id="MathJax-Element-22">n \le 10^{1000}</script> =&gt; <span class="MathJax_Preview" style="color: inherit;"></span><span class="MathJax" id="MathJax-Element-23-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>O</mi><mo stretchy=&quot;false&quot;>(</mo><mo stretchy=&quot;false&quot;>(</mo><mi>l</mi><mi>o</mi><mi>g</mi><mi>n</mi><msup><mo stretchy=&quot;false&quot;>)</mo><mn>2</mn></msup><mo stretchy=&quot;false&quot;>)</mo></math>" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-167" role="math" style="width: 5.404em; display: inline-block;"><span style="display: inline-block; position: relative; width: 4.358em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.513em, 1004.3em, 2.907em, -999.997em); top: -2.494em; left: 0.003em;"><span class="mrow" id="MathJax-Span-168"><span class="mi" id="MathJax-Span-169" style="font-family: STIXGeneral-Italic;">O</span><span class="mo" id="MathJax-Span-170" style="font-family: STIXGeneral-Regular;">(</span><span class="mo" id="MathJax-Span-171" style="font-family: STIXGeneral-Regular;">(</span><span class="mi" id="MathJax-Span-172" style="font-family: STIXGeneral-Italic;">l<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mi" id="MathJax-Span-173" style="font-family: STIXGeneral-Italic;">o</span><span class="mi" id="MathJax-Span-174" style="font-family: STIXGeneral-Italic;">g</span><span class="mi" id="MathJax-Span-175" style="font-family: STIXGeneral-Italic;">n</span><span class="msubsup" id="MathJax-Span-176"><span style="display: inline-block; position: relative; width: 0.758em; height: 0px;"><span style="position: absolute; clip: rect(3.139em, 1000.293em, 4.358em, -999.997em); top: -4.004em; left: 0.003em;"><span class="mo" id="MathJax-Span-177" style="font-family: STIXGeneral-Regular;">)</span><span style="display: inline-block; width: 0px; height: 4.01em;"></span></span><span style="position: absolute; top: -4.352em; left: 0.351em;"><span class="mn" id="MathJax-Span-178" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">2</span><span style="display: inline-block; width: 0px; height: 4.01em;"></span></span></span></span><span class="mo" id="MathJax-Span-179" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.5em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.354em; border-left-width: 0px; border-left-style: solid; width: 0px; height: 1.432em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>O</mi><mo stretchy="false">(</mo><mo stretchy="false">(</mo><mi>l</mi><mi>o</mi><mi>g</mi><mi>n</mi><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mo stretchy="false">)</mo></math></span></span><script type="math/tex" id="MathJax-Element-23">O((logn)^2)</script>，高精度加减乘除</li><li><span class="MathJax_Preview" style="color: inherit;"></span><span class="MathJax" id="MathJax-Element-24-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>n</mi><mo>&amp;#x2264;</mo><msup><mn>10</mn><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mn>100000</mn></mrow></msup></math>" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-180" role="math" style="width: 6.159em; display: inline-block;"><span style="display: inline-block; position: relative; width: 4.997em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.455em, 1004.997em, 2.79em, -999.997em); top: -2.494em; left: 0.003em;"><span class="mrow" id="MathJax-Span-181"><span class="mi" id="MathJax-Span-182" style="font-family: STIXGeneral-Italic;">n</span><span class="mo" id="MathJax-Span-183" style="font-family: STIXGeneral-Regular; padding-left: 0.293em;">≤</span><span class="msubsup" id="MathJax-Span-184" style="padding-left: 0.293em;"><span style="display: inline-block; position: relative; width: 3.197em; height: 0px;"><span style="position: absolute; clip: rect(3.139em, 1000.99em, 4.184em, -999.997em); top: -4.004em; left: 0.003em;"><span class="mn" id="MathJax-Span-185" style="font-family: STIXGeneral-Regular;">10</span><span style="display: inline-block; width: 0px; height: 4.01em;"></span></span><span style="position: absolute; top: -4.411em; left: 0.99em;"><span class="texatom" id="MathJax-Span-186"><span class="mrow" id="MathJax-Span-187"><span class="mn" id="MathJax-Span-188" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">100000</span></span></span><span style="display: inline-block; width: 0px; height: 4.01em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.5em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.211em; border-left-width: 0px; border-left-style: solid; width: 0px; height: 1.361em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>n</mi><mo>≤</mo><msup><mn>10</mn><mrow class="MJX-TeXAtom-ORD"><mn>100000</mn></mrow></msup></math></span></span><script type="math/tex" id="MathJax-Element-24">n \le 10^{100000}</script> =&gt; <span class="MathJax_Preview" style="color: inherit;"></span><span class="MathJax" id="MathJax-Element-25-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>O</mi><mo stretchy=&quot;false&quot;>(</mo><mi>l</mi><mi>o</mi><mi>g</mi><mi>k</mi><mo>&amp;#x00D7;</mo><mi>l</mi><mi>o</mi><mi>g</mi><mi>l</mi><mi>o</mi><mi>g</mi><mi>k</mi><mo stretchy=&quot;false&quot;>)</mo><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo>&amp;#xFF0C;</mo></mrow><mi>k</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo>&amp;#x8868;</mo></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo>&amp;#x793A;</mo></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo>&amp;#x4F4D;</mo></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo>&amp;#x6570;</mo></mrow></math>" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-189" role="math" style="width: 14.521em; display: inline-block;"><span style="display: inline-block; position: relative; width: 11.792em; height: 0px; font-size: 123%;"><span style="position: absolute; clip: rect(1.513em, 1011.792em, 2.907em, -999.997em); top: -2.494em; left: 0.003em;"><span class="mrow" id="MathJax-Span-190"><span class="mi" id="MathJax-Span-191" style="font-family: STIXGeneral-Italic;">O</span><span class="mo" id="MathJax-Span-192" style="font-family: STIXGeneral-Regular;">(</span><span class="mi" id="MathJax-Span-193" style="font-family: STIXGeneral-Italic;">l<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mi" id="MathJax-Span-194" style="font-family: STIXGeneral-Italic;">o</span><span class="mi" id="MathJax-Span-195" style="font-family: STIXGeneral-Italic;">g</span><span class="mi" id="MathJax-Span-196" style="font-family: STIXGeneral-Italic;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mo" id="MathJax-Span-197" style="font-family: STIXGeneral-Regular; padding-left: 0.235em;">×</span><span class="mi" id="MathJax-Span-198" style="font-family: STIXGeneral-Italic; padding-left: 0.235em;">l<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mi" id="MathJax-Span-199" style="font-family: STIXGeneral-Italic;">o</span><span class="mi" id="MathJax-Span-200" style="font-family: STIXGeneral-Italic;">g</span><span class="mi" id="MathJax-Span-201" style="font-family: STIXGeneral-Italic;">l<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mi" id="MathJax-Span-202" style="font-family: STIXGeneral-Italic;">o</span><span class="mi" id="MathJax-Span-203" style="font-family: STIXGeneral-Italic;">g</span><span class="mi" id="MathJax-Span-204" style="font-family: STIXGeneral-Italic;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mo" id="MathJax-Span-205" style="font-family: STIXGeneral-Regular;">)</span><span class="texatom" id="MathJax-Span-206"><span class="mrow" id="MathJax-Span-207"><span class="mo" id="MathJax-Span-208"><span style="font-family: STIXGeneral, &quot;Arial Unicode MS&quot;, serif; font-size: 81%; font-style: normal; font-weight: normal;">，</span></span></span></span><span class="mi" id="MathJax-Span-209" style="font-family: STIXGeneral-Italic;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="texatom" id="MathJax-Span-210"><span class="mrow" id="MathJax-Span-211"><span class="mo" id="MathJax-Span-212"><span style="font-family: STIXGeneral, &quot;Arial Unicode MS&quot;, serif; font-size: 81%; font-style: normal; font-weight: normal;">表</span></span></span></span><span class="texatom" id="MathJax-Span-213"><span class="mrow" id="MathJax-Span-214"><span class="mo" id="MathJax-Span-215"><span style="font-family: STIXGeneral, &quot;Arial Unicode MS&quot;, serif; font-size: 81%; font-style: normal; font-weight: normal;">示</span></span></span></span><span class="texatom" id="MathJax-Span-216"><span class="mrow" id="MathJax-Span-217"><span class="mo" id="MathJax-Span-218"><span style="font-family: STIXGeneral, &quot;Arial Unicode MS&quot;, serif; font-size: 81%; font-style: normal; font-weight: normal;">位</span></span></span></span><span class="texatom" id="MathJax-Span-219"><span class="mrow" id="MathJax-Span-220"><span class="mo" id="MathJax-Span-221"><span style="font-family: STIXGeneral, &quot;Arial Unicode MS&quot;, serif; font-size: 81%; font-style: normal; font-weight: normal;">数</span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.5em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.354em; border-left-width: 0px; border-left-style: solid; width: 0px; height: 1.361em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>O</mi><mo stretchy="false">(</mo><mi>l</mi><mi>o</mi><mi>g</mi><mi>k</mi><mo>×</mo><mi>l</mi><mi>o</mi><mi>g</mi><mi>l</mi><mi>o</mi><mi>g</mi><mi>k</mi><mo stretchy="false">)</mo><mrow class="MJX-TeXAtom-ORD"><mo>，</mo></mrow><mi>k</mi><mrow class="MJX-TeXAtom-ORD"><mo>表</mo></mrow><mrow class="MJX-TeXAtom-ORD"><mo>示</mo></mrow><mrow class="MJX-TeXAtom-ORD"><mo>位</mo></mrow><mrow class="MJX-TeXAtom-ORD"><mo>数</mo></mrow></math></span></span><script type="math/tex" id="MathJax-Element-25">O(logk \times loglogk)，k表示位数</script>，高精度加减、FFT/NTT</li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;优化&quot;&gt;&lt;a href=&quot;#优化&quot; class=&quot;headerlink&quot; title=&quot;优化&quot;&gt;&lt;/a&gt;优化&lt;/h1&gt;&lt;pre&gt;&lt;code class=&quot;c++&quot;&gt;#pragma GCC optimize (&amp;quot;O1&amp;quot;)
#pragma comm</summary>
      
    
    
    
    <category term="程序设计" scheme="https://liting1024.github.io/categories/%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1/"/>
    
    
    <category term="ACM" scheme="https://liting1024.github.io/tags/ACM/"/>
    
  </entry>
  
  <entry>
    <title>Pytorch</title>
    <link href="https://liting1024.github.io/2021/06/05/Pytorch/"/>
    <id>https://liting1024.github.io/2021/06/05/Pytorch/</id>
    <published>2021-06-05T09:20:54.000Z</published>
    <updated>2021-06-05T09:20:54.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="加载数据类"><a href="#加载数据类" class="headerlink" title="加载数据类"></a>加载数据类</h2><p>获取数据和其对应的label值、总共有多少数据</p><pre><code>from torch.utils.data import Dataset</code></pre><h2 id="GPU训练"><a href="#GPU训练" class="headerlink" title="GPU训练"></a>GPU训练</h2><p>将输入、输出、模型、损失函数都移到cuda上</p><h3 id="设置环境变量"><a href="#设置环境变量" class="headerlink" title="设置环境变量"></a>设置环境变量</h3><p>必须在import torch之前键入以下代码</p><pre><code class="python">import osos.environ[&#39;CUDA_VISIBLE_DEVICES&#39;] = &#39;3&#39;</code></pre><p>然后都移动到cuda上</p><pre><code class="python">x = x.cuda()y = y.cuda()model = model.cuda()loss_function = loss_function.cuda()</code></pre><h3 id="使用todevice"><a href="#使用todevice" class="headerlink" title="使用todevice"></a>使用todevice</h3><pre><code class="python">device = torch.device(&quot;cuda:0&quot; if torch.cuda.is_available() else &quot;cpu&quot;)model.to(device)</code></pre><h2 id="Tensorboard"><a href="#Tensorboard" class="headerlink" title="Tensorboard"></a>Tensorboard</h2><pre><code class="python">from torch.utils.tensorboard import SummaryWriterwriter = SummaryWriter(&quot;logs&quot;)# y = x+1for i in range(100):    writer.add_scalar(&quot;y=x&quot;,i+1,i)writer.close()</code></pre><p>生成一个logs文件夹，终端进入logs文件夹的同级目录，输入</p><pre><code>tensroboard --logdir=logs --port 6007</code></pre><h2 id="计算模型体量"><a href="#计算模型体量" class="headerlink" title="计算模型体量"></a>计算模型体量</h2><h2 id="进度条"><a href="#进度条" class="headerlink" title="进度条"></a>进度条</h2><pre><code class="python">from tqdm import tqdm  # 直接import tqdm会报错loop = tqdm(enumerate(train_dataloader), total=train_data_size)for step, data in loop:  pass</code></pre><h2 id="保存模型"><a href="#保存模型" class="headerlink" title="保存模型"></a>保存模型</h2><p>包含GPU tensors的模型，自动load到GPU上</p><p>保存整个模型</p><pre><code class="python">## 保存模型torch.save(model, MODEL_PATH)## 读取模型model = torch.load(MODEL_PATH)</code></pre><p>只保存参数</p><pre><code class="python">## 保存模型torch.save(model.state_dict(), MODEL_PATH)torch.save(optimizer.state_dict(), OPTIM_PATH)## 读取模型if os.path.exists(MODEL_PATH)    model.load_state_dict(torch.load(MODEL_PATH))if os.path.exists(OPTIM_PATH)  optimizer.load_state_dict(optimizer.state_dict(), OPTIM_PATH)</code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;加载数据类&quot;&gt;&lt;a href=&quot;#加载数据类&quot; class=&quot;headerlink&quot; title=&quot;加载数据类&quot;&gt;&lt;/a&gt;加载数据类&lt;/h2&gt;&lt;p&gt;获取数据和其对应的label值、总共有多少数据&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;from torch.utils.da</summary>
      
    
    
    
    <category term="机器学习" scheme="https://liting1024.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
  </entry>
  
  <entry>
    <title>Linux常见问题</title>
    <link href="https://liting1024.github.io/2021/06/05/Linux%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/"/>
    <id>https://liting1024.github.io/2021/06/05/Linux%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/</id>
    <published>2021-06-05T08:25:55.000Z</published>
    <updated>2021-06-05T08:25:55.000Z</updated>
    
    <content type="html"><![CDATA[<p>[TOC]</p><h2 id="进程"><a href="#进程" class="headerlink" title="进程"></a>进程</h2><pre><code class="bash">ll /proc/&lt;pid&gt;kill -9 &lt;pid&gt;</code></pre><h2 id="网络测试"><a href="#网络测试" class="headerlink" title="网络测试"></a>网络测试</h2><pre><code class="bash">curl &lt;url&gt;ping &lt;ip&gt;ping -i &lt;ip&gt; &lt;port&gt;lsof -i &lt;port&gt;</code></pre><h2 id="pip"><a href="#pip" class="headerlink" title="pip"></a>pip</h2><pre><code class="bash">pip show 包名pip install -i https://pypi.tuna.tsinghua.edu.cn/simple 包名</code></pre><h2 id="bash脚本"><a href="#bash脚本" class="headerlink" title="bash脚本"></a>bash脚本</h2><p>等号两边无空格</p><h3 id="bashrc和-bash-profile的区别"><a href="#bashrc和-bash-profile的区别" class="headerlink" title=".bashrc和.bash_profile的区别"></a>.bashrc和.bash_profile的区别</h3><p>.bash_profile是在登陆的时候才会执行的，也叫.bash_login，在命令行再运行bash命令的时候不执行这个文件里面的命令。</p><p>.bashrc恰好相反，是在执行子shell(sub-shell)的时候才会执行里面的命令，可以通过source ~/.bashrc执行。</p><p>在.bash_profile中加入下面的代码，可以在登录时执行.bashrc里的代码，注意空格</p><pre><code class="bash">if  [ -f ~/.bashrc ]; then        . ~/.bashrc        echo &quot;.bash_profile call .bashrc&quot;fi</code></pre><h2 id="安装pytorch"><a href="#安装pytorch" class="headerlink" title="安装pytorch"></a>安装pytorch</h2><p>正常清华源为<a href="https://mirror.tuna.tsinghua.edu.cn/help/anaconda/" target="_blank" rel="noopener">anaconda | 镜像站使用帮助 | 清华大学开源软件镜像站 | Tsinghua Open Source Mirror</a>，其中不包含pytorch</p><p>添加pytorch清华源如下</p><pre><code class="bash">  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/</code></pre><h2 id="vim无法保存"><a href="#vim无法保存" class="headerlink" title="vim无法保存"></a>vim无法保存</h2><p>1、由于权限不够，即未使用sudo</p><p>2、用vim打开了一个目录，可以继续选择进入文件，打开文件后再退出</p><p>qa!可以退出，不能保存</p><h2 id="CUDA命令"><a href="#CUDA命令" class="headerlink" title="CUDA命令"></a>CUDA命令</h2><pre><code class="bash">nvidia-smi</code></pre><table><thead><tr><th align="center">Perf</th><th align="center">Persistence-M</th><th align="center">Compute M</th><th>Disp.A</th><th>Uncorr. ECC</th><th>Compute M</th></tr></thead><tbody><tr><td align="center">性能模式（P0到P12）</td><td align="center">持续模式</td><td align="center">计算模式</td><td>GPU的显示是否初始化</td><td>错误检查与纠正</td><td>计算模式</td></tr></tbody></table><p>查看cuda版本 /usr/local/cuda/version.txt</p><h2 id="查看配置和使用状态"><a href="#查看配置和使用状态" class="headerlink" title="查看配置和使用状态"></a>查看配置和使用状态</h2><pre><code class="bash">nvidia-smitop 监视进程watch nvidia-smi 持续查看free -m 查看存储空间</code></pre><h2 id="终端复用"><a href="#终端复用" class="headerlink" title="终端复用"></a>终端复用</h2><h3 id="screen"><a href="#screen" class="headerlink" title="screen"></a>screen</h3><pre><code class="bash">yum install -y screen  # 安装screen -S 窗口名称  # 开启新的Ctrl+A+C  # 在当前窗口开启新的窗口Ctrl+A+D  # 非中断detached退出按住Ctrl，依次再按a,d 可重连按住Ctrl和a,放开a去按d 不可重连Ctrl+A+K  # 杀掉当前screen -r 窗口名称  # 恢复重连exit  # 退出窗口screen -X -S id号  # 杀死screen -wipe 　# 检查目前所有的screen作业，并删除已经无法使用的screen作业。</code></pre><h3 id="Tmux"><a href="#Tmux" class="headerlink" title="Tmux"></a>Tmux</h3><p>启动tmux后，底部[0]表示第0个tmux伪窗口，再启动一个tmux伪窗口为[1]。</p><p>安装</p><pre><code class="bash"># Ubuntu 或 Debian$ sudo apt-get install tmux# CentOS$ sudo yum install tmux</code></pre><p>常用命令</p><pre><code class="bash">tmux lstmux attach -t 0  # 重连窗口tmux detach  # 分离窗口Ctrl+d或exit  # 退出Tmux窗口tmux new -s &lt;session-name&gt;  # 新建有名字的窗口tmux  # 用编号自动命名窗口tmux kill-session -t &lt;session-name&gt;</code></pre><h2 id="conda"><a href="#conda" class="headerlink" title="conda"></a>conda</h2><pre><code class="bash">conda create -n 环境名 python=版本号conda deactivateconda info -e 或者 conda env listconda remove -n 环境名 --all</code></pre><h2 id="Jupyter"><a href="#Jupyter" class="headerlink" title="Jupyter"></a>Jupyter</h2><p>由于服务器上必须</p><p>运行jupyter并强制指定执行程序内核为python</p><pre><code>jupyter nbconvert --to notebook --execute --inplace 7.21CIFAR-10添加Dropout.ipynb --ExecutePreprocessor.kernel_name=python</code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;[TOC]&lt;/p&gt;
&lt;h2 id=&quot;进程&quot;&gt;&lt;a href=&quot;#进程&quot; class=&quot;headerlink&quot; title=&quot;进程&quot;&gt;&lt;/a&gt;进程&lt;/h2&gt;&lt;pre&gt;&lt;code class=&quot;bash&quot;&gt;ll /proc/&amp;lt;pid&amp;gt;

kill -9 &amp;lt;pi</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>深度学习Review【三】序列、RNN、LSTM（GRU）、DRNN</title>
    <link href="https://liting1024.github.io/2021/05/28/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0Review%E3%80%90%E4%B8%89%E3%80%91%E5%BA%8F%E5%88%97%E3%80%81RNN%E3%80%81LSTM%EF%BC%88GRU%EF%BC%89%E3%80%81DRNN/"/>
    <id>https://liting1024.github.io/2021/05/28/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0Review%E3%80%90%E4%B8%89%E3%80%91%E5%BA%8F%E5%88%97%E3%80%81RNN%E3%80%81LSTM%EF%BC%88GRU%EF%BC%89%E3%80%81DRNN/</id>
    <published>2021-05-28T13:45:31.000Z</published>
    <updated>2021-05-28T13:45:31.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p><a href="https://zh-v2.d2l.ai/chapter_multilayer-perceptrons/mlp-concise.html" target="_blank" rel="noopener">课程地址</a></p></blockquote><h1 id="一、序列模型"><a href="#一、序列模型" class="headerlink" title="一、序列模型"></a>一、序列模型</h1><p>序列数据：实际中很多数据是随着时间变化而变化。</p><p>根据条件概率一直x1到xT的概率可以算出x的概率。<br><img src="https://cdn.jsdelivr.net/gh/liting1024/PicImage/PicgoGithub/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phbWVzU2h1a2Vy,size_16,color_FFFFFF,t_70-20220528215317525.png" alt="在这里插入图片描述"><br>自回归模型：用的数据，预测现在的数据</p><h2 id="马尔科夫假设"><a href="#马尔科夫假设" class="headerlink" title="马尔科夫假设"></a>马尔科夫假设</h2><p>当前数据只和t个过去的数据相关<br><img src="https://cdn.jsdelivr.net/gh/liting1024/PicImage/PicgoGithub/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phbWVzU2h1a2Vy,size_16,color_FFFFFF,t_70-20220528215317506.png" alt="在这里插入图片描述"></p><h2 id="潜变量"><a href="#潜变量" class="headerlink" title="潜变量"></a>潜变量</h2><p>引入潜变量h来表示过去的信息<br>绿色代表不同的潜变量h，每次在改变x后计算新的潜变量h<br><img src="https://cdn.jsdelivr.net/gh/liting1024/PicImage/PicgoGithub/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phbWVzU2h1a2Vy,size_16,color_FFFFFF,t_70-20220528215317616.png" alt="在这里插入图片描述"></p><h1 id="二、RNN-循环神经网络"><a href="#二、RNN-循环神经网络" class="headerlink" title="二、RNN 循环神经网络"></a>二、RNN 循环神经网络</h1><p> 适用于100以内的序列<br> 用当前时刻的输入预测下一时刻的输出，“你好世界”，输出的“好”是由输入的“你”和“好”预测出来的。<br><img src="https://cdn.jsdelivr.net/gh/liting1024/PicImage/PicgoGithub/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phbWVzU2h1a2Vy,size_16,color_FFFFFF,t_70-20220528215317481.png" alt="在这里插入图片描述"><br>W[hx]表示从x到h的权重</p><h2 id="衡量语言模型"><a href="#衡量语言模型" class="headerlink" title="衡量语言模型"></a>衡量语言模型</h2><ul><li>平均交叉熵<ul><li>困惑度：指数（1表示完美，无穷表示垃）</li></ul></li></ul><h2 id="梯度剪裁"><a href="#梯度剪裁" class="headerlink" title="梯度剪裁"></a>梯度剪裁</h2><p>可以防止梯度爆炸，如果梯度长度超过某个值，就拖回到这个值。<br><img src="https://cdn.jsdelivr.net/gh/liting1024/PicImage/PicgoGithub/91b5da51c44f458884862918ed0395fc.png" alt="在这里插入图片描述"></p><h2 id="torch实现"><a href="#torch实现" class="headerlink" title="torch实现"></a>torch实现</h2><pre><code class="python">import torchfrom torch import nnfrom torch.nn import functional as Ffrom d2l import torch as d2lbatch_size, num_steps = 32, 35 #句子长度为35train_iter, vocab = d2l.load_data_time_machine(batch_size, num_steps)#一个具有256个隐藏单元的单隐藏层的循环神经网络层 rnn_layernum_hiddens = 256rnn_layer = rnn.RNN(num_hiddens)rnn_layer.initialize()class RNNModel(nn.Module):    &quot;&quot;&quot;循环神经网络模型。&quot;&quot;&quot;    def __init__(self, rnn_layer, vocab_size, **kwargs):        super(RNNModel, self).__init__(**kwargs)        self.rnn = rnn_layer #不包括输出层        self.vocab_size = vocab_size        self.num_hiddens = self.rnn.hidden_size        # 如果RNN是双向的（之后将介绍），`num_directions`应该是2，否则应该是1。        # 构造输出层        if not self.rnn.bidirectional:            self.num_directions = 1            self.linear = nn.Linear(self.num_hiddens, self.vocab_size)        else:            self.num_directions = 2            self.linear = nn.Linear(self.num_hiddens * 2, self.vocab_size)    def forward(self, inputs, state):        X = F.one_hot(inputs.T.long(), self.vocab_size)        X = X.to(torch.float32)        Y, state = self.rnn(X, state) # 中间隐藏层的Y        # 全连接层首先将`Y`的形状改为(`时间步数`*`批量大小`, `隐藏单元数`)。        # 它的输出形状是 (`时间步数`*`批量大小`, `词表大小`)。        output = self.linear(Y.reshape((-1, Y.shape[-1])))#把时间和批量这两个维度和到一起        return output, state    def begin_state(self, device, batch_size=1):        if not isinstance(self.rnn, nn.LSTM):            # `nn.GRU` 以张量作为隐藏状态            return  torch.zeros((self.num_directions * self.rnn.num_layers,                                 batch_size, self.num_hiddens),                                device=device)        else:            # `nn.LSTM` 以张量作为隐藏状态            return (torch.zeros((                self.num_directions * self.rnn.num_layers,                batch_size, self.num_hiddens), device=device),                    torch.zeros((                        self.num_directions * self.rnn.num_layers,                        batch_size, self.num_hiddens), device=device))def train_ch8(net, train_iter, vocab, lr, num_epochs, device,              use_random_iter=False):    &quot;&quot;&quot;训练模型（定义见第8章）。&quot;&quot;&quot;    loss = nn.CrossEntropyLoss()    animator = d2l.Animator(xlabel=&#39;epoch&#39;, ylabel=&#39;perplexity&#39;,                            legend=[&#39;train&#39;], xlim=[10, num_epochs])    # 初始化    if isinstance(net, nn.Module):        updater = torch.optim.SGD(net.parameters(), lr)    else:        updater = lambda batch_size: d2l.sgd(net.params, lr, batch_size)    predict = lambda prefix: predict_ch8(prefix, 50, net, vocab, device)    # 训练和预测    for epoch in range(num_epochs):        ppl, speed = train_epoch_ch8(            net, train_iter, loss, updater, device, use_random_iter)        if (epoch + 1) % 10 == 0:            print(predict(&#39;time traveller&#39;))            animator.add(epoch + 1, [ppl])    print(f&#39;困惑度 {ppl:.1f}, {speed:.1f} 词元/秒 {str(device)}&#39;)    print(predict(&#39;time traveller&#39;))    print(predict(&#39;traveller&#39;))num_epochs, lr = 500, 1d2l.train_ch8(net, train_iter, vocab, lr, num_epochs, device)</code></pre><h1 id="三、GRU-门控循环单元"><a href="#三、GRU-门控循环单元" class="headerlink" title="三、GRU 门控循环单元"></a>三、GRU 门控循环单元</h1><p>  是LSTM的简化，正常情况下效果差不多。</p><h2 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h2><p>由于并不是每个值都是同等重要的，所以设置更新门（关注的机制）和重置门（遗忘机制）来只记住相关的值（关键字、关键点、切换场景时的帧 ）。  </p><p><img src="https://cdn.jsdelivr.net/gh/liting1024/PicImage/PicgoGithub/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phbWVzU2h1a2Vy,size_16,color_FFFFFF,t_70-20220528215317525-3745997.png" alt="在这里插入图片描述"><br>R和Z本质是用sigmoid对全连接层做激活<br>R（重置门）：0到1之间的数，若为0表示之前的东西全不要<br>Z（更新门）：0到1之间的数，若为1表示不用之前的东西更新<br>改进：多了几个可以计算的权重<br><del>H是候选隐含状态：根据X、R和W、之前的H输出当前候选隐含状态<br>H是隐含状态：根据Z、</del>H、之前的H的值输出新的隐含状态<br><img src="https://cdn.jsdelivr.net/gh/liting1024/PicImage/PicgoGithub/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phbWVzU2h1a2Vy,size_16,color_FFFFFF,t_70-20220528215317628.png" alt="在这里插入图片描述"></p><h2 id="torch实现-1"><a href="#torch实现-1" class="headerlink" title="torch实现"></a>torch实现</h2><pre><code class="python">num_inputs = vocab_sizegru_layer = nn.GRU(num_inputs, num_hiddens)model = d2l.RNNModel(gru_layer, len(vocab))model = model.to(device)d2l.train_ch8(model, train_iter, vocab, lr, num_epochs, device)</code></pre><h1 id="四、LSTM"><a href="#四、LSTM" class="headerlink" title="四、LSTM"></a>四、LSTM</h1><p>先于GRU提出，四套W权重</p><p>遗忘门F：将值收缩为0<br>输入门I：决定是否忽略输入数据<br>输出门O：决定是否使用隐含状态（ 当前的C）<br>候选记忆单元~C：包括了 前一个状态的H（相当于GRU中的 当前状态的H）<br>记忆单元C：C的数值区间比较大，是否使用 之前的C 和 ~C<br>隐含状态H：将C的值稳定在1和-1之间，根据O控制要不要输出<br><img src="https://cdn.jsdelivr.net/gh/liting1024/PicImage/PicgoGithub/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phbWVzU2h1a2Vy,size_16,color_FFFFFF,t_70-20220528215317553.png" alt="在这里插入图片描述"></p><h2 id="torch实现-2"><a href="#torch实现-2" class="headerlink" title="torch实现"></a>torch实现</h2><pre><code class="python">num_inputs = vocab_sizelstm_layer = nn.LSTM(num_inputs, num_hiddens)model = d2l.RNNModel(lstm_layer, len(vocab))model = model.to(device)d2l.train_ch8(model, train_iter, vocab, lr, num_epochs, device)</code></pre><h1 id="五、Deep-RNN-深度循环"><a href="#五、Deep-RNN-深度循环" class="headerlink" title="五、Deep RNN 深度循环"></a>五、Deep RNN 深度循环</h1><p>输入-隐藏层-输出<br>通过增加隐藏层的个数，来加深RNN，获得更多的非线性性，增大可处理的序列长度。<br>后一个隐藏层的输出是上一个隐藏层的输出，同时下一个时刻的输入是上一个时刻的输出。<br><img src="https://cdn.jsdelivr.net/gh/liting1024/PicImage/PicgoGithub/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phbWVzU2h1a2Vy,size_16,color_FFFFFF,t_70-20220528215317501.png" alt="在这里插入图片描述"></p><h2 id="torch实现-3"><a href="#torch实现-3" class="headerlink" title="torch实现"></a>torch实现</h2><pre><code class="python">import torchfrom torch import nnfrom d2l import torch as d2lbatch_size, num_steps = 32, 35train_iter, vocab = d2l.load_data_time_machine(batch_size, num_steps)#num layers是隐藏层的个数vocab_size, num_hiddens, num_layers = len(vocab), 256, 2num_inputs = vocab_sizedevice = d2l.try_gpu()# Pytorch的LSTM不带输出层lstm_layer = nn.LSTM(num_inputs, num_hiddens, num_layers)model = d2l.RNNModel(lstm_layer, len(vocab))model = model.to(device)num_epochs, lr = 500, 2d2l.train_ch8(model, train_iter, vocab, lr, num_epochs, device)</code></pre><h1 id="六、BRNN双向循环网络"><a href="#六、BRNN双向循环网络" class="headerlink" title="六、BRNN双向循环网络"></a>六、BRNN双向循环网络</h1><p>一个词取决于过去和未来的上下文，所以不能用于推测下一个词，只能做完词填空，对一个句子做特征提取，Eg：翻译、改写。</p><p>一个前向RNN隐藏层，一个后向RNN隐藏层，合并（concat）两个隐状态得到输出，两个隐藏层为一组，这两组隐藏层的权重不共享。<br><img src="https://cdn.jsdelivr.net/gh/liting1024/PicImage/PicgoGithub/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phbWVzU2h1a2Vy,size_16,color_FFFFFF,t_70-20220528215317587.png" alt="在这里插入图片描述"></p><h2 id="torch实现-4"><a href="#torch实现-4" class="headerlink" title="torch实现"></a>torch实现</h2><pre><code class="python">import torchfrom torch import nnfrom d2l import torch as d2l# 加载数据batch_size, num_steps, device = 32, 35, d2l.try_gpu()train_iter, vocab = d2l.load_data_time_machine(batch_size, num_steps)# 通过设置&#39;bidirective=True&#39;来定义双向LSTM模型vocab_size, num_hiddens, num_layers = len(vocab), 256, 2num_inputs = vocab_sizelstm_layer = nn.LSTM(num_inputs, num_hiddens, num_layers, bidirectional=True)model = d2l.RNNModel(lstm_layer, len(vocab))model = model.to(device)# 训练模型num_epochs, lr = 500, 1d2l.train_ch8(model, train_iter, vocab, lr, num_epochs, device)</code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&quot;https://zh-v2.d2l.ai/chapter_multilayer-perceptrons/mlp-concise.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;课程地址&lt;/a&gt;&lt;/p&gt;
&lt;</summary>
      
    
    
    
    <category term="机器学习" scheme="https://liting1024.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
  </entry>
  
  <entry>
    <title>深度学习Review【三】序列、RNN、LSTM（GRU）、DRNN</title>
    <link href="https://liting1024.github.io/2021/05/28/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0Review%E3%80%90%E5%9B%9B%E3%80%91%E7%BC%96%E8%A7%A3%E7%A0%81/"/>
    <id>https://liting1024.github.io/2021/05/28/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0Review%E3%80%90%E5%9B%9B%E3%80%91%E7%BC%96%E8%A7%A3%E7%A0%81/</id>
    <published>2021-05-28T13:45:31.000Z</published>
    <updated>2021-05-28T13:45:31.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p><a href="https://zh-v2.d2l.ai/chapter_multilayer-perceptrons/mlp-concise.html" target="_blank" rel="noopener">课程地址</a></p></blockquote><h1 id="一、编码-解码"><a href="#一、编码-解码" class="headerlink" title="一、编码-解码"></a>一、编码-解码</h1><p>编码（训练）：处理输出，把输入编程成中甲你表达形式（特征）<br>解码（预测）：生成输出，把特征解码成输出</p><pre><code class="python">from torch import nnclass Encoder(nn.Module):    &quot;&quot;&quot;编码器-解码器结构的基本编码器接口。&quot;&quot;&quot;    def __init__(self, **kwargs):        super(Encoder, self).__init__(**kwargs)    def forward(self, X, *args):        raise NotImplementedErrorclass Decoder(nn.Module):    &quot;&quot;&quot;编码器-解码器结构的基本解码器接口。&quot;&quot;&quot;    def __init__(self, **kwargs):        super(Decoder, self).__init__(**kwargs)    def init_state(self, enc_outputs, *args):        raise NotImplementedError    def forward(self, X, state):        raise NotImplementedErrorclass EncoderDecoder(nn.Module):    &quot;&quot;&quot;编码器-解码器结构的基类。&quot;&quot;&quot;    def __init__(self, encoder, decoder, **kwargs):        super(EncoderDecoder, self).__init__(**kwargs)        self.encoder = encoder        self.decoder = decoder    def forward(self, enc_X, dec_X, *args):        enc_outputs = self.encoder(enc_X, *args)        dec_state = self.decoder.init_state(enc_outputs, *args)        return self.decoder(dec_X, dec_state)</code></pre><h1 id="二、Seq2seq"><a href="#二、Seq2seq" class="headerlink" title="二、Seq2seq"></a>二、Seq2seq</h1><p><img src="https://cdn.jsdelivr.net/gh/liting1024/PicImage/PicgoGithub/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phbWVzU2h1a2Vy,size_16,color_FFFFFF,t_70-20220528215455572.png" alt="在这里插入图片描述"><br>训练过程，即Encode的过程（一个RNN)是双向的<br>解码器是单向的<br>RNN也不需要定长的序列作为输入输出</p><p><img src="https://cdn.jsdelivr.net/gh/liting1024/PicImage/PicgoGithub/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_Q1NETiBA6IiS5YWL5YS_5LiN5byA6aOe5py6,size_26,color_FFFFFF,t_70,g_se,x_16.png" alt="在这里插入图片描述"><br>把编码器的RNN最后一层的输出放在解码器里，作为初始隐状态 </p><h2 id="torch"><a href="#torch" class="headerlink" title="torch"></a>torch</h2><pre><code class="python">import collectionsimport mathimport torchfrom torch import nnfrom d2l import torch as d2lclass Seq2SeqEncoder(d2l.Encoder):    &quot;&quot;&quot;用于序列到序列学习的循环神经网络编码器Encode&quot;&quot;&quot;    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers,dropout=0, **kwargs):        super(Seq2SeqEncoder, self).__init__(**kwargs)        # 嵌入层        self.embedding = nn.Embedding(vocab_size, embed_size)         #对每个词embedding        self.rnn = nn.GRU(embed_size, num_hiddens, num_layers,                          dropout=dropout)        #numlayers是RNN的层数 numhiddens是隐藏层的层数    def forward(self, X, *args):        # 输出&#39;X&#39;的形状：(`batch_size`, `num_steps`, `embed_size`)        X = self.embedding(X)        # 在循环神经网络模型中，第一个轴对应于时间步，交换batchsize和numstep        X = X.permute(1, 0, 2)        # 如果未提及状态，则默认为0        output, state = self.rnn(X)        # `output`的形状: (`num_steps`, `batch_size`, `num_hiddens`)        # `state[0]`的形状: (`num_layers`, `batch_size`, `num_hiddens`)        return output, stateencoder = Seq2SeqEncoder(vocab_size=10, embed_size=8, num_hiddens=16,                         num_layers=2)encoder.eval()X = torch.zeros((4, 7), dtype=torch.long)output, state = encoder(X)#output和state的形状torch.Size([7, 4, 16]) torch.Size([2, 4, 16])class Seq2SeqDecoder(d2l.Decoder):    &quot;&quot;&quot;用于序列到序列学习的循环神经网络解码器。&quot;&quot;&quot;    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers,                 dropout=0, **kwargs):        super(Seq2SeqDecoder, self).__init__(**kwargs)        self.embedding = nn.Embedding(vocab_size, embed_size)        self.rnn = nn.GRU(embed_size + num_hiddens, num_hiddens, num_layers,                          dropout=dropout)        self.dense = nn.Linear(num_hiddens, vocab_size)        #分类    def init_state(self, enc_outputs, *args):        return enc_outputs[1] #enc_outputs[1]为state    def forward(self, X, state):        # 输出&#39;X&#39;的形状：(`batch_size`, `num_steps`, `embed_size`)        X = self.embedding(X).permute(1, 0, 2)        # 广播`context`，使其具有与`X`相同的`num_steps`        context = state[-1].repeat(X.shape[0], 1, 1)        X_and_context = torch.cat((X, context), 2)        output, state = self.rnn(X_and_context, state)        output = self.dense(output).permute(1, 0, 2)        # `output`的形状: (`batch_size`, `num_steps`, `vocab_size`)        # `state[0]`的形状: (`num_layers`, `batch_size`, `num_hiddens`)        return output, statedecoder = Seq2SeqDecoder(vocab_size=10, embed_size=8, num_hiddens=16,                         num_layers=2)decoder.eval()state = decoder.init_state(encoder(X))output, state = decoder(X, state)# output和state的shape(torch.Size([4, 7, 10]), torch.Size([2, 4, 16]))</code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&quot;https://zh-v2.d2l.ai/chapter_multilayer-perceptrons/mlp-concise.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;课程地址&lt;/a&gt;&lt;/p&gt;
&lt;</summary>
      
    
    
    
    <category term="机器学习" scheme="https://liting1024.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
  </entry>
  
  <entry>
    <title>深度学习Review【二】LeNet、AlexNet、VGG、NiN、GoogLeNet、ResNet、DenseNet</title>
    <link href="https://liting1024.github.io/2021/05/28/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0Review%E3%80%90%E4%BA%8C%E3%80%91LeNet%E3%80%81AlexNet%E3%80%81VGG%E3%80%81NiN%E3%80%81GoogLeNet%E3%80%81ResNet%E3%80%81DenseNet/"/>
    <id>https://liting1024.github.io/2021/05/28/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0Review%E3%80%90%E4%BA%8C%E3%80%91LeNet%E3%80%81AlexNet%E3%80%81VGG%E3%80%81NiN%E3%80%81GoogLeNet%E3%80%81ResNet%E3%80%81DenseNet/</id>
    <published>2021-05-28T13:45:31.000Z</published>
    <updated>2021-05-28T13:45:31.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p><a href="https://zh-v2.d2l.ai/chapter_multilayer-perceptrons/mlp-concise.html" target="_blank" rel="noopener">课程地址</a></p></blockquote><h1 id="一、LeNet"><a href="#一、LeNet" class="headerlink" title="一、LeNet"></a>一、LeNet</h1><p>手写数字识别（MNIST）<br><img src="https://cdn.jsdelivr.net/gh/liting1024/PicImage/PicgoGithub/512cd1b1e7c840acb4eabbffd3d6923a.png" alt="在这里插入图片描述"><br>使用了Conv2d、AvgPooling、Linear<br>高宽减半时通道数翻倍，保证信息能匹配更多的模式（将信息分配到多个通道）<br>输入超过100x100时MLP不如CNN，输入少时mlp更快</p><h2 id="torch实现"><a href="#torch实现" class="headerlink" title="torch实现"></a>torch实现</h2><pre><code class="python">import torchfrom torch import nnfrom d2l import torch as d2l#使用类可以放在Sequential里class Reshape(torch.nn.Module):    def forward(self, x):        return x.view(-1, 1, 28, 28)net = torch.nn.Sequential(    Reshape(),    nn.Conv2d(1, 6, kernel_size=5, padding=2), nn.Sigmoid(),#窗口5x5，由于数据集是28x28和论文中32x32不同，所以padding了2    nn.AvgPool2d(kernel_size=2, stride=2),#stride=2防止2x2的窗口重叠    nn.Conv2d(6, 16, kernel_size=5), nn.Sigmoid(),    nn.AvgPool2d(kernel_size=2, stride=2),#输出为16*5*5    nn.Flatten(),#把16x5x5拉长变成1维的1x400    nn.Linear(16 * 5 * 5, 120), nn.Sigmoid(),    nn.Linear(120, 84), nn.Sigmoid(),nn.Linear(84, 10))#最后输出1*10的向量    #去掉了高斯层batch_size = 256train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size=batch_size)def evaluate_accuracy_gpu(net, data_iter, device=None):    &quot;&quot;&quot;使用GPU计算模型在数据集上的精度。&quot;&quot;&quot;    if isinstance(net, torch.nn.Module):        net.eval()  # 设置为评估模式        if not device: #未设置device就看net的第一个参数的device            device = next(iter(net.parameters())).device    # 正确预测的数量，总预测的数量    metric = d2l.Accumulator(2)    for X, y in data_iter:        if isinstance(X, list):            # BERT微调所需的（之后将介绍）            X = [x.to(device) for x in X]        else:            X = X.to(device)        y = y.to(device)        metric.add(d2l.accuracy(net(X), y), y.numel())    return metric[0] / metric[1] #分类正确的个数/所有#lr为学习率def train_ch6(net, train_iter, test_iter, num_epochs, lr, device):    &quot;&quot;&quot;用GPU训练模型(在第六章定义)&quot;&quot;&quot;    def init_weights(m): #初始化权重        if type(m) == nn.Linear or type(m) == nn.Conv2d:            nn.init.xavier_uniform_(m.weight) #线性回归和二维卷积自动初始化权重（卷积核）    net.apply(init_weights)    print(&#39;training on&#39;, device)    net.to(device)#搬入GPU    optimizer = torch.optim.SGD(net.parameters(), lr=lr)    loss = nn.CrossEntropyLoss()    #使用动画方便查看结果    animator = d2l.Animator(xlabel=&#39;epoch&#39;, xlim=[1, num_epochs],                            legend=[&#39;train loss&#39;, &#39;train acc&#39;, &#39;test acc&#39;])    timer, num_batches = d2l.Timer(), len(train_iter)    for epoch in range(num_epochs):        # 训练损失之和，训练准确率之和，范例数        metric = d2l.Accumulator(3)        net.train()        for i, (X, y) in enumerate(train_iter):            timer.start()            optimizer.zero_grad()            X, y = X.to(device), y.to(device)#把输入输出放在GPU上            y_hat = net(X)            l = loss(y_hat, y)            l.backward()            optimizer.step()            with torch.no_grad():                metric.add(l * X.shape[0], d2l.accuracy(y_hat, y), X.shape[0])            timer.stop()            train_l = metric[0] / metric[2]            train_acc = metric[1] / metric[2]            if (i + 1) % (num_batches // 5) == 0 or i == num_batches - 1:                animator.add(epoch + (i + 1) / num_batches,                             (train_l, train_acc, None))        test_acc = evaluate_accuracy_gpu(net, test_iter)        animator.add(epoch + 1, (None, None, test_acc))    print(f&#39;loss {train_l:.3f}, train acc {train_acc:.3f}, &#39;          f&#39;test acc {test_acc:.3f}&#39;)    print(f&#39;{metric[2] * num_epochs / timer.sum():.1f} examples/sec &#39;          f&#39;on {str(device)}&#39;)</code></pre><p>图片的学习结果 <a href="http://poloclub.github.io/cnn-explainer/" target="_blank" rel="noopener">http://poloclub.github.io/cnn-explainer/</a></p><h1 id="二、AlexNet"><a href="#二、AlexNet" class="headerlink" title="二、AlexNet"></a>二、AlexNet</h1><p>数据集：ImageNet 自然物体彩色图片</p><h2 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h2><p>更深更大的LeNet<br>使用了丢弃法（正则化）、ReLU（减缓梯度消失）、MaxPooling（扩大梯度更容易训练）、隐藏全连接层后（Dense/FC 4096后）加入丢弃层<br> <img src="https://cdn.jsdelivr.net/gh/liting1024/PicImage/PicgoGithub/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phbWVzU2h1a2Vy,size_16,color_FFFFFF,t_70-20220528215030179.png" alt="在这里插入图片描述"></p><h2 id="torch实现-1"><a href="#torch实现-1" class="headerlink" title="torch实现"></a>torch实现</h2><pre><code class="python">import torchfrom torch import nnfrom d2l import torch as d2lnet = nn.Sequential(    # 步幅为4，以减少输出的高度和宽度 输出通道 96    nn.Conv2d(1, 96, kernel_size=11, stride=4, padding=1), nn.ReLU(),    nn.MaxPool2d(kernel_size=3, stride=2),    # 减小卷积窗口，使用填充为2来使得输入与输出的高和宽一致，且增大输出通道数    nn.Conv2d(96, 256, kernel_size=5, padding=2), nn.ReLU(),    nn.MaxPool2d(kernel_size=3, stride=2),    # 使用三个连续的卷积层和较小的卷积窗口 除了最后的卷积层，输出通道的数量进一步增加。    # 在前两个卷积层之后，汇聚层不用于减少输入的高度和宽度    nn.Conv2d(256, 384, kernel_size=3, padding=1), nn.ReLU(),    nn.Conv2d(384, 384, kernel_size=3, padding=1), nn.ReLU(),    nn.Conv2d(384, 256, kernel_size=3, padding=1), nn.ReLU(),    nn.MaxPool2d(kernel_size=3, stride=2),    nn.Flatten(),    # 这里，全连接层的输出数量是LeNet中的好几倍。使用dropout层来减轻过度拟合    nn.Linear(6400, 4096), nn.ReLU(),    nn.Dropout(p=0.5),    nn.Linear(4096, 4096), nn.ReLU(),    nn.Dropout(p=0.5), # 丢弃了50%    # 最后是输出层。使用Fashion-MNIST，类别数为10，论文中是1000    nn.Linear(4096, 10))batch_size = 128train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=224)lr, num_epochs = 0.01, 10#train_ch6定义在上d2l.train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())</code></pre><h1 id="三、VGG"><a href="#三、VGG" class="headerlink" title="三、VGG"></a>三、VGG</h1><p>为了让模型更深更大，使用更多的卷积层，将卷积层组成块，重复使用这些卷积块<br>更深的模型 窗口更小 效果更好<br><img src="https://cdn.jsdelivr.net/gh/liting1024/PicImage/PicgoGithub/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phbWVzU2h1a2Vy,size_16,color_FFFFFF,t_70-20220528215030263.png" alt="在这里插入图片描述"></p><h2 id="结构"><a href="#结构" class="headerlink" title="结构"></a>结构</h2><p>原始 VGG 网络有 5 个卷积块，其中前两个块各有一个卷积层，后三个块各包含两个卷积层。<br>第一个模块有 64 个输出通道，每个后续模块将输出通道数量翻倍，直到该数字达到 512。由于该网络使用 8 个卷积层和 3 个全连接层，因此它被称为 VGG-11</p><h2 id="torch实现-2"><a href="#torch实现-2" class="headerlink" title="torch实现"></a>torch实现</h2><pre><code class="python">import torchfrom torch import nnfrom d2l import torch as d2ldef vgg_block(num_convs, in_channels, out_channels):    layers = []    for _ in range(num_convs):        layers.append(nn.Conv2d(in_channels, out_channels,                                kernel_size=3, padding=1))        layers.append(nn.ReLU())        in_channels = out_channels    layers.append(nn.MaxPool2d(kernel_size=2,stride=2))    return nn.Sequential(*layers)conv_arch = ((1, 64), (1, 128), (2, 256), (2, 512), (2, 512))def vgg(conv_arch):    conv_blks = []    in_channels = 1    # 卷积层部分    for (num_convs, out_channels) in conv_arch:        conv_blks.append(vgg_block(num_convs, in_channels, out_channels))        in_channels = out_channels    return nn.Sequential(        *conv_blks, nn.Flatten(),        # 全连接层部分 224        nn.Linear(out_channels * 7 * 7, 4096), nn.ReLU(), nn.Dropout(0.5),        nn.Linear(4096, 4096), nn.ReLU(), nn.Dropout(0.5),        nn.Linear(4096, 10))net = vgg(conv_arch)ratio = 4 #将通道数除以4 以方便训练small_conv_arch = [(pair[0], pair[1] // ratio) for pair in conv_arch]net = vgg(small_conv_arch)lr, num_epochs, batch_size = 0.05, 10, 128train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=224)d2l.train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())</code></pre><h1 id="四、NiN"><a href="#四、NiN" class="headerlink" title="四、NiN"></a>四、NiN</h1><p>网络中的网络</p><h2 id="思路、结构"><a href="#思路、结构" class="headerlink" title="思路、结构"></a>思路、结构</h2><p>全连接层会导致过拟合，用卷积层替代全连接层<br>使用NiN块，一个卷积层+两个卷积层（卷积核为1x1、步幅为1、无填充、输出形状和卷积层输出一致（不改变输出和通道数）），来代替全连接层<br>交替使用NiN块和步幅为2的最大池化层（逐步减小高宽 增大通道数），最后用全局平均池化层替代非常大的全连接层得到输出<br><img src="https://cdn.jsdelivr.net/gh/liting1024/PicImage/PicgoGithub/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phbWVzU2h1a2Vy,size_16,color_FFFFFF,t_70-20220528215030176.png" alt="在这里插入图片描述"></p><h2 id="torch实现-3"><a href="#torch实现-3" class="headerlink" title="torch实现"></a>torch实现</h2><pre><code class="python">import torchfrom torch import nnfrom d2l import torch as d2ldef nin_block(in_channels, out_channels, kernel_size, strides, padding):    return nn.Sequential(        nn.Conv2d(in_channels, out_channels, kernel_size, strides, padding),nn.ReLU(),        #输入输出通道数相同        nn.Conv2d(out_channels, out_channels, kernel_size=1), nn.ReLU(),        nn.Conv2d(out_channels, out_channels, kernel_size=1), nn.ReLU())net = nn.Sequential(    nin_block(1, 96, kernel_size=11, strides=4, padding=0),    nn.MaxPool2d(3, stride=2),    nin_block(96, 256, kernel_size=5, strides=1, padding=2),    nn.MaxPool2d(3, stride=2),    nin_block(256, 384, kernel_size=3, strides=1, padding=1),    nn.MaxPool2d(3, stride=2),    nn.Dropout(0.5),    # MNIST的类别数是10，输出降到10即可    nin_block(384, 10, kernel_size=3, strides=1, padding=1),    nn.AdaptiveAvgPool2d((1, 1)),    # 将四维的输出转成二维的输出，其形状为(批量大小, 10)    nn.Flatten())lr, num_epochs, batch_size = 0.1, 10, 128train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=224)#内含有Softmaxd2l.train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())</code></pre><h1 id="五、GoogLeNet"><a href="#五、GoogLeNet" class="headerlink" title="五、GoogLeNet"></a>五、GoogLeNet</h1><p>并行连接的网络</p><h2 id="Inception块"><a href="#Inception块" class="headerlink" title="Inception块"></a>Inception块</h2><p>将输入的通道分为4份<br>为每个通道使用不同窗口大小和padding的卷积层<br>最后的输出高宽相同<br>减少计算量<br><img src="https://cdn.jsdelivr.net/gh/liting1024/PicImage/PicgoGithub/e1aeffe2ab1243f0a52877f7c9d9242c.png" alt="在这里插入图片描述"></p><h2 id="GoogLeNet"><a href="#GoogLeNet" class="headerlink" title="GoogLeNet"></a>GoogLeNet</h2><p>保留更多高宽<br>9个Inception块<br>每个Stage将高宽减半<br>使用全局平均池化<br><img src="https://cdn.jsdelivr.net/gh/liting1024/PicImage/PicgoGithub/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phbWVzU2h1a2Vy,size_16,color_FFFFFF,t_70-20220528215030177.png" alt="在这里插入图片描述"><br>Stage1&amp;2：更小的核 更小的输出通道<br><img src="https://cdn.jsdelivr.net/gh/liting1024/PicImage/PicgoGithub/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phbWVzU2h1a2Vy,size_16,color_FFFFFF,t_70-20220528215030148.png" alt="在这里插入图片描述"></p><p>Stage3：输出通道增加<br><img src="https://cdn.jsdelivr.net/gh/liting1024/PicImage/PicgoGithub/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phbWVzU2h1a2Vy,size_16,color_FFFFFF,t_70-20220528215030261.png" alt="在这里插入图片描述"></p><p>Stage4&amp;5：增加通道数 最后输出1024维特征</p><p><img src="https://cdn.jsdelivr.net/gh/liting1024/PicImage/PicgoGithub/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phbWVzU2h1a2Vy,size_16,color_FFFFFF,t_70-20220528215030254.png" alt="在这里插入图片描述"></p><h2 id="Inception变种"><a href="#Inception变种" class="headerlink" title="Inception变种"></a>Inception变种</h2><p>Inception-BN（V2） 加入batch normalization</p><p>Inception-V3 替换卷积层，消耗内存较多，精度提升<br>把Inception块中的 5x5 替换为多个 3x3 的卷积层（或者1x7和7x1）、把 3x3 换为 1x3 和 3x1 的卷积层<br><img src="https://cdn.jsdelivr.net/gh/liting1024/PicImage/PicgoGithub/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phbWVzU2h1a2Vy,size_16,color_FFFFFF,t_70-20220528215030261-3745830.png" alt="在这里插入图片描述"><br><img src="watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phbWVzU2h1a2Vy,size_16,color_FFFFFF,t_70-20220528215030260.png" alt="在这里插入图片描述"></p><p>Inception-V4 添加残差块连接</p><h2 id="torch实现-4"><a href="#torch实现-4" class="headerlink" title="torch实现"></a>torch实现</h2><pre><code class="python">import torchfrom torch import nnfrom torch.nn import functional as Ffrom d2l import torch as d2lclass Inception(nn.Module):    # `c1`--`c4` 是每条路径的输出通道数    def __init__(self, in_channels, c1, c2, c3, c4, **kwargs):        super(Inception, self).__init__(**kwargs)        # 线路1，单1 x 1卷积层        self.p1_1 = nn.Conv2d(in_channels, c1, kernel_size=1)        # 线路2，1 x 1卷积层后接3 x 3卷积层        self.p2_1 = nn.Conv2d(in_channels, c2[0], kernel_size=1)        self.p2_2 = nn.Conv2d(c2[0], c2[1], kernel_size=3, padding=1)        # 线路3，1 x 1卷积层后接5 x 5卷积层        self.p3_1 = nn.Conv2d(in_channels, c3[0], kernel_size=1)        self.p3_2 = nn.Conv2d(c3[0], c3[1], kernel_size=5, padding=2)        # 线路4，3 x 3最大汇聚层后接1 x 1卷积层        self.p4_1 = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)        self.p4_2 = nn.Conv2d(in_channels, c4, kernel_size=1)    def forward(self, x):        p1 = F.relu(self.p1_1(x))        p2 = F.relu(self.p2_2(F.relu(self.p2_1(x))))        p3 = F.relu(self.p3_2(F.relu(self.p3_1(x))))        p4 = F.relu(self.p4_2(self.p4_1(x)))        # 在通道维度上拼接输出        return torch.cat((p1, p2, p3, p4), dim=1)b1 = nn.Sequential(nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3),                   nn.ReLU(),                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))b2 = nn.Sequential(nn.Conv2d(64, 64, kernel_size=1),                   nn.ReLU(),                   nn.Conv2d(64, 192, kernel_size=3, padding=1),                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))b3 = nn.Sequential(Inception(192, 64, (96, 128), (16, 32), 32),                   Inception(256, 128, (128, 192), (32, 96), 64),                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))b4 = nn.Sequential(Inception(480, 192, (96, 208), (16, 48), 64),                   Inception(512, 160, (112, 224), (24, 64), 64),                   Inception(512, 128, (128, 256), (24, 64), 64),                   Inception(512, 112, (144, 288), (32, 64), 64),                   Inception(528, 256, (160, 320), (32, 128), 128),                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))b5 = nn.Sequential(Inception(832, 256, (160, 320), (32, 128), 128),                   Inception(832, 384, (192, 384), (48, 128), 128),                   nn.AdaptiveAvgPool2d((1,1)),                   nn.Flatten())net = nn.Sequential(b1, b2, b3, b4, b5, nn.Linear(1024, 10))lr, num_epochs, batch_size = 0.1, 10, 128train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=96)d2l.train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())</code></pre><h1 id="六、批量归一化"><a href="#六、批量归一化" class="headerlink" title="六、批量归一化"></a>六、批量归一化</h1><p>对于很深的神经网络，损失出现在最后，但数据在底部；当底部层发生变化所有层都要跟着改变，因此最后的那些层会重新学习很多次，导致loss收敛变慢。<br>一般作用在全连接层和卷积层的输出上，激活函数之前；全连接层和卷积层输入上<br>对于全连接层，作用在特征维；对于卷积层，作用在通道维。<br>由于是在每个小批量里加入噪音控制模型复杂度，因此不必和Dropout混用。 </p><h2 id="思想"><a href="#思想" class="headerlink" title="思想"></a>思想</h2><p>固定小批量里的均值和方差，然后学习出适合的偏移和缩放，以加快收敛<br><img src="https://cdn.jsdelivr.net/gh/liting1024/PicImage/PicgoGithub/3524edcea5e443bb9a103cb17ac75a4c.png" alt="在这里插入图片描述"><br>方差和均值是可学习的参数，控制着做小量的调整（线性变换）<br><img src="https://cdn.jsdelivr.net/gh/liting1024/PicImage/PicgoGithub/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phbWVzU2h1a2Vy,size_16,color_FFFFFF,t_70-20220528215030304.png" alt="在这里插入图片描述"></p><h1 id="七、残差网络ResNet"><a href="#七、残差网络ResNet" class="headerlink" title="七、残差网络ResNet"></a>七、残差网络ResNet</h1><p>加更多的层不一定能距离最优点更近</p><h2 id="残差块"><a href="#残差块" class="headerlink" title="残差块"></a>残差块</h2><p>加入快速通道来得到 f(x) = x + g(x)，由于g(x)在反向传播，层层求梯度之后可能变得非常小，所有将x加在这里，防止变成0而消失。<br><img src="https://cdn.jsdelivr.net/gh/liting1024/PicImage/PicgoGithub/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phbWVzU2h1a2Vy,size_16,color_FFFFFF,t_70-20220528215030342.png" alt="在这里插入图片描述"><br>也可以用1x1的Conv调整通道和分辨率<br><img src="watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phbWVzU2h1a2Vy,size_16,color_FFFFFF,t_70-20220528215030347.png" alt="在这里插入图片描述"></p><p>可以有各种各样的排列形式<br><img src="https://cdn.jsdelivr.net/gh/liting1024/PicImage/PicgoGithub/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phbWVzU2h1a2Vy,size_16,color_FFFFFF,t_70-20220528215030318.png" alt="在这里插入图片描述"><br>多个块拼接成ResNet，每个块高宽减半（strides = 2）<br><img src="https://cdn.jsdelivr.net/gh/liting1024/PicImage/PicgoGithub/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phbWVzU2h1a2Vy,size_16,color_FFFFFF,t_70-20220528215030365.png" alt="在这里插入图片描述"></p><h2 id="torch实现-5"><a href="#torch实现-5" class="headerlink" title="torch实现"></a>torch实现</h2><pre><code class="python">import torchfrom torch import nnfrom torch.nn import functional as Ffrom d2l import torch as d2lclass Residual(nn.Module):  #@save    def __init__(self, input_channels, num_channels,                 use_1x1conv=False, strides=1):        #use1x1是否使用1x1的卷积层        super().__init__()        self.conv1 = nn.Conv2d(input_channels, num_channels,                               kernel_size=3, padding=1, stride=strides)        self.conv2 = nn.Conv2d(num_channels, num_channels,                               kernel_size=3, padding=1)        if use_1x1conv:            self.conv3 = nn.Conv2d(input_channels, num_channels,                                   kernel_size=1, stride=strides)        else:            self.conv3 = None        self.bn1 = nn.BatchNorm2d(num_channels)        self.bn2 = nn.BatchNorm2d(num_channels)        self.relu = nn.ReLU(inplace=True)    def forward(self, X):        Y = F.relu(self.bn1(self.conv1(X)))        Y = self.bn2(self.conv2(Y))        if self.conv3:            X = self.conv3(X)        Y += X        return F.relu(Y)b1 = nn.Sequential(nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3),                   nn.BatchNorm2d(64), nn.ReLU(),                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))#num residuals是表示使用几个block组成一个Stagedef resnet_block(input_channels, num_channels, num_residuals,                 first_block=False):    blk = []    for i in range(num_residuals):        if i == 0 and not first_block:            blk.append(Residual(input_channels, num_channels,                                use_1x1conv=True, strides=2))        else:            blk.append(Residual(num_channels, num_channels))    return blkb2 = nn.Sequential(*resnet_block(64, 64, 2, first_block=True))b3 = nn.Sequential(*resnet_block(64, 128, 2))b4 = nn.Sequential(*resnet_block(128, 256, 2))b5 = nn.Sequential(*resnet_block(256, 512, 2))net = nn.Sequential(b1, b2, b3, b4, b5,                    nn.AdaptiveAvgPool2d((1,1)),                    nn.Flatten(), nn.Linear(512, 10))</code></pre><p>各块输出的Shape<br>Sequential output shape:     torch.Size([1, 64, 56, 56])<br>Sequential output shape:     torch.Size([1, 64, 56, 56])<br>Sequential output shape:     torch.Size([1, 128, 28, 28])<br>Sequential output shape:     torch.Size([1, 256, 14, 14])<br>Sequential output shape:     torch.Size([1, 512, 7, 7])<br>AdaptiveAvgPool2d output shape:      torch.Size([1, 512, 1, 1])<br>Flatten output shape:        torch.Size([1, 512])<br>Linear output shape:         torch.Size([1, 10])</p><pre><code class="python">lr, num_epochs, batch_size = 0.05, 10, 256train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=96)d2l.train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())</code></pre><h1 id="DenseNet-稠密连接网络"><a href="#DenseNet-稠密连接网络" class="headerlink" title="DenseNet 稠密连接网络"></a>DenseNet 稠密连接网络</h1><p>用更高阶的泰勒展开，每一层都加上x<br><img src="https://cdn.jsdelivr.net/gh/liting1024/PicImage/PicgoGithub/f7ac3960291949338e7370cfe6832566.png" alt="在这里插入图片描述"></p><h2 id="结构-1"><a href="#结构-1" class="headerlink" title="结构"></a>结构</h2><p>由 稠密块（dense block）和 过渡层 （transition layer）构成。 前者定义如何连接输入和输出，而后者则通过  1×1  的卷积层来减小通道数，并使用步幅为 2 的平均池化层减半高和宽，控制通道数量。</p><h2 id="torch实现-6"><a href="#torch实现-6" class="headerlink" title="torch实现"></a>torch实现</h2><pre><code class="python">import torchfrom torch import nnfrom d2l import torch as d2ldef conv_block(input_channels, num_channels):    return nn.Sequential(        nn.BatchNorm2d(input_channels), nn.ReLU(),        nn.Conv2d(input_channels, num_channels, kernel_size=3, padding=1))# 稠密层        class DenseBlock(nn.Module):    def __init__(self, num_convs, input_channels, num_channels):        super(DenseBlock, self).__init__()        layer = []        for i in range(num_convs):            layer.append(conv_block(                num_channels * i + input_channels, num_channels))        self.net = nn.Sequential(*layer)    def forward(self, X):        for blk in self.net:            Y = blk(X)            # 连接通道维度上每个块的输入和输出            X = torch.cat((X, Y), dim=1)        return Xblk = DenseBlock(2, 3, 10)X = torch.randn(4, 3, 8, 8)Y = blk(X)Y.shape# 过渡层def transition_block(input_channels, num_channels):    return nn.Sequential(        nn.BatchNorm2d(input_channels), nn.ReLU(),        nn.Conv2d(input_channels, num_channels, kernel_size=1),        nn.AvgPool2d(kernel_size=2, stride=2))blk = transition_block(23, 10)blk(Y).shape# DenseNetb1 = nn.Sequential(    nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3),    nn.BatchNorm2d(64), nn.ReLU(),    nn.MaxPool2d(kernel_size=3, stride=2, padding=1))num_channels, growth_rate = 64, 32num_convs_in_dense_blocks = [4, 4, 4, 4]blks = []for i, num_convs in enumerate(num_convs_in_dense_blocks):    blks.append(DenseBlock(num_convs, num_channels, growth_rate))    # 上一个稠密块的输出通道数    num_channels += num_convs * growth_rate    # 在稠密块之间添加一个转换层，使通道数量减半    if i != len(num_convs_in_dense_blocks) - 1:        blks.append(transition_block(num_channels, num_channels // 2))        num_channels = num_channels // 2#最后加上池化和全连接net = nn.Sequential(    b1, *blks,    nn.BatchNorm2d(num_channels), nn.ReLU(),    nn.AdaptiveMaxPool2d((1, 1)),    nn.Flatten(),    nn.Linear(num_channels, 10))lr, num_epochs, batch_size = 0.1, 10, 256train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=96)d2l.train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu()) </code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&quot;https://zh-v2.d2l.ai/chapter_multilayer-perceptrons/mlp-concise.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;课程地址&lt;/a&gt;&lt;/p&gt;
&lt;</summary>
      
    
    
    
    <category term="机器学习" scheme="https://liting1024.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
  </entry>
  
  <entry>
    <title>深度学习Review【一】线性回归、Softmax、感知机、卷积</title>
    <link href="https://liting1024.github.io/2021/05/28/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0Review%E3%80%90%E4%B8%80%E3%80%91%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E3%80%81Softmax%E3%80%81%E6%84%9F%E7%9F%A5%E6%9C%BA%E3%80%81%E5%8D%B7%E7%A7%AF/"/>
    <id>https://liting1024.github.io/2021/05/28/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0Review%E3%80%90%E4%B8%80%E3%80%91%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E3%80%81Softmax%E3%80%81%E6%84%9F%E7%9F%A5%E6%9C%BA%E3%80%81%E5%8D%B7%E7%A7%AF/</id>
    <published>2021-05-28T13:45:31.000Z</published>
    <updated>2021-05-28T13:45:31.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p><a href="https://zh-v2.d2l.ai/chapter_multilayer-perceptrons/mlp-concise.html" target="_blank" rel="noopener">课程地址</a></p></blockquote><h1 id="一、线性回归"><a href="#一、线性回归" class="headerlink" title="一、线性回归"></a>一、线性回归</h1><p>线性模型：y = ax + b<br><img src="https://cdn.jsdelivr.net/gh/liting1024/PicImage/PicgoGithub/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phbWVzU2h1a2Vy,size_16,color_FFFFFF,t_70.png" alt="在这里插入图片描述"><br>单层神经网络（输出层不看做是一层）<br><img src="https://cdn.jsdelivr.net/gh/liting1024/PicImage/PicgoGithub/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phbWVzU2h1a2Vy,size_16,color_FFFFFF,t_70-20220528214613631.png" alt="在这里插入图片描述"></p><h2 id="1-损失函数"><a href="#1-损失函数" class="headerlink" title="1 损失函数"></a>1 损失函数</h2><p>比较真实值和预估值<br><a href="https://zhuanlan.zhihu.com/p/58883095" target="_blank" rel="noopener">以下几种损失函数比较</a></p><ul><li>0-1损失函数(zero-one loss)</li><li>绝对值损失函数</li><li>log对数损失函数</li><li>平方损失函数</li><li>指数损失函数（exponential loss）</li><li>Hinge 损失函数</li><li>感知损失(perceptron loss)函数</li><li>交叉熵损失函数 (Cross-entropy loss function)</li></ul><p><a href="https://blog.csdn.net/u010637291/article/details/118381364" target="_blank" rel="noopener">语音的几种损失函数</a></p><h2 id="2-参数学习"><a href="#2-参数学习" class="headerlink" title="2 参数学习"></a>2 参数学习</h2><p>选取不同的w和b，根据输入X，计算y的损失<br><img src="https://cdn.jsdelivr.net/gh/liting1024/PicImage/PicgoGithub/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phbWVzU2h1a2Vy,size_16,color_FFFFFF,t_70-20220528214613918-3745573.png" alt="最小化损失"></p><h2 id="3-梯度下降-GD"><a href="#3-梯度下降-GD" class="headerlink" title="3 梯度下降 GD"></a>3 梯度下降 GD</h2><p><img src="https://cdn.jsdelivr.net/gh/liting1024/PicImage/PicgoGithub/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phbWVzU2h1a2Vy,size_16,color_FFFFFF,t_70-20220528214613688.png" alt="在这里插入图片描述"><br>学习率：每次计算loss后调整的步长</p><p>小批量随机梯度下降 SGD：通过随机采样b个样本计算近似损失，以减少计算梯度求导的消耗<br>这里的b  就是batchsize，并行进入神经网络的样本数量</p><h2 id="3-torch实现"><a href="#3-torch实现" class="headerlink" title="3 torch实现"></a>3 torch实现</h2><pre><code class="python"># `nn` 是神经网络的缩写from torch import nn#Sequential是存放网络的list#全连接层（单层网络）输入维度是2 输出为1net = nn.Sequential(nn.Linear(2, 1))#初始化网络参数net[0].weight.data.normal_(0, 0.01)net[0].bias.data.fill_(0)#损失函数 均方误差loss = nn.MSELoss()#定义优化算法 小批量随机梯度下降 传入net的参数w和b 指定学习率lrtrainer = torch.optim.SGD(net.parameters(), lr=0.03)#训练num_epochs = 3for epoch in range(num_epochs):    for X, y in data_iter:        l = loss(net(X) ,y)        trainer.zero_grad() #梯度清零以计算backward        l.backward()         trainer.step() #更新模型    l = loss(net(features), labels)    print(f&#39;epoch {epoch + 1}, loss {l:f}&#39;)w = net[0].weight.dataprint(&#39;w的估计误差：&#39;, true_w - w.reshape(true_w.shape))b = net[0].bias.dataprint(&#39;b的估计误差：&#39;, true_b - b)</code></pre><h1 id="二、Softmax分类"><a href="#二、Softmax分类" class="headerlink" title="二、Softmax分类"></a>二、Softmax分类</h1><p>预测离散的类型，通常有多个输出，输出 i 是预测为第 i 类的置信度<br><img src="https://cdn.jsdelivr.net/gh/liting1024/PicImage/PicgoGithub/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phbWVzU2h1a2Vy,size_16,color_FFFFFF,t_70-20220528214613675.png" alt="在这里插入图片描述"><br>对每个类别进行一位有效编码（==One-Hot==），编码后为向量y作为输入，每个类别的置信度分数（即每个类别的概率）作为输出（输出向量的每个元素非负，元素和为1）<br>使用均方损失函数训练</p><h2 id="1-损失函数-1"><a href="#1-损失函数-1" class="headerlink" title="1 损失函数"></a>1 损失函数</h2><p>橙色为导数，绿色为最大似然函数，蓝色为损失函数<br><img src="https://cdn.jsdelivr.net/gh/liting1024/PicImage/PicgoGithub/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phbWVzU2h1a2Vy,size_16,color_FFFFFF,t_70-20220528214613620.png" alt="在这里插入图片描述"><br>随着预测值和真实值相差不同，进行不同的优化<br><img src="watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phbWVzU2h1a2Vy,size_16,color_FFFFFF,t_70-20220528214613574.png" alt="在这里插入图片描述"><br>不管预测值和真实值相差多远，都能稳定优化<br><img src="https://cdn.jsdelivr.net/gh/liting1024/PicImage/PicgoGithub/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phbWVzU2h1a2Vy,size_16,color_FFFFFF,t_70-20220528214613645.png" alt="在这里插入图片描述"><br>在预测值和真实值相差不大时，减少优化 </p><h2 id="2-torch实现"><a href="#2-torch实现" class="headerlink" title="2 torch实现"></a>2 torch实现</h2><pre><code class="python">import torchfrom torch import nnfrom d2l import torch as d2lbatch_size = 256train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)# PyTorch不会隐式地调整输入的形状 在线性层前定义展平层（flatten）调整网络输入的形状#输入为784 输出为10net = nn.Sequential(nn.Flatten(), nn.Linear(784, 10))#初始化为均值为0方差为0.01的随机值def init_weights(m):    if type(m) == nn.Linear:        nn.init.normal_(m.weight, std=0.01)net.apply(init_weights);loss = nn.CrossEntropyLoss()trainer = torch.optim.SGD(net.parameters(), lr=0.1)#训练模型num_epochs = 10def train_ch3(net, train_iter, test_iter, loss, num_epochs, updater):      animator = Animator(xlabel=&#39;epoch&#39;, xlim=[1, num_epochs], ylim=[0.3, 0.9],                        legend=[&#39;train loss&#39;, &#39;train acc&#39;, &#39;test acc&#39;])    for epoch in range(num_epochs):        train_metrics = train_epoch_ch3(net, train_iter, loss, updater)        test_acc = evaluate_accuracy(net, test_iter)        animator.add(epoch + 1, train_metrics + (test_acc,))    train_loss, train_acc = train_metrics    assert train_loss &lt; 0.5, train_loss    assert train_acc &lt;= 1 and train_acc &gt; 0.7, train_acc    assert test_acc &lt;= 1 and test_acc &gt; 0.7, test_accd2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, trainer)</code></pre><h1 id="三、感知机-Perceptron"><a href="#三、感知机-Perceptron" class="headerlink" title="三、感知机 Perceptron"></a>三、感知机 Perceptron</h1><h2 id="1-二分类的感知机"><a href="#1-二分类的感知机" class="headerlink" title="1 二分类的感知机"></a>1 二分类的感知机</h2><p>二分类问题，x为给定输入，w为权重，b为偏移<br><img src="https://cdn.jsdelivr.net/gh/liting1024/PicImage/PicgoGithub/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phbWVzU2h1a2Vy,size_16,color_FFFFFF,t_70-20220528214613716.png" alt="在这里插入图片描述"><br>线性回归输出的是实数，softmax回归输出的是概率，这里只输出0和1（或者-1和1）是二分类问题<br><img src="https://cdn.jsdelivr.net/gh/liting1024/PicImage/PicgoGithub/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phbWVzU2h1a2Vy,size_16,color_FFFFFF,t_70-20220528214613817.png" alt="在这里插入图片描述"><br>y为实际值，wx+b为预测值，以下所有wx为w和x的混合积</p><pre><code class="c">w=b=0;while(所有分类正确):     if (y*[wx+b]&lt;=0) w+=y*x,b+=y;</code></pre><p>等价于使用batchsize为1的梯度下降，其中loss=max(0,-y*wx)<br>根据收敛定理，对于正确的数据一定可以得到一条直线，将两类样本点分开<br>局限：普通感知机不能拟合XOR函数，必须使用多层感知机</p><h2 id="2-多层感知机MLP"><a href="#2-多层感知机MLP" class="headerlink" title="2 多层感知机MLP"></a>2 多层感知机MLP</h2><p>两个分类器做乘法（用与门和或门实现与或门）<br><img src="https://cdn.jsdelivr.net/gh/liting1024/PicImage/PicgoGithub/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phbWVzU2h1a2Vy,size_16,color_FFFFFF,t_70-20220528214613729.png" alt="在这里插入图片描述"></p><h3 id="单隐藏层-单分类"><a href="#单隐藏层-单分类" class="headerlink" title="单隐藏层-单分类"></a>单隐藏层-单分类</h3><p>Hidden-layer隐藏层是 mxn 的矩阵<br><img src="https://cdn.jsdelivr.net/gh/liting1024/PicImage/PicgoGithub/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phbWVzU2h1a2Vy,size_16,color_FFFFFF,t_70-20220528214613748.png" alt="在这里插入图片描述"><br>使用线性==激活函数==会导致多个连接层摞在一起，变成单层感知机；应当使用Sigmoid、Tanh、ReLU</p><h3 id="多隐藏层多分类"><a href="#多隐藏层多分类" class="headerlink" title="多隐藏层多分类"></a>多隐藏层多分类</h3><p><img src="https://cdn.jsdelivr.net/gh/liting1024/PicImage/PicgoGithub/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phbWVzU2h1a2Vy,size_16,color_FFFFFF,t_70-20220528214613833.png" alt="在这里插入图片描述"><br>结果 y = ==softmax== (o) </p><p><img src="https://cdn.jsdelivr.net/gh/liting1024/PicImage/PicgoGithub/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phbWVzU2h1a2Vy,size_16,color_FFFFFF,t_70-20220528214613805.png" alt="在这里插入图片描述"><br>每次计算出隐藏层结果之前都要使用非线性激活函数，最后一层可以直接通过softmax得到y</p><h2 id="3-torch实现-1"><a href="#3-torch实现-1" class="headerlink" title="3 torch实现"></a>3 torch实现</h2><pre><code class="python">import torchfrom torch import nnfrom d2l import torch as d2lnet = nn.Sequential(nn.Flatten(),                    nn.Linear(784, 256),                    nn.ReLU(),                    nn.Linear(256, 10))# 将三维flatten成二维def init_weights(m):    if type(m) == nn.Linear:        nn.init.normal_(m.weight, std=0.01)net.apply(init_weights);batch_size, lr, num_epochs = 256, 0.1, 10loss = nn.CrossEntropyLoss()#交叉熵损失trainer = torch.optim.SGD(net.parameters(), lr=lr)train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, trainer)</code></pre><h1 id="四、卷积层"><a href="#四、卷积层" class="headerlink" title="四、卷积层"></a>四、卷积层</h1><h2 id="1-卷积操作"><a href="#1-卷积操作" class="headerlink" title="1 卷积操作"></a>1 卷积操作</h2><p>卷积是具有平移不变性（权重共享）和局部性的全连接<br>以下以二维卷积为例<br>二维交叉相关：w为权重，v为重新构建索引后的w<br><img src="https://cdn.jsdelivr.net/gh/liting1024/PicImage/PicgoGithub/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phbWVzU2h1a2Vy,size_16,color_FFFFFF,t_70-20220528214613795.png" alt="在这里插入图片描述"><br>平移不变性：换不同的位置 卷积的计算方式不改变<br><img src="https://cdn.jsdelivr.net/gh/liting1024/PicImage/PicgoGithub/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phbWVzU2h1a2Vy,size_16,color_FFFFFF,t_70-20220528214613815.png" alt="在这里插入图片描述"></p><p>局部性：卷积核在局部进行运算即可<br><img src="https://cdn.jsdelivr.net/gh/liting1024/PicImage/PicgoGithub/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phbWVzU2h1a2Vy,size_16,color_FFFFFF,t_70-20220528214613843.png" alt="在这里插入图片描述"></p><h2 id="2-卷积层"><a href="#2-卷积层" class="headerlink" title="2 卷积层"></a>2 卷积层</h2><p><img src="https://cdn.jsdelivr.net/gh/liting1024/PicImage/PicgoGithub/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phbWVzU2h1a2Vy,size_16,color_FFFFFF,t_70-20220528214613863.png" alt="在这里插入图片描述"><br>填充：通过填充保证卷积后矩阵尺寸不会太小<br><img src="https://cdn.jsdelivr.net/gh/liting1024/PicImage/PicgoGithub/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phbWVzU2h1a2Vy,size_16,color_FFFFFF,t_70-20220528214613871.png" alt="在这里插入图片描述"></p><p>步长（步幅）：矩阵太大，跳过一些以控制输出<br><img src="https://cdn.jsdelivr.net/gh/liting1024/PicImage/PicgoGithub/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phbWVzU2h1a2Vy,size_16,color_FFFFFF,t_70-20220528214613895.png" alt="在这里插入图片描述"></p><h2 id="3-gif"><a href="#3-gif" class="headerlink" title="3 gif"></a>3 gif</h2><p><a href="https://github.com/vdumoulin/conv_arithmetic" target="_blank" rel="noopener">动图地址</a></p><p>正卷积 Convolution</p><table style="width:100%; table-layout:fixed;">  <tr>    <td><img width="150px" src="https://img-blog.csdnimg.cn/5eef48d06fb14f899bda33df05105a29.gif"></td>    <td><img width="150px" src="https://img-blog.csdnimg.cn/15690af9e7f14fdfa4792e36d9917a9b.gif"></td>    <td><img width="150px" src="https://img-blog.csdnimg.cn/f1c24feaa4824cc58c1c73c1241a6ca6.gif"></td>    <td><img width="150px" src="https://img-blog.csdnimg.cn/74e048c5c87b4c5eab6d1c021a9ef8d0.gif"></td>  </tr>  <tr>    <td>No padding, no strides</td>    <td>Arbitrary padding, no strides</td>    <td>Half padding, no strides</td>    <td>Full padding, no strides</td>  </tr>  <tr>    <td><img width="150px" src="https://img-blog.csdnimg.cn/77c1340f081447dd80235a0314ea4e39.gif"></td>    <td><img width="150px" src="https://img-blog.csdnimg.cn/d8248ba016884fe2b9a3459d4d256ca4.gif"></td>    <td><img width="150px" src="https://img-blog.csdnimg.cn/36415057172440488fdeb342d30e9bf7.gif"></td>    <td></td>  </tr>  <tr>    <td>No padding, strides</td>    <td>Padding, strides</td>    <td>Padding, strides (odd)</td>    <td></td>  </tr></table><p>转置卷积 Transposed Convolution</p><table style="width:100%; table-layout:fixed;">  <tr>    <td><img width="150px" src="https://img-blog.csdnimg.cn/624f5f3771ce4420a681ed56542d9f16.gif"></td>    <td><img width="150px" src="https://img-blog.csdnimg.cn/d4212dc0bd7a47b098ac3951f84e642e.gif"></td>    <td><img width="150px" src="https://img-blog.csdnimg.cn/c846e49417fe4eb3a5e4ac05ae37ef86.gif"></td>    <td><img width="150px" src="https://img-blog.csdnimg.cn/b2d1713bb7d84db285f91ce3b469b8de.gif"></td>  </tr>  <tr>    <td>No padding, no strides, transposed</td>    <td>Arbitrary padding, no strides, transposed</td>    <td>Half padding, no strides, transposed</td>    <td>Full padding, no strides, transposed</td>  </tr>  <tr>    <td><img width="150px" src="https://img-blog.csdnimg.cn/e30aa2ee0e8b4bcfb4a737e8641b35f5.gif"></td>    <td><img width="150px" src="https://img-blog.csdnimg.cn/4415738c84e043b696971d25fb6da0b9.gif"></td>    <td><img width="150px" src="https://img-blog.csdnimg.cn/445168d353204ffbb47f3f60fd14702d.gif"></td>    <td></td>  </tr>  <tr>    <td>No padding, strides, transposed</td>    <td>Padding, strides, transposed</td>    <td>Padding, strides, transposed (odd)</td>    <td></td>  </tr></table>空洞卷积 Dilated convolution![在这里插入图片描述](https://cdn.jsdelivr.net/gh/liting1024/PicImage/PicgoGithub/405a4c3d348d42d98f83aedcae5648b5.gif)<h2 id="4-多输入输出通道channls"><a href="#4-多输入输出通道channls" class="headerlink" title="4 多输入输出通道channls"></a>4 多输入输出通道channls</h2><h3 id="意义"><a href="#意义" class="headerlink" title="意义"></a>意义</h3><p>多个输出out通道可以识别特定的模式，Eg：RGB图片三通道可以按照颜色分别识别<br>多个输入in通道可以识别并组合输入中的模式，Eg：在识别猫的图片时，分别识别出猫的脚和身体，然后组合</p><h3 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h3><p>多输入in：在每个通道各自卷积后加权求和（降维）为一个通道<br>多输出out：使用多个卷积核，每个卷积核生成一个输出通道</p><h2 id="5-1x1的卷积层"><a href="#5-1x1的卷积层" class="headerlink" title="5 1x1的卷积层"></a>5 1x1的卷积层</h2><p>不识别空间模式，只是融合不同通道的信息，对不同的通道进行加权求和<br>Eg：语音分离<br><img src="https://cdn.jsdelivr.net/gh/liting1024/PicImage/PicgoGithub/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phbWVzU2h1a2Vy,size_16,color_FFFFFF,t_70-20220528214613889.png" alt="在这里插入图片描述"><br>将input拉成一维的向量就变成全连接层</p><h1 id="五、ConvTranspoes-转置卷积"><a href="#五、ConvTranspoes-转置卷积" class="headerlink" title="五、ConvTranspoes 转置卷积"></a>五、ConvTranspoes 转置卷积</h1><p>增大输入的高宽，一般用于恢复形状，但输出的信息比较抽象，不能被人直接分辨，也用于上采样。<br>输入中的每一个值与卷积核的每一个值做乘法，把重合的部分相加。<br>padding是去掉输出的外层。<br><img src="https://cdn.jsdelivr.net/gh/liting1024/PicImage/PicgoGithub/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phbWVzU2h1a2Vy,size_16,color_FFFFFF,t_70-20220528214613918.png" alt="在这里插入图片描述"></p><h1 id="六、池化层（汇聚层）-Pooling"><a href="#六、池化层（汇聚层）-Pooling" class="headerlink" title="六、池化层（汇聚层） Pooling"></a>六、池化层（汇聚层） Pooling</h1><p>卷积层做边缘检测时，对边缘太敏感，检测时往往会不准确</p><p>最大池化：在滑动窗口时，返回窗口中的最大值<br>平均池化：返回窗口中各元素的均值</p><h2 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h2><p>超参数有窗口大小、填充和步幅<br>没有可学习的参数<br>输出通道数=输入通道数<br>在每个输入通道都用池化层来分别获得输出，不进行多通道融合</p><h2 id="torch实现"><a href="#torch实现" class="headerlink" title="torch实现"></a>torch实现</h2><p>2x3大小的窗口</p><pre><code class="python">pool2d = nn.MaxPool2d((2, 3), padding=(1, 1), stride=(2, 3))pool2d(X)</code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&quot;https://zh-v2.d2l.ai/chapter_multilayer-perceptrons/mlp-concise.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;课程地址&lt;/a&gt;&lt;/p&gt;
&lt;</summary>
      
    
    
    
    <category term="机器学习" scheme="https://liting1024.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
  </entry>
  
  <entry>
    <title>基础算法</title>
    <link href="https://liting1024.github.io/2021/05/27/%E5%9F%BA%E7%A1%80%E7%AE%97%E6%B3%95/"/>
    <id>https://liting1024.github.io/2021/05/27/%E5%9F%BA%E7%A1%80%E7%AE%97%E6%B3%95/</id>
    <published>2021-05-27T14:43:44.000Z</published>
    <updated>2021-05-27T14:43:44.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="基础算法"><a href="#基础算法" class="headerlink" title="基础算法"></a>基础算法</h1><h2 id="排序"><a href="#排序" class="headerlink" title="排序"></a>排序</h2><h3 id="快速排序-分治"><a href="#快速排序-分治" class="headerlink" title="快速排序 - 分治"></a>快速排序 - 分治</h3><p>分治：不断把数据分成两部分，一半小于另一半</p><ol><li><p>确定分界（4种方法）：取q[l], q[(l + r) / 2], q[r], 随机点 </p></li><li><p>调整区间：小于分界点的在左区间，其余在右区间 </p><p>​    使用两个数组作为左右区间 </p><p>​    使用两个指针（i = l - 1，j = r + 1），如果a[i]&gt;x,a[i]&lt;x，交换a[i] a[j] </p></li><li><p>递归：给左右排序 </p></li></ol><pre><code class="c++">void quick_sort(int q[], int l, int r) {    if (l &gt;= r)       return;    int i = l - 1, j = r + 1, x = q[l + r &gt;&gt; 1];    while (i &lt; j) {        do i ++ ; while (q[i] &lt; x);        do j -- ; while (q[j] &gt; x);        if (i &lt; j) swap(q[i], q[j]);    }    quick_sort(q, l, j); quick_sort(q, j + 1, r);}</code></pre><h3 id="归并排序-分治（稳定）"><a href="#归并排序-分治（稳定）" class="headerlink" title="归并排序 - 分治（稳定）"></a>归并排序 - 分治（稳定）</h3><p>合并：两个有序数组</p><p>双指针：比较两个数组里待合并的数，将较小的放入新数组</p><ol><li>确定分界点 mid = (l + r) / 2 数组的中心</li><li>递归</li><li>归并两个有序数组（用双指针合并）</li></ol><pre><code class="C++">void merge_sort(int q[], int l, int r) {    if (l &gt;= r) return;    int mid = l + r &gt;&gt; 1; // 用mid将原数组一分为二    // 先递归到底    merge_sort(q, l, mid);    merge_sort(q, mid + 1, r);    int k = 0, i = l, j = mid + 1;    while (i &lt;= mid &amp;&amp; j &lt;= r)         // 双指针i和j分别对mid左右的两个数组遍历        if (q[i] &lt;= q[j]) tmp[k ++ ] = q[i ++ ];        else tmp[k ++ ] = q[j ++ ];    // 将剩余的部分加入数组    while (i &lt;= mid) tmp[k ++ ] = q[i ++ ];    while (j &lt;= r) tmp[k ++ ] = q[j ++ ];    for (i = l, j = 0; i &lt;= r; i ++, j ++ ) q[i] = tmp[j];}</code></pre><h2 id="二分"><a href="#二分" class="headerlink" title="二分"></a>二分</h2><p>有单调性 一定可以 二分</p><p>求范围，让答案在收缩的区间里</p><p>向左收缩和向右收缩mid的取值不同</p><p><img src="https://cdn.jsdelivr.net/gh/liting1024/PicImage/PicgoGithub/96221_90b4ffa079-IMG_67CE3ECA2B0B-1.jpeg" alt="IMG_67CE3ECA2B0B-1.jpeg"> </p><pre><code class="C++">// 整数二分bool check(int x) {} // 检查x是否满足某种性质// 区间[l, r]被划分成[l, mid]和[mid + 1, r]时使用：向左收缩int bsearch_1(int l, int r) {    while (l &lt; r) {        int mid = l + r &gt;&gt; 1;        if (check(mid)) r = mid;    // check()判断mid是否满足性质        else l = mid + 1;    } // 结束时l和r相等    return l;}// 区间[l, r]被划分成[l, mid - 1]和[mid, r]时使用：向右收缩int bsearch_2(int l, int r) {    while (l &lt; r) {        int mid = l + r + 1 &gt;&gt; 1;//防止死循环 多加1        if (check(mid)) l = mid; // arr[mid]=x 时需要取边界        else r = mid - 1;    }    return l;}</code></pre><p> 对于浮点数 将while里停止的条件改为 r - l &gt; 1e-6</p><p>while控制的精度最好小于输出保留位数两位，防止精度不够</p><p>Eg：输出小数点后四位，这里控制为1e-6</p><pre><code class="C++">// 实数二分bool check(double x) {} // 检查x是否满足某种性质double bsearch_3(double l, double r) {    const double eps = 1e-6;   // eps 表示精度，取决于题目对精度的要求    while (r - l &gt; eps) {        double mid = (l + r) / 2;        if (check(mid)) r = mid;        else l = mid;    }    return l;}</code></pre><h2 id="高精度"><a href="#高精度" class="headerlink" title="高精度"></a>高精度</h2><p>用数组存大整数，低地址存低位（小端），0存个位</p><h3 id="加"><a href="#加" class="headerlink" title="加"></a>加</h3><pre><code class="C++">// C = A + B, A &gt;= 0, B &gt;= 0vector&lt;int&gt; add(vector&lt;int&gt; &amp;A, vector&lt;int&gt; &amp;B) {    if (A.size() &lt; B.size()) return add(B, A);    vector&lt;int&gt; C;    int t = 0;    for (int i = 0; i &lt; A.size(); i ++ ) {        t += A[i];        if (i &lt; B.size()) t += B[i];        C.push_back(t % 10);        t /= 10;    }    if (t) C.push_back(t);    return C;}</code></pre><h3 id="减"><a href="#减" class="headerlink" title="减"></a>减</h3><p>A &lt; B =&gt; -(B - A) </p><pre><code class="C++">// C = A - B, 满足A &gt;= B, A &gt;= 0, B &gt;= 0bool cmp(vector&lt;int&gt; &amp;A, vector&lt;int&gt; &amp;B) {    if (A.size() != B.size()) return A.size() &gt; B.size();    for (int i = A.size()-1; i &gt;= 0; i--)         if (A[i] != B[i]) return A[i] &gt; B[i];    return true; // }vector&lt;int&gt; sub(vector&lt;int&gt; &amp;A, vector&lt;int&gt; &amp;B) { //引用 节省时间    vector&lt;int&gt; C;    for (int i = 0, t = 0; i &lt; A.size(); i ++ ) {        t = A[i] - t;        if (i &lt; B.size()) t -= B[i];        C.push_back((t + 10) % 10);          // 只防止负数 不会改变结果         //（1+10）%10 = 1 （10+10）%10 = 0        if (t &lt; 0) t = 1;        else t = 0;    }        // 去除多个 0    while (C.size() &gt; 1 &amp;&amp; C.back() == 0) C.pop_back();    return C;}// 主函数if (cmp(A, B)) C = sub(A, B);else {    C = sub(B, A);    cout&lt;&lt;&#39;-&#39;;}</code></pre><h3 id="乘"><a href="#乘" class="headerlink" title="乘"></a>乘</h3><pre><code class="C++">// C = A * b, A &gt;= 0, b &gt;= 0vector&lt;int&gt; mul(vector&lt;int&gt; &amp;A, int b) {    vector&lt;int&gt; C;    for (int i = 0, t = 0; i &lt; A.size() || t; i ++ ) {        if (i &lt; A.size()) t += A[i] * b;        C.push_back(t % 10);        t /= 10;    }    while (C.size() &gt; 1 &amp;&amp; C.back() == 0) C.pop_back();    return C;}</code></pre><h3 id="除"><a href="#除" class="headerlink" title="除"></a>除</h3><p><img src="https://cdn.jsdelivr.net/gh/liting1024/PicImage/PicgoGithub/96221_46df52f37a-IMG_CF57C855FBAC-1.jpeg" alt="IMG_CF57C855FBAC-1.jpeg"> </p><pre><code class="C++">// A / b = C ... r, A &gt;= 0, b &gt; 0// 引用直接修改原来的rvector&lt;int&gt; div(vector&lt;int&gt; &amp;A, int b, int &amp;r) {    vector&lt;int&gt; C;    r = 0;    for (int i = A.size() - 1; i &gt;= 0; i -- ) {        r = r * 10 + A[i]; // 借位        C.push_back(r / b);        r %= b;    }    reverse(C.begin(), C.end());    while (C.size() &gt; 1 &amp;&amp; C.back() == 0) C.pop_back();    return C;}</code></pre><h2 id="前缀和"><a href="#前缀和" class="headerlink" title="前缀和"></a>前缀和</h2><p>应用：计算前缀和</p><p>存前缀和的下标从1开始，将数组下标为0的值设为0</p><h3 id="一维"><a href="#一维" class="headerlink" title="一维"></a>一维</h3><p><img src="https://cdn.jsdelivr.net/gh/liting1024/PicImage/PicgoGithub/96221_fda86e367a-IMG_D9E1403749B2-1.jpeg" alt="IMG_D9E1403749B2-1.jpeg"></p><h3 id="二维"><a href="#二维" class="headerlink" title="二维"></a>二维</h3><p><img src="https://cdn.jsdelivr.net/gh/liting1024/PicImage/PicgoGithub/96221_bfe890657b-96221_82a4b4b87a-IMG_57AF8F31A5F1-1.jpg" alt="96221_82a4b4b87a-IMG_57AF8F31A5F1-1.jpg"> </p><pre><code class="C++">// 一维s[i] = s[i-1] + a[i];s[j] - s[i-1];// 二维sum[i][j] = sum[i-1][j] + sum[i][j-1] - sum[i-1][j-1] + a[i][j];sum[x2][y2] - sum[x2][y1-1] - sum[x1-1][y2] + sum[x1-1][y1-1];</code></pre><h2 id="差分"><a href="#差分" class="headerlink" title="差分"></a>差分</h2><p>应用：在[ l , r ]之间的每个数加上 c</p><p>前缀和的逆运算</p><h3 id="一维-1"><a href="#一维-1" class="headerlink" title="一维"></a>一维</h3><p><img src="https://cdn.jsdelivr.net/gh/liting1024/PicImage/PicgoGithub/96221_2d5a8c7d7b-IMG_C86BC0DC46CD-1.jpeg" alt="IMG_C86BC0DC46CD-1.jpeg"> </p><h3 id="二维-1"><a href="#二维-1" class="headerlink" title="二维"></a>二维</h3><p><img src="https://cdn.jsdelivr.net/gh/liting1024/PicImage/PicgoGithub/96221_3c3bcc877b-IMG_66D0BEAAF6CD-1.jpeg" alt="IMG_66D0BEAAF6CD-1.jpeg"> </p><pre><code class="C++">// 一维// a存b的前缀和b[i] = a[i]-a[i-1]void insert(int l, int r,int c) {  b[l] += c;  b[r+1] -= c;}// 求前缀和 得到操作后的a数组b[i] += b[i-1];// 二维void insert(int x1,int y1,int x2,int y2,int c) {    b[x1][y1] += c;    b[x2+1][y1] -= c;    b[x1][y2+1] -= c;    b[x2+1][y2+1] += c;}// 求前缀和 把b还原成加了c之后的ab[i][j] += b[i-1][j] + b[i][j-1] - b[i-1][j-1];</code></pre><h2 id="双指针"><a href="#双指针" class="headerlink" title="双指针"></a>双指针</h2><p>核心：将两个指针 n^2 优化到 n ， 没思路可以先写一个 n^2 找规律</p><p>两个序列：合并；归并排序的归并、快速排序的划分；KMP</p><p>一个序列：确定区间的开头结尾，如：滑动窗口；判断环</p><pre><code class="C++">for (i = 0, j = 0; i &lt; n; i++) {    while(j &lt; i &amp;&amp; check(i, j)) j++;}</code></pre><h2 id="位运算"><a href="#位运算" class="headerlink" title="位运算"></a>位运算</h2><p>n&gt;&gt;k&amp;1：n（二进制）的第k位（从第0位开始）</p><p>1&lt;&lt;n：2的n次方</p><p>lowbit(x) { return x&amp;-x;}：x&amp;(~x+1)，即返回x的最后一位1，可以计算1的个数</p><h3 id="异或"><a href="#异或" class="headerlink" title="异或"></a>异或</h3><p>不进位加法，相同为0，不同为1</p><table><thead><tr><th align="center">运算</th><th align="center">功能</th></tr></thead><tbody><tr><td align="center">0^x = x</td><td align="center">0异或还是原数</td></tr><tr><td align="center">1^1010 = 1011</td><td align="center">1异或末尾取反</td></tr><tr><td align="center">x^x = 0</td><td align="center">异或自己得0</td></tr><tr><td align="center">a^b == 0</td><td align="center">判断a和b是否相等</td></tr></tbody></table><p>交换a和b：a = a ^ b, b = b ^ a, a = a ^ b</p><p>交换律： a ^ b = b ^a, a ^ b ^ a = b 可以用于找奇数个数的数</p><h2 id="离散化"><a href="#离散化" class="headerlink" title="离散化"></a>离散化</h2><p>离散化：稀疏数组中，10^5个数，值域为 0 ~ 10^9，将值域映射到 0 ~ n</p><p>难点：可能存在重复元素，并能及时得到离散化后的值</p><p>应用：稀疏数组即数组下标很大，但数组中很多值是空的</p><p><img src="https://cdn.jsdelivr.net/gh/liting1024/PicImage/PicgoGithub/96221_3d6388e57c-IMG_DA2CAA82DDB6-1.jpeg" alt="IMG_DA2CAA82DDB6-1.jpeg"> </p><pre><code class="C++">// 用vector模拟set，可以用下标访问vector&lt;int&gt; vec;sort(vec.begin(), vec.end()); // 排序vec.erase(unique(vec.begin(), vec.end()), vec.end()); // 去重// 用二分找第一个大于等于x的，相当于lower_bound()int find(int x) {     int l = 0, r = vec.size()-1;    while (l &lt; r) {        int mid = l+r&gt;&gt;1;        if (vec[mid] &gt;= x) r = mid;        else l = mid + 1;    }    return r+1; // 从1开始映射}</code></pre><h1 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h1><h2 id="链表"><a href="#链表" class="headerlink" title="链表"></a>链表</h2><h3 id="单链表"><a href="#单链表" class="headerlink" title="单链表"></a>单链表</h3><pre><code class="C++">/** head 头结点下标 存值* e 存val* ne 存next* idx 表示e中当前位置*/int head, e[N], ne[N], idx;// 头插void add_to_head(int x) {    e[idx] = x;    ne[idx] = head;    head = idx;    idx ++;}// 下标为k的后面插xvoid add(int k, int x) {     e[idx] = x;    ne[idx] = ne[k];    ne[k] = idx;    idx ++;}// 删k后的点 (-1后的点为0)void remove(int k) {    if (k == -1) head = ne[head];    ne[k] = ne[ne[k]];}void init() {    head = -1;    idx = 0;}</code></pre><h3 id="邻接表"><a href="#邻接表" class="headerlink" title="邻接表"></a>邻接表</h3><pre><code class="C++">int head[N];</code></pre><h3 id="双链表"><a href="#双链表" class="headerlink" title="双链表"></a>双链表</h3><p>优化某些问题</p><pre><code class="C++">int head, tail;int e[N], l[N], r[N], idx;void init() {    head = -1;     tail = -1;    idx = 0;}// 在k右边插入 // 在k左边插入 add(l[k], x);void add(int k, int x) {    e[idx] = x;    r[idx] = r[k];    l[idx] = k;    l[r[k]] = idx;    r[k] = idx;    idx ++;}void remove(int k) {    r[l[k]] = r[k];    l[r[k]] = l[k];}</code></pre><h2 id="栈"><a href="#栈" class="headerlink" title="栈"></a>栈</h2><h3 id="单调栈"><a href="#单调栈" class="headerlink" title="单调栈"></a>单调栈</h3><p>应用：找每个数左边第一个比它小/大的数、视野总和、柱状图中最大矩形</p><p>有序栈：如果<strong>栈为空</strong>或<strong>入栈元素值小于栈顶元素值</strong>，则入栈；否则，如果入栈则会破坏栈的单调性，则需要把比入栈元素小的元素全部出栈。</p><p>思想：先考虑暴力，然后优化</p><p><img src="https://cdn.jsdelivr.net/gh/liting1024/PicImage/PicgoGithub/96221_207657767c-IMG_75854B600D80-1.jpeg" alt="IMG_75854B600D80-1.jpeg"> </p><pre><code class="C++">// STLfor (int i = 0; i &lt; n; i ++ ) {    cin&gt;&gt;x;    while (!stk.empty() &amp;&amp; stk.top() &gt;= x) stk.pop();    if (!stk.empty()) cout&lt;&lt;stk.top();    else cout&lt;&lt;-1;    cout&lt;&lt;&#39; &#39;;    stk.push(x);}// 数组for (int i = 0; i &lt; n; i ++ ) {  cin&gt;&gt;x;  while (tt &amp;&amp; stk[tt] &gt;= x) tt --;  if (tt) cout&lt;&lt;stk[tt];  else cout&lt;&lt;-1;  cout&lt;&lt;&#39; &#39;;  stk[++tt] = x;}</code></pre><h2 id="队列"><a href="#队列" class="headerlink" title="队列"></a>队列</h2><h3 id="单调队列（滑动窗口）"><a href="#单调队列（滑动窗口）" class="headerlink" title="单调队列（滑动窗口）"></a>单调队列（滑动窗口）</h3><p>思路：先暴力 再优化，根据单调性，去除不必要的数据和遍历</p><p><img src="https://cdn.jsdelivr.net/gh/liting1024/PicImage/PicgoGithub/96221_c426d80b7d-IMG_802D4A12F0EB-1.jpeg" alt="IMG_802D4A12F0EB-1.jpeg"> </p><pre><code class="C++">// 数组模拟队列int hh = 0, tt = -1;for (int i = 0; i &lt; n; i ++ ) {  while (hh &lt;= tt &amp;&amp; q[hh] &lt; i-k+1) hh++;  while (hh &lt;= tt &amp;&amp; a[q[tt]] &gt;= a[i]) tt--;    q[++tt] = i;    if (i &gt;= k-1) cout&lt;&lt;a[q[hh]]&lt;&lt;&#39; &#39;;}// 双端队列deque&lt;int&gt; que;for (int i = 0; i &lt; n; i ++ ) {  while (!que.empty() &amp;&amp; que.front() &lt; i-k+1) que.pop_front(); // 超出窗口大小出队  // 次新的不如新的小 丢弃  while (!que.empty() &amp;&amp; a[i] &lt;= a[que.back()]) que.pop_back();  que.push_back(i);  if (i &gt;= k-1) cout&lt;&lt;a[que.front()]&lt;&lt;&#39; &#39;;}// 优先队列priority_queue&lt;PII, vector&lt;PII&gt;, greater&lt;PII&gt;&gt; que1;for (int i = 0; i &lt; n; i ++ ) {    while (!que1.empty() &amp;&amp; que1.top().y &lt; i-k+1) que1.pop();  que1.push({a[i], i});  if (que1.size() &gt; k-1) cout&lt;&lt;que1.top().x&lt;&lt;&#39; &#39;;}</code></pre><h2 id="KMP"><a href="#KMP" class="headerlink" title="KMP"></a>KMP</h2><p>应用：找子串</p><p><img src="https://cdn.jsdelivr.net/gh/liting1024/PicImage/PicgoGithub/96221_64cbfa007e-IMG_E8CB8965BF92-1.jpeg" alt="IMG_E8CB8965BF92-1.jpeg"> </p><pre><code class="C++">// 求nextfor (int i = 2, j = 0; i &lt;= n; i ++ ) {    while (j &amp;&amp; p[i] != p[j+1]) j = ne[j];  if (p[i] == p[j+1]) j++;  ne[i] = j;}for (int i = 1, j = 0; i &lt;= m; i ++ ) {    while (j &amp;&amp; s[i] != p[j+1]) { // 不能匹配或j无处可退      j = ne[j];  }  if (s[i] == p[j+1]) j++;  if (j == n) {        // 匹配成功    cout&lt;&lt;i-n&lt;&lt;&#39; &#39;;    j = ne[j]; //   }}</code></pre><h2 id="Trie树"><a href="#Trie树" class="headerlink" title="Trie树"></a>Trie树</h2><p>高效存储查找字符串集合</p><p><img src="https://cdn.jsdelivr.net/gh/liting1024/PicImage/PicgoGithub/96221_8b858dd97e-IMG_F19C60B06C11-1.jpeg" alt="IMG_F19C60B06C11-1.jpeg"> </p><pre><code class="C++">// son每个结点的子节点// cnt以当前点结尾的单词的数量// 下标为0的点 空节点或者根节点int son[N][26], cnt[N], idx; void insert(char str[]) {    int p = 0;    for (int i = 0; str[i] ;i++ ) {        int u = str[i] - &#39;a&#39;;        if (!son[p][u]) son[p][u] = ++idx; // 不存在字母u        p = son[p][u];    }    cnt[p] ++;}int query(char str[]) { // 返回string出现的次数    int p = 0;    for (int i = 0; str[i] ;i++ ) {        int u = str[i] - &#39;a&#39;;        if (!son[p][u]) return 0;        p = son[p][u];    }    return cnt[p];}</code></pre><h2 id="并查集-Union-Find-Set"><a href="#并查集-Union-Find-Set" class="headerlink" title="并查集 Union Find Set"></a>并查集 Union Find Set</h2><p>合并两个集合、询问两个元素是否在一个集合中</p><p>基本：树根（代表元素）的编号是整个树的编号</p><p>路径压缩：所有孩子都直接指向根节点</p><p>按秩合并：将简单的树合并在复杂的树下（计算深度）</p><h3 id="朴素并查集"><a href="#朴素并查集" class="headerlink" title="朴素并查集"></a>朴素并查集</h3><pre><code class="C++">int p[N]; //储存每个点的祖宗节点int find(int x) { //返回x的祖宗节点 + 递归保证 路径压缩    if(p[x] != x) p[x] = find(p[x]);    return p[x];}for (int i = 1; i &lt;= n; i ++ ) p[i] = i; //初始化p[find(a)] = find(b); //合并a,b两个集合</code></pre><h3 id="维护size数组的并查集"><a href="#维护size数组的并查集" class="headerlink" title="维护size数组的并查集"></a>维护size数组的并查集</h3><pre><code class="C++">int p[N], size[N];//p[]存储每个点的祖宗节点, size[]只有祖宗节点的有意义，表示祖宗节点所在集合中的点的数量// 返回x的祖宗节点int find(int x){  if (p[x] != x) p[x] = find(p[x]);  return p[x];}// 初始化，假定节点编号是1~n    for (int i = 1; i &lt;= n; i ++ ){  p[i] = i;      size[i] = 1;}// 合并a和b所在的两个集合：先把size求和    size[find(b)] += size[find(a)];p[find(a)] = find(b);</code></pre><h3 id="维护到祖宗节点距离的并查集"><a href="#维护到祖宗节点距离的并查集" class="headerlink" title="维护到祖宗节点距离的并查集"></a>维护到祖宗节点距离的并查集</h3><pre><code class="C++">int p[N], d[N];//p[]存储每个点的祖宗节点, d[x]存储x到p[x]的距离// 返回x的祖宗节点int find(int x){    if (p[x] != x){        int u = find(p[x]);        d[x] += d[p[x]];        p[x] = u;    }    return p[x];}// 初始化，假定节点编号是1~nfor (int i = 1; i &lt;= n; i ++ ){    p[i] = i;    d[i] = 0;}// 合并a和b所在的两个集合：p[find(a)] = find(b);d[find(a)] = distance; // 根据具体问题，初始化find(a)的偏移量</code></pre><h2 id="堆"><a href="#堆" class="headerlink" title="堆"></a>堆</h2><p>完全二叉树</p><p>根结点小于等于左右子结点</p><p><img src="https://cdn.jsdelivr.net/gh/liting1024/PicImage/PicgoGithub/96221_52e7bb837f-IMG_06DCF7F7578D-1.jpeg" alt="IMG_06DCF7F7578D-1.jpeg"> </p><pre><code class="C++">int h[N]; // 用完全二叉树存堆// 从根往下调整void down(int u) {  int t = u;  if (u*2 &lt;= size &amp;&amp; h[u*2] &lt; h[t]) t = u*2;  if (u*2+1 &lt;= size &amp;&amp; h[u*2+1] &lt; h[t]) t = u*@+1;  if (u != t) {    swap(h[u], h[t]);    down(t);  }}void up(); // 向上调整// 插入heap[++size] = x; up(size);// 求最值（堆顶）head[1]// 删除最值heap[1] = heap[size]; size --; down(1);// 删除任意元素（用最后一个代替原值并执行down或up，这里都写但实际不会都执行下去）heap[k] = heap[size]; size --; down(k); up(k);// 修改任意值heap[k] = x; down(k); up(k);</code></pre><h1 id="搜索与图论"><a href="#搜索与图论" class="headerlink" title="搜索与图论"></a>搜索与图论</h1><h2 id="DFS"><a href="#DFS" class="headerlink" title="DFS"></a>DFS</h2><p>深搜</p><h2 id="BFS"><a href="#BFS" class="headerlink" title="BFS"></a>BFS</h2><p>广搜</p><p>八皇后</p><h2 id="拓扑排序"><a href="#拓扑排序" class="headerlink" title="拓扑排序"></a>拓扑排序</h2><p>关键：广搜、入度</p><p><img src="https://cdn.jsdelivr.net/gh/liting1024/PicImage/PicgoGithub/96221_3f32973686-IMG_99F1477B4A0A-1.jpeg" alt="IMG_99F1477B4A0A-1.jpeg"> </p><pre><code class="C++">bool topsort() {    queue&lt;int&gt; que;    for (int i = 1; i &lt;= n; i++) // 初始化 将入度为0的点入队        if (d[i] == 0) que.push(i);    while(!que.empty()) {        int tmp = que.front();        ans.push_back(tmp);        que.pop();        for (auto e : edge[tmp]) {            d[e] --;            if (d[e] == 0) que.push(e);        }    }    return ans.size() == n; // 全进入ans则存在拓扑}</code></pre><h2 id="最短路径"><a href="#最短路径" class="headerlink" title="最短路径"></a>最短路径</h2><p>n为点数，m为边数</p><h3 id="分类"><a href="#分类" class="headerlink" title="分类"></a>分类</h3><p><img src="https://cdn.jsdelivr.net/gh/liting1024/PicImage/PicgoGithub/IMG_275108A5538C-1.jpeg" alt="IMG_275108A5538C-1"></p><h3 id="朴素Dijkstra"><a href="#朴素Dijkstra" class="headerlink" title="朴素Dijkstra"></a>朴素Dijkstra</h3><p>稠密图用邻接矩阵</p><p>重边保留短边，忽略自环</p><p><img src="https://cdn.jsdelivr.net/gh/liting1024/PicImage/PicgoGithub/IMG_E4D127BD4E5A-1.jpeg" alt="IMG_E4D127BD4E5A-1"></p><pre><code class="C++">int g[N][N];  // 存储每条边int dist[N];  // 存储1号点到每个点的最短距离bool st[N];   // 存储每个点的最短路是否已经确定// 求1号点到n号点的最短路，如果不存在则返回-1int dijkstra() {    memset(dist, 0x3f, sizeof dist); //初始化 dist 为无穷    dist[1] = 0;    for (int i = 0; i &lt; n - 1; i++) {        int t = -1;     // 在还未确定最短路的点中，找距离最小的点        for (int j = 1; j &lt;= n; j++)            if (!st[j] &amp;&amp; (t == -1 || dist[t] &gt; dist[j]))                t = j;        // 用t更新其他点的距离        for (int j = 1; j &lt;= n; j++)            dist[j] = min(dist[j], dist[t] + g[t][j]);        st[t] = true;    }    if (dist[n] == 0x3f3f3f3f) return -1;    return dist[n];}</code></pre><h3 id="堆优化Dijkstra"><a href="#堆优化Dijkstra" class="headerlink" title="堆优化Dijkstra"></a>堆优化Dijkstra</h3><p>稀疏图用邻接表</p><pre><code class="C++">const int N = 510; // 太大会爆vectortypedef pair&lt;int,int&gt; PII;int n, m, dist[N], weight[N][N];memset(weight, 0x3f, sizeof weight);vector&lt;int&gt; g[N];bool st[N]; int dijkstra() {    memset(dist, 0x3f, sizeof dist);    dist[1] = 0;    priority_queue&lt;PII,vector&lt;PII&gt;,greater&lt;&gt;&gt; heap; // 小顶堆    heap.push({0,1}); // first-&gt;距离 second-&gt;点 用距离排序    while (!heap.empty()) {        auto t = heap.top();        heap.pop();        int ver = t.second, distance = t.first;        if (st[ver]) continue;        st[ver] = true        for (auto vec : g[ver]) {            if (dist[vec] &gt; distance + weight[ver][vec]) {                dist[vec] = distance + weight[ver][vec];                heap.push({dist[vec], vec});            }        }    }    if (dist[n] == 0x3f3f3f3f) return -1;    return dist[n];}</code></pre><h3 id="Bellman-Ford"><a href="#Bellman-Ford" class="headerlink" title="Bellman-Ford"></a>Bellman-Ford</h3><pre><code class="C++"></code></pre><h1 id="数学"><a href="#数学" class="headerlink" title="数学"></a>数学</h1><h2 id="数论"><a href="#数论" class="headerlink" title="数论"></a>数论</h2><h3 id="质（素）数"><a href="#质（素）数" class="headerlink" title="质（素）数"></a>质（素）数</h3><p>大于等于2的整数中，只包含1和本身这两个约数</p><p>质数判断一试除法：</p><pre><code class="C++">bool is_prime(int n) {    if (n &lt; 2) return false;    for (int i = 2; i &lt;= n/i; i++)         if (n % i == 0)        return false;  return true;}</code></pre><p>质数判断二分解质因数：</p><p>从小到大枚举n的所有因数</p><pre><code class="C++"></code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;基础算法&quot;&gt;&lt;a href=&quot;#基础算法&quot; class=&quot;headerlink&quot; title=&quot;基础算法&quot;&gt;&lt;/a&gt;基础算法&lt;/h1&gt;&lt;h2 id=&quot;排序&quot;&gt;&lt;a href=&quot;#排序&quot; class=&quot;headerlink&quot; title=&quot;排序&quot;&gt;&lt;/a&gt;排序&lt;/h</summary>
      
    
    
    
    <category term="程序设计" scheme="https://liting1024.github.io/categories/%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1/"/>
    
    
    <category term="ACM" scheme="https://liting1024.github.io/tags/ACM/"/>
    
  </entry>
  
  <entry>
    <title>Mac使用SecureCRT或终端直接连接跳板机访问内网</title>
    <link href="https://liting1024.github.io/2021/01/25/Mac%E4%BD%BF%E7%94%A8SecureCRT%E6%88%96%E7%BB%88%E7%AB%AF%E7%9B%B4%E6%8E%A5%E8%BF%9E%E6%8E%A5%E8%B7%B3%E6%9D%BF%E6%9C%BA%E8%AE%BF%E9%97%AE%E5%86%85%E7%BD%91/"/>
    <id>https://liting1024.github.io/2021/01/25/Mac%E4%BD%BF%E7%94%A8SecureCRT%E6%88%96%E7%BB%88%E7%AB%AF%E7%9B%B4%E6%8E%A5%E8%BF%9E%E6%8E%A5%E8%B7%B3%E6%9D%BF%E6%9C%BA%E8%AE%BF%E9%97%AE%E5%86%85%E7%BD%91/</id>
    <published>2021-01-25T06:28:12.000Z</published>
    <updated>2021-01-25T06:28:12.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="一、为什么使用跳板机"><a href="#一、为什么使用跳板机" class="headerlink" title="一、为什么使用跳板机"></a>一、为什么使用跳板机</h1><p>由于学校放假，使用跳板机可以连接布置在学校内网的服务器</p><h1 id="二、为什么使用SecureCRT"><a href="#二、为什么使用SecureCRT" class="headerlink" title="二、为什么使用SecureCRT"></a>二、为什么使用SecureCRT</h1><p>在尝试过Item2写expect连接跳板机后毅然决然的使用了SecureCRT<br><img src="https://cdn.jsdelivr.net/gh/liting1024/PicImage/PicgoGithub/20210125115014252.png" alt="在这里插入图片描述"><br>没有的可以私信我</p><h1 id="三、-连接方法"><a href="#三、-连接方法" class="headerlink" title="三、 连接方法"></a>三、 连接方法</h1><h2 id="1、连接跳板机"><a href="#1、连接跳板机" class="headerlink" title="1、连接跳板机"></a>1、连接跳板机</h2><p>Configuration =&gt; SSH2 =&gt; 按照图中输入跳板机数据 =&gt; OK保存后点Connect<br><img src="https://cdn.jsdelivr.net/gh/liting1024/PicImage/PicgoGithub/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phbWVzU2h1a2Vy,size_16,color_FFFFFF,t_70-20220528215712248.png" alt="在这里插入图片描述"></p><h2 id="2-tab显示绿色的对勾就表示连接成功"><a href="#2-tab显示绿色的对勾就表示连接成功" class="headerlink" title="2.tab显示绿色的对勾就表示连接成功"></a>2.tab显示绿色的对勾就表示连接成功</h2><p>直接使用ssh连接内部服务器</p><pre><code class="javascript">ssh 用户名@服务器IP</code></pre><p>会跳出一些验证，按提示回复yes即可</p><hr style=" border:solid; width:100px; height:1px;" color=#000000 size=1"><h1 id="四、-终端直连"><a href="#四、-终端直连" class="headerlink" title="四、 终端直连"></a>四、 终端直连</h1><h2 id="修改本地和跳板机上的ssh文件"><a href="#修改本地和跳板机上的ssh文件" class="headerlink" title="修改本地和跳板机上的ssh文件"></a>修改本地和跳板机上的ssh文件</h2><p>仅第一次连接时需要修改</p><pre><code class="javascript">vim ~/.ssh./config//添加以下内容Host *    ControlPersist yes    ControlMaster auto    ControlPath ~/.ssh/%n:%p</code></pre><h2 id="终端设置ssh隧道"><a href="#终端设置ssh隧道" class="headerlink" title="终端设置ssh隧道"></a>终端设置ssh隧道</h2><pre><code class="javascript">//连接跳板机作为端口转发ssh -N -f -L 6000:&lt;内网服务器ip&gt;:22 -p &lt;跳板机端口&gt; username@&lt;跳板机ip&gt; -o TCPKeepAlive=yes//登录本地的6000端口访问内网服务器ssh -p 6000 服务器用户名@localhost</code></pre><h1 id="五、使用PyCharm连接-编写代码"><a href="#五、使用PyCharm连接-编写代码" class="headerlink" title="五、使用PyCharm连接 编写代码"></a>五、使用PyCharm连接 编写代码</h1><p>1、创建新项目<br>2、选择项目解释器时选择现有解释器，添加SSH解释器<br><img src="https://cdn.jsdelivr.net/gh/liting1024/PicImage/PicgoGithub/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phbWVzU2h1a2Vy,size_16,color_FFFFFF,t_70.jpeg" alt="在这里插入图片描述"></p><p>3、设置好主机ip、端口和用户名<br><img src="https://cdn.jsdelivr.net/gh/liting1024/PicImage/PicgoGithub/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phbWVzU2h1a2Vy,size_16,color_FFFFFF,t_70-20220528215711230.png" alt="在这里插入图片描述"></p><p>4、设置服务器与本地文件共享位置</p><p>点赞的码农无BUG！</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;一、为什么使用跳板机&quot;&gt;&lt;a href=&quot;#一、为什么使用跳板机&quot; class=&quot;headerlink&quot; title=&quot;一、为什么使用跳板机&quot;&gt;&lt;/a&gt;一、为什么使用跳板机&lt;/h1&gt;&lt;p&gt;由于学校放假，使用跳板机可以连接布置在学校内网的服务器&lt;/p&gt;
&lt;h1 id</summary>
      
    
    
    
    <category term="Debug" scheme="https://liting1024.github.io/categories/Debug/"/>
    
    
  </entry>
  
</feed>
