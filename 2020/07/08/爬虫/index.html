<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">

    
    <title>爬虫 | Li Ting</title>

    <meta name="description" content="Li Ting">
    <meta name="keywords" content="">

    

    <meta property="og:locale" content="cn" />
    <meta property="og:type" content="article" />
    <meta property="og:title" content= "爬虫 | Li Ting"  />
    <meta property="og:description" content= "Li Ting" />
    <meta property="og:url" content="https://liting1024.github.io/2020/07/08/%E7%88%AC%E8%99%AB/index.html" />
    <meta property="og:site_name" content="" />
    <meta property="article:author" content="李挺" />
    <meta property="article:publisher" content="" />
    <meta property="og:description" content="Li Ting" />
    <meta name="twitter:title" content="爬虫 | Li Ting"/>
    <meta name="twitter:description" content="Li Ting"/>
    <script type="application/ld+json">
        {
            "description": "Li Ting",
            "author": { "@type": "Person", "name": "李挺" },
            "@type": "BlogPosting",
            "url": "https://liting1024.github.io/2020/07/08/%E7%88%AC%E8%99%AB/index.html",
            "publisher": {
            "@type": "Organization",
            "logo": {
                "@type": "ImageObject",
                "url": "https://liting1024.github.ioundefined"
            },
            "name": "李挺"
            },
            "headline": "爬虫 | Li Ting",
            "datePublished": "2020-07-08T15:58:00.000Z",
            "mainEntityOfPage": {
                "@type": "WebPage",
                "@id": "https://liting1024.github.io/2020/07/08/%E7%88%AC%E8%99%AB/index.html"
            },
            "@context": "http://schema.org"
        }
    </script>




    

    
    <meta property="algolia:search" data-application-id="ISC1J3PZW8" data-api-key="8ca1e8ef1083d2f2d2acee1b617e3850" data-index-name="liting_homepage">
    

    

    

    

    
    <link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css">
    

    

    
<link rel="stylesheet" href="/dist/build.css?v=1651727875408.css">


    
<link rel="stylesheet" href="/dist/custom.css?v=1651727875408.css">


    <script>
        window.isPost = true
        window.aomori = {
            
            gitalk: {
                enable: true,
                clientID: "6d0cedf1b471cbc3fb0d",
                clientSecret: "397c8d7ca7ab800dba9e60fd593649b23b6059b8",
                repo: "comments-section",
                owner: "liting1024",
                admin: ["liting1024",],
                distractionFreeMode: true  // Facebook-like distraction free mode
            },
            
            
            
        }
        window.aomori_logo_typed_animated = true
        window.aomori_search_algolia = true

    </script>

<meta name="generator" content="Hexo 4.2.0"><link rel="alternate" href="/atom.xml" title="Li Ting" type="application/atom+xml">
</head>

<body>

    <div class="container">
    <header class="header">
        <div class="header-type">
            
            <div class="header-type-inner">
                
                    <div id="typed-strings" style="display:none">
                        <p>Li Ting</p>
                    </div>
                    <a class="header-type-title" id="typed" href="/"></a>
                
    
                
            </div>
        </div>
        <div class="header-menu">
            <div class="header-menu-inner">
                
                <a href="/">首页</a>
                
                <a href="/archives">存档</a>
                
                <a href="/collection">收藏</a>
                
                <a href="/about">关于</a>
                
            </div>
            <div class="header-menu-social">
                
    <a class="social" target="_blank" href="https://github.com/liting1024">
        <box-icon type='logo' name='github'></box-icon>
    </a>

    <a class="social" target="_blank" href="jkliting@163.com">
        <box-icon type='solid' name='envelope'></box-icon>
    </a>

            </div>
        </div>

        <div class="header-menu-mobile">
            <div class="header-menu-mobile-inner" id="mobile-menu-open">
                <i class="icon icon-menu"></i>
            </div>
        </div>
    </header>

    <div class="header-menu-mobile-menu">
        <div class="header-menu-mobile-menu-bg"></div>
        <div class="header-menu-mobile-menu-wrap">
            <div class="header-menu-mobile-menu-inner">
                <div class="header-menu-mobile-menu-close" id="mobile-menu-close">
                    <i class="icon icon-cross"></i>
                </div>
                <div class="header-menu-mobile-menu-list">
                    
                    <a href="/">首页</a>
                    
                    <a href="/archives">存档</a>
                    
                    <a href="/collection">收藏</a>
                    
                    <a href="/about">关于</a>
                    
                </div>
            </div>
        </div>
    </div>

</div>

    <div class="container">
        <div class="main">
            <section class="inner">
                <section class="inner-main">
                    <div class="post">
    <article id="post-cl44991fj001couvmd0dsc13f" class="article article-type-post" itemscope
    itemprop="blogPost">

    <div class="article-inner">

        
          
        
        
        

        
        <header class="article-header">
            
  
    <h1 class="article-title" itemprop="name">
      爬虫
    </h1>
  

        </header>
        

        <div class="article-more-info article-more-info-post hairline">

            <div class="article-date">
  <time datetime="2020-07-08T15:58:00.000Z" itemprop="datePublished">2020-07-08</time>
</div>

            
            <div class="article-category">
                <a class="article-category-link" href="/categories/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/">数据挖掘</a>
            </div>
            

            
            <div class="article-tag">
                <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E7%88%AC%E8%99%AB/" rel="tag">爬虫</a></li></ul>
            </div>
            

            
            <div class="article-busuanzi">
                <span id="busuanzi_value_page_pv">N</span> 人看过
            </div>
            

        </div>

        <div class="article-entry post-inner-html hairline" itemprop="articleBody">
            <h2 id="爬取有道翻译（POST后下载）"><a href="#爬取有道翻译（POST后下载）" class="headerlink" title="爬取有道翻译（POST后下载）"></a>爬取有道翻译（POST后下载）</h2><pre><code>import ssl
ssl._create_default_https_context = ssl._create_unverified_context
# 取消SSL证书检测
import urllib.request
import urllib.parse
import json
import time
while True:
    url = &#39;http://fanyi.youdao.com/translate?smartresult=dict&amp;smartresult=rule&#39;
    data = {}
    data[&#39;i&#39;] = input(&quot;请输入翻译内容：\n&quot;)
    data[&#39;doctype&#39;] = &#39;json&#39;
    data[&#39;keyfrom&#39;] = &#39;fanyi.web&#39;
    data = urllib.parse.urlencode(data).encode(&#39;utf-8&#39;)

    response = urllib.request.Request(url, data) #POST给网站要翻译的句子
    response.add_header(&#39;User-Agent&#39;, &#39;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.138 Safari/537.36&#39;) # 伪装访问方式
    response = urllib.request.urlopen(response)
    html = response.read().decode(&#39;utf-8&#39;)
    target = json.loads(html)
    print(target[&#39;translateResult&#39;][0][0][&#39;tgt&#39;])
    time.sleep(2)</code></pre><h2 id="BeautifulSoup爬HTML"><a href="#BeautifulSoup爬HTML" class="headerlink" title="BeautifulSoup爬HTML"></a>BeautifulSoup爬HTML</h2><h3 id="查找"><a href="#查找" class="headerlink" title="查找"></a>查找</h3><p>find_all(self, name=None, attrs={‘ ‘:’ ‘}, recursive=True, text=None, limit=None, **kwargs)</p>
<p>查找所有</p>
<p>self要查找的元素</p>
<p>name目标元素的名称</p>
<p>attrs元素的属性</p>
<p>recursive查找是否在节点子树下展开</p>
<p>支持自己定义函数查找</p>
<p>find(self, name=None, attrs={‘ ‘:’ ‘}, recursive=True, text=None, limit=None, **kwargs)</p>
<p>查找第一个</p>
<pre><code>import ssl
ssl._create_default_https_context = ssl._create_unverified_context
import urllib.request
from bs4 import BeautifulSoup

try:
    url = &#39;https://liting1024.github.io/2020/02/20/Python/&#39;
    response=urllib.request.urlopen(url)
    html=response.read().decode()
    soup=BeautifulSoup(html,&#39;lxml&#39;)

    def endsWith(s,t):
        if len(s)&gt;=len(t):
            return s[len(s)-len(t):]==t
        return False
    def myFilter(tag):
        return (tag.name==&#39;a&#39; and tag.has_attr(&#39;href&#39;) and tag[&#39;href&#39;]==&#39;/category&#39; and endsWith(tag.text,&#39;ies&#39;))
    # 元素类型为a，有超链接，且超链接为/category，内容以ies结尾

    tag1=soup.find(&#39;h1&#39;)
    tag2=soup.find_all(&#39;a&#39;,attrs={&#39;class&#39;:&#39;menu-item&#39;})
    tag3=soup.find_all(myFilter)
    print(tag1,&#39;\n&#39;,tag2,&#39;\n&#39;,tag3)
    for tag in tag2:
        print(tag[&#39;href&#39;])
    for tag in tag2:
        print(tag.text)
except Exception as err:
    print(err)</code></pre><h3 id="遍历"><a href="#遍历" class="headerlink" title="遍历"></a>遍历</h3><p>tag.parent 父类树节点</p>
<p>tag.children 子节点</p>
<p>tag.descendants 所有子孙节点</p>
<p>tag.next_sibling 最近的下一个兄弟节点</p>
<p>tag.previous_sibling 上一个兄弟节点</p>
<h3 id="CSS语法查找"><a href="#CSS语法查找" class="headerlink" title="CSS语法查找"></a>CSS语法查找</h3><p>soup.select(tagName, attName=value)</p>
<table>
<thead>
<tr>
<th align="left">attName</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td align="left">attName^=value</td>
<td>以value开头匹配属性</td>
</tr>
<tr>
<td align="left">attName$=value</td>
<td>以value结尾</td>
</tr>
<tr>
<td align="left">attName*=value</td>
<td>包含指定值</td>
</tr>
</tbody></table>
<pre><code>soup.select(&quot;p a[rel=&#39;noopener&#39;]&quot;))
# 查找p下的具有rel=‘noopenner’属性的a
soup.select(&quot;p &gt; a&quot;)
# 查找p下的子节点a，不包含孙节点
soup.select(&quot;p ~ a&quot;)
# 查到p后面同级别的a</code></pre><h3 id="爬天气预报"><a href="#爬天气预报" class="headerlink" title="爬天气预报"></a>爬天气预报</h3><pre><code>import ssl
ssl._create_default_https_context = ssl._create_unverified_context
import urllib.request
from bs4 import BeautifulSoup
from bs4 import UnicodeDammit

try:
    url = &#39;http://www.weather.com.cn/weather/101080101.shtml&#39;
    headers={&quot;User-Agent&quot;:&quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.138 Safari/537.36&quot;}
    req=urllib.request.Request(url,headers=headers)
    data=urllib.request.urlopen(req)
    data=data.read()
    dammit=UnicodeDammit(data,[&#39;utf-8&#39;,&#39;gdk&#39;])
    html=dammit.unicode_markup
    # 自动选择解码
    soup=BeautifulSoup(html, &#39;lxml&#39;)
    lis=soup.select(&quot;ul[class=&#39;t clearfix&#39;] li&quot;)
    for li in lis:
        date = li.select(&#39;h1&#39;)[0].text
        weather = li.select(&quot;p[class=&#39;wea&#39;]&quot;)[0].text
        temp1 = li.select(&quot;p[class=&#39;tem&#39;] i&quot;)[0].text
        if li.select(&quot;p[class=&#39;tem&#39;] span&quot;)==[]:
            temp=temp1
            # temp2和temp1相等是无法搜索到temp2
        else:
            temp2=li.select(&quot;p[class=&#39;tem&#39;] span&quot;)[0].text
            temp=temp1+&#39;/&#39;+temp2
        print(date, weather, temp)
except Exception as err:
    print(err)</code></pre><h2 id="爬树"><a href="#爬树" class="headerlink" title="爬树"></a>爬树</h2><h3 id="深度和广度类"><a href="#深度和广度类" class="headerlink" title="深度和广度类"></a>深度和广度类</h3><pre><code>class Stack: # 列表栈，深度
    def __init__(self):
        self.st=[]
    def pop(self):
        return self.st.pop()
    def push(self,obj):
        return self.st.append(obj)
    def isempty(self):
        return len(self.st)==0

class Queue: # 队列，广度
    def __init__(self):
        self.st=[]
    def fetch(self):
        return self.st.pop(0)
    def enter(self,obj):
        return self.st.append(obj)
    def isempty(self):
        return len(self.st)==0</code></pre><h3 id="多线程"><a href="#多线程" class="headerlink" title="多线程"></a>多线程</h3><p>t = Thread(target=,args=)</p>
<p>target：要执行的函数</p>
<p>args：一个元组或列表</p>
<pre><code>from threading import Thread

t.setDaemon(False)
# 设定为后台线程
t.start()
# 启动线程
t.join()
# 阻塞当前线程，等t执行后继续执行
lock=threading._RLock()
# 设定一个锁
lock.acquire()
# lock获取线程锁，如果另一个线程调用了acquire而没有release则阻塞当前线程等待别的线程释放锁
lock.release()
# 释放锁</code></pre><h3 id="多线程爬天气网图片"><a href="#多线程爬天气网图片" class="headerlink" title="多线程爬天气网图片"></a>多线程爬天气网图片</h3><pre><code>import ssl
ssl._create_default_https_context = ssl._create_unverified_context
from bs4 import BeautifulSoup
from bs4 import UnicodeDammit
from urllib import parse
import urllib.request
import threading

def imageSpider(start_url):
    global threads
    global count
    try:
        urls=[]
        req=urllib.request.Request(start_url,headers=headers)
        data=urllib.request.urlopen(req)
        data=data.read()
        dammit=UnicodeDammit(data, [&quot;utf-8&quot;,&quot;gdk&quot;])
        data=dammit.unicode_markup
        soup=BeautifulSoup(data,&#39;lxml&#39;)
        images=soup.select(&#39;img&#39;)
        for image in images:
            src=image[&#39;src&#39;]
            url=parse.urljoin(start_url, src)
            if url not in urls:
                print(url)
                urls.append(url)
                count=count+1
                T=threading.Thread(target=download,args=(url,count))
                # 多线程运行download函数
                T.setDaemon(False)
                T.start()
                threads.append(T)
    except Exception as err:
        print(err)

def download(url,count):
    if url[len(url)-4]==&#39;.&#39;:
        ext=url[len(url)-4:]
    else:
        ext=&#39;&#39;
    req=urllib.request.Request(url, headers=headers)
    data=urllib.request.urlopen(req,timeout=100)
    data=data.read()
    fobj=open(&#39;image\\&#39;+str(count)+ext,&#39;wb&#39;)
    fobj.write(data)
    fobj.close()
    print(&#39;downloaded&#39;+str(count)+ext)

start_url=&#39;http://www.weather.com.cn/weather1d/101080101.shtml&#39;
headers={&#39;User-Agent&#39;:&#39;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.138 Safari/537.36&#39;}
count=0
threads=[]
imageSpider(start_url)
for t in threads: #多线程等待后结束主程序
    t.join()
print(&#39;END&#39;)</code></pre><h2 id="Scrapy"><a href="#Scrapy" class="headerlink" title="Scrapy"></a><a href="https://www.jianshu.com/p/a87dee628cc2" target="_blank" rel="noopener">Scrapy</a></h2><h3 id="创建简单爬虫"><a href="#创建简单爬虫" class="headerlink" title="创建简单爬虫"></a>创建简单爬虫</h3><p>在虚拟python环境中pip install scrapy</p>
<p>scrapy startproject XXX</p>
<p>生成爬虫名字为itcast，地址为itcast.cn </p>
<p>scrapy genspider itcast itcast.cn</p>
<p>启动爬虫不打印日志</p>
<p>scrapy crawl 爬虫名字 –nolog </p>
<p>在spider文件夹中建立py文件</p>
<pre><code>import scrapy

class MySpider(scrapy.Spider):
    name=&quot;mySpider&quot;

    def start_requests(self):
    # 整个函数可以用start_urls = [&#39;https://www.baidu.com&#39;]代替
        url=&#39;https://www.baidu.com&#39;
        yield scrapy.Request(url=url, callback=self.parse)
        # 访问网页回调callback函数，yield返回数据但可以不结束函数
    def parse(self, response):
        print(response.url)
        data=response.body.decode()
        print(data)</code></pre><p>在XXX文件中建立py文件</p>
<pre><code>from scrapy import cmdline

cmdline.execute(&#39;scrapy crawl mySpider -s LOG_ENABLED=False&#39;.split())</code></pre><h3 id="查找HTML元素"><a href="#查找HTML元素" class="headerlink" title="查找HTML元素"></a>查找HTML元素</h3><pre><code>from scrapy.selector import Selector

selector=Selector(text=html)
s=selector.xpath(&#39;//title&#39;)
# //表示在任何位置，/表示下一级，&#39;//body/book&#39;搜索body下一级的book
# selector.xpath(&#39;//book&#39;).xpath(&#39;/title&#39;)
# .xpath(&#39;//book&#39;).xpath(&#39;//title&#39;) 对每个book查找title
print(s)</code></pre><h4 id="解析为列表"><a href="#解析为列表" class="headerlink" title="解析为列表"></a>解析为列表</h4><p>s=selector.xpath(‘//title’).extract()</p>
<p>得到title组成的list，.extract_first()得到第一个元素</p>
<h4 id="获取属性、文本"><a href="#获取属性、文本" class="headerlink" title="获取属性、文本"></a>获取属性、文本</h4><p>s=selector.xpath(‘//title/@id’).extract()</p>
<p>获取属性值</p>
<p>s=selector.xpath(“”//title[@id=’chinese’]/text()”).extract()</p>
<p>限定id属性的值筛选</p>
<p>s=selector.xpath(‘//title/text()’).extract()</p>
<p>获取title的文本</p>
<h4 id="用-代表任何"><a href="#用-代表任何" class="headerlink" title="用*代表任何"></a>用*代表任何</h4><p>用*代替任何节点，不包括Text、Comment节点</p>
<p>s=selector.xpath(“”//title[@*]”)</p>
<p>任何属性</p>
<h4 id="position下角标"><a href="#position下角标" class="headerlink" title="position下角标"></a>position下角标</h4><p>从1开始编号</p>
<p>//body/title[position( )&gt;2] [position( )&lt;5]</p>
<p>取第三到六个title</p>
<h4 id="兄弟节点父节点"><a href="#兄弟节点父节点" class="headerlink" title="兄弟节点父节点"></a>兄弟节点父节点</h4><p>s= selector.xpath( //title[ @lang = ‘chinese ]/parent::*”)</p>
<p>查找属性为lang= chinese’的title的父节点</p>
<p>s=sclector.xpathC(“//b[position()= 1]following-sibling::* [position()=1]”)<br>搜索第一个b节点后面的第一个兄弟节点</p>
<p>“element/ollowing-sibling::*”搜索element后面的同级的所有兄弟节点</p>
<p>“element/preceding-sibling::*“搜索element 前面的同级的所有兄弟节点<br>“element/preceding-sibling::*[position()=1]”搜索element 前面的同级的第一个兄弟节<br>点</p>
<h3 id="其他py文件"><a href="#其他py文件" class="headerlink" title="其他py文件"></a>其他py文件</h3><h4 id="items-py储存数据"><a href="#items-py储存数据" class="headerlink" title="items.py储存数据"></a>items.py储存数据</h4><p>items中建立用于储存数据的类</p>
<pre><code>class YourprojectItem(scrapy.Item): # 继承scrapy.Item
    # define the fields for your item here like:
    # name = scrapy.Field()
    title=scrapy.Field()</code></pre><p>在spiders中的爬虫中应用这个类</p>
<pre><code>from yourProject.items import YourprojectItem

class MySpider(scrapy.Spider):
    name=&quot;mySpider&quot;
    start_urls = [&#39;https://www.baidu.com&#39;]

    def parse(self, response):
        data=response.body.decode()
        selector=scrapy.Selector(text=data)
        books=selector.xpath(&quot;//book&quot;)
        for book in books:
            item=YourprojectItem()
            item[&quot;title&quot;]=book.xpath(&quot;./title/text()&quot;).extract_first()
            yield item</code></pre><h4 id="pipelines-py数据管道处理类"><a href="#pipelines-py数据管道处理类" class="headerlink" title="pipelines.py数据管道处理类"></a>pipelines.py数据管道处理类</h4><p>在settings.py中取消注释</p>
<p>ITEM_PIPELINES = {</p>
<p>​    ‘yourProject.pipelines.YourprojectPipeline’: 300,</p>
<p>}</p>
<p>爬取一次数据，调用一次process_item函数</p>
<pre><code>from itemadapter import ItemAdapter

class YourprojectPipeline(object):
    count = 0
    def process_item(self, item, spider):
        YourprojectPipeline.count+=1
        if YourprojectPipeline.count==1:
            fobj=open(&quot;book.txt&quot;,&quot;wb&quot;)
        else:
            fobj=open(&quot;book.txt&quot;,&quot;at&quot;)
        print(item[&quot;title&quot;])
        fobj.write(item[&#39;title&#39;])
        fobj.close()
        return item</code></pre><h3 id="爬取当当网图书数据"><a href="#爬取当当网图书数据" class="headerlink" title="爬取当当网图书数据"></a>爬取当当网图书数据</h3>
        </div>

    </div>

    

    

    

    

    

    
<nav class="article-nav">
  
    <a href="/2021/01/25/Mac%E4%BD%BF%E7%94%A8SecureCRT%E6%88%96%E7%BB%88%E7%AB%AF%E7%9B%B4%E6%8E%A5%E8%BF%9E%E6%8E%A5%E8%B7%B3%E6%9D%BF%E6%9C%BA%E8%AE%BF%E9%97%AE%E5%86%85%E7%BD%91/" id="article-nav-newer" class="article-nav-link-wrap">
      <div class="article-nav-caption">下一篇</div>
      <div class="article-nav-title">
        
          Mac使用SecureCRT或终端直接连接跳板机访问内网
        
      </div>
    </a>
  
  
    <a href="/2020/05/27/%E6%9B%B4%E6%8D%A2Aomori%E4%B8%BB%E9%A2%98/" id="article-nav-older" class="article-nav-link-wrap">
      <div class="article-nav-caption">上一篇</div>
      <div class="article-nav-title">更换Aomori主题</div>
    </a>
  
</nav>


    <section class="share">
        <div class="share-title">分享</div>
        <a class="share-item" target="_blank"
            href="https://twitter.com/share?text=爬虫 - Li Ting&url=https%3A%2F%2Fliting1024.github.io%2F2020%2F07%2F08%2F%25E7%2588%25AC%25E8%2599%25AB%2F">
            <box-icon type='logo' name='twitter'></box-icon>
        </a>
        <a class="share-item" target="_blank"
            href="https://service.weibo.com/share/share.php?title=爬虫 - Li Ting&url=https://liting1024.github.io/2020/07/08/%E7%88%AC%E8%99%AB/&pic=">
            <div class="n-icon n-icon-weibo"></div>
        </a>
    </section>

</article>








<section class="comments">
    <div id="gitalk-container"></div>
</section>









<script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

</div>
                </section>
            </section>

            
            <aside class="sidebar sidebar-search-fix">
                

    <div class="search">
    <div class="has-icon-right">
        <input type="text" class="form-input" id="search" placeholder="SEARCH" autocomplete="off">
        <div class="form-icon">
            <box-icon name='search' color="#3c4859"></box-icon>
        </div>
    </div>
    <div class="search-result" id="search-ps"></div>
</div>


<div class="widget" id="widget">
    
      
  <div class="widget-wrap">
    <div class="widget-inner">
      <div class="toc post-toc-html"></div>
    </div>
  </div>

    
      
  <div class="widget-wrap widget-recent-posts">
    <div class="widget-title"><span>Recent Posts</span></div>
    <div class="widget-inner">
      <ul>
        
          <li>
            <a href="/2022/06/07/DateMinder/">【项目详情】DateMinder</a>
          </li>
        
          <li>
            <a href="/2022/05/27/jiezi/">【项目详情】解字</a>
          </li>
        
          <li>
            <a href="/2022/05/26/CLIP/">CLIP</a>
          </li>
        
          <li>
            <a href="/2022/01/27/STL/">STL</a>
          </li>
        
          <li>
            <a href="/2022/01/13/ACM%E7%BB%8F%E9%AA%8C/">ACM经验</a>
          </li>
        
      </ul>
    </div>
  </div>

    
      
  <div class="widget-wrap widget-archive">
    <div class="widget-title"><span>Archive</span></div>
    <div class="widget-inner">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/">2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/">2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/">2020</a></li></ul>
    </div>
  </div>


    
      
  <div class="widget-wrap widget-tags">
    <div class="widget-title"><span>Tags</span></div>
    <div class="widget-inner">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/ACM/" rel="tag">ACM</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/C/" rel="tag">C++</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%88%AC%E8%99%AB/" rel="tag">爬虫</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%AF%BB%E8%AE%BA%E6%96%87/" rel="tag">读论文</a></li></ul>
    </div>
  </div>


    
      
  <div class="widget-wrap widget-cate">
    <div class="widget-title"><span>Categories</span></div>
    <div class="widget-inner">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Debug/">Debug</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91/">应用开发</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/">数据挖掘</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1/">程序设计</a></li></ul>
    </div>
  </div>


    
</div>

<div id="backtop"><i class="icon icon-arrow-up"></i></div>
            </aside>
            
        </div>
    </div>

    <footer class="footer">
    <div class="footer-wave">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 1440 320"><path fill="#3c4859" fill-opacity="1" d="M0,160L60,181.3C120,203,240,245,360,240C480,235,600,181,720,186.7C840,192,960,256,1080,261.3C1200,267,1320,213,1380,186.7L1440,160L1440,320L1380,320C1320,320,1200,320,1080,320C960,320,840,320,720,320C600,320,480,320,360,320C240,320,120,320,60,320L0,320Z"></path></svg>
    </div>

    <!-- Please do not remove this -->
    <!-- 开源不易，请勿删除 -->
    <div class="footer-wrap">
        <div class="footer-inner"> 
            Li Ting &copy; 2022<br>
            Powered By Hexo · Theme By <a href="https://linhong.me/" target="_blank">Aomori</a> · <a href="https://github.com/lh1me/hexo-theme-aomori" target="_blank">Github</a>
        </div>
    </div>

</footer>


<script src="https://unpkg.com/gitalk/dist/gitalk.min.js"></script>





<script src="/dist/build.js?1651727875408.js"></script>


<script src="/dist/custom.js?1651727875408.js"></script>



<!-- 百度链接提交 -->
<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        }
        else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>











</body>

</html>