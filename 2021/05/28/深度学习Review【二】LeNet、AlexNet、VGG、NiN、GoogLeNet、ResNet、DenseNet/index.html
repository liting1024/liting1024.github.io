<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">

    
    <title>深度学习Review【二】LeNet、AlexNet、VGG、NiN、GoogLeNet、ResNet、DenseNet | Li Ting</title>

    <meta name="description" content="Li Ting">
    <meta name="keywords" content="">

    

    <meta property="og:locale" content="cn" />
    <meta property="og:type" content="article" />
    <meta property="og:title" content= "深度学习Review【二】LeNet、AlexNet、VGG、NiN、GoogLeNet、ResNet、DenseNet | Li Ting"  />
    <meta property="og:description" content= "Li Ting" />
    <meta property="og:url" content="https://liting1024.github.io/2021/05/28/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0Review%E3%80%90%E4%BA%8C%E3%80%91LeNet%E3%80%81AlexNet%E3%80%81VGG%E3%80%81NiN%E3%80%81GoogLeNet%E3%80%81ResNet%E3%80%81DenseNet/index.html" />
    <meta property="og:site_name" content="" />
    <meta property="article:author" content="李挺" />
    <meta property="article:publisher" content="" />
    <meta property="og:description" content="Li Ting" />
    <meta name="twitter:title" content="深度学习Review【二】LeNet、AlexNet、VGG、NiN、GoogLeNet、ResNet、DenseNet | Li Ting"/>
    <meta name="twitter:description" content="Li Ting"/>
    <script type="application/ld+json">
        {
            "description": "Li Ting",
            "author": { "@type": "Person", "name": "李挺" },
            "@type": "BlogPosting",
            "url": "https://liting1024.github.io/2021/05/28/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0Review%E3%80%90%E4%BA%8C%E3%80%91LeNet%E3%80%81AlexNet%E3%80%81VGG%E3%80%81NiN%E3%80%81GoogLeNet%E3%80%81ResNet%E3%80%81DenseNet/index.html",
            "publisher": {
            "@type": "Organization",
            "logo": {
                "@type": "ImageObject",
                "url": "https://liting1024.github.ioundefined"
            },
            "name": "李挺"
            },
            "headline": "深度学习Review【二】LeNet、AlexNet、VGG、NiN、GoogLeNet、ResNet、DenseNet | Li Ting",
            "datePublished": "2021-05-28T13:45:31.000Z",
            "mainEntityOfPage": {
                "@type": "WebPage",
                "@id": "https://liting1024.github.io/2021/05/28/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0Review%E3%80%90%E4%BA%8C%E3%80%91LeNet%E3%80%81AlexNet%E3%80%81VGG%E3%80%81NiN%E3%80%81GoogLeNet%E3%80%81ResNet%E3%80%81DenseNet/index.html"
            },
            "@context": "http://schema.org"
        }
    </script>




    

    
    <meta property="algolia:search" data-application-id="ISC1J3PZW8" data-api-key="8ca1e8ef1083d2f2d2acee1b617e3850" data-index-name="liting_homepage">
    

    

    

    

    
    <link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css">
    

    

    
<link rel="stylesheet" href="/dist/build.css?v=1651727875408.css">


    
<link rel="stylesheet" href="/dist/custom.css?v=1651727875408.css">


    <script>
        window.isPost = true
        window.aomori = {
            
            gitalk: {
                enable: true,
                clientID: "6d0cedf1b471cbc3fb0d",
                clientSecret: "397c8d7ca7ab800dba9e60fd593649b23b6059b8",
                repo: "comments-section",
                owner: "liting1024",
                admin: ["liting1024",],
                distractionFreeMode: true  // Facebook-like distraction free mode
            },
            
            
            
        }
        window.aomori_logo_typed_animated = true
        window.aomori_search_algolia = true

    </script>

<meta name="generator" content="Hexo 4.2.0"><link rel="alternate" href="/atom.xml" title="Li Ting" type="application/atom+xml">
</head>

<body>

    <div class="container">
    <header class="header">
        <div class="header-type">
            
            <div class="header-type-inner">
                
                    <div id="typed-strings" style="display:none">
                        <p>Li Ting</p>
                    </div>
                    <a class="header-type-title" id="typed" href="/"></a>
                
    
                
            </div>
        </div>
        <div class="header-menu">
            <div class="header-menu-inner">
                
                <a href="/">首页</a>
                
                <a href="/archives">存档</a>
                
                <a href="/collection">收藏</a>
                
                <a href="/about">关于</a>
                
            </div>
            <div class="header-menu-social">
                
    <a class="social" target="_blank" href="https://github.com/liting1024">
        <box-icon type='logo' name='github'></box-icon>
    </a>

    <a class="social" target="_blank" href="mailto:jkliting@163.com">
        <box-icon type='solid' name='envelope'></box-icon>
    </a>

            </div>
        </div>

        <div class="header-menu-mobile">
            <div class="header-menu-mobile-inner" id="mobile-menu-open">
                <i class="icon icon-menu"></i>
            </div>
        </div>
    </header>

    <div class="header-menu-mobile-menu">
        <div class="header-menu-mobile-menu-bg"></div>
        <div class="header-menu-mobile-menu-wrap">
            <div class="header-menu-mobile-menu-inner">
                <div class="header-menu-mobile-menu-close" id="mobile-menu-close">
                    <i class="icon icon-cross"></i>
                </div>
                <div class="header-menu-mobile-menu-list">
                    
                    <a href="/">首页</a>
                    
                    <a href="/archives">存档</a>
                    
                    <a href="/collection">收藏</a>
                    
                    <a href="/about">关于</a>
                    
                </div>
            </div>
        </div>
    </div>

</div>

    <div class="container">
        <div class="main">
            <section class="inner">
                <section class="inner-main">
                    <div class="post">
    <article id="post-cla9j39uc001v4qvm9jxj1az3" class="article article-type-post" itemscope
    itemprop="blogPost">

    <div class="article-inner">

        
          
        
        
        

        
        <header class="article-header">
            
  
    <h1 class="article-title" itemprop="name">
      深度学习Review【二】LeNet、AlexNet、VGG、NiN、GoogLeNet、ResNet、DenseNet
    </h1>
  

        </header>
        

        <div class="article-more-info article-more-info-post hairline">

            <div class="article-date">
  <time datetime="2021-05-28T13:45:31.000Z" itemprop="datePublished">2021-05-28</time>
</div>

            
            <div class="article-category">
                <a class="article-category-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a>
            </div>
            

            

            
            <div class="article-busuanzi">
                <span id="busuanzi_value_page_pv">N</span> 人看过
            </div>
            

        </div>

        <div class="article-entry post-inner-html hairline" itemprop="articleBody">
            <blockquote>
<p><a href="https://zh-v2.d2l.ai/chapter_multilayer-perceptrons/mlp-concise.html" target="_blank" rel="noopener">课程地址</a></p>
</blockquote>
<h1 id="一、LeNet"><a href="#一、LeNet" class="headerlink" title="一、LeNet"></a>一、LeNet</h1><p>手写数字识别（MNIST）<br><img src="https://cdn.jsdelivr.net/gh/liting1024/PicImage/PicgoGithub/512cd1b1e7c840acb4eabbffd3d6923a.png" alt="在这里插入图片描述"><br>使用了Conv2d、AvgPooling、Linear<br>高宽减半时通道数翻倍，保证信息能匹配更多的模式（将信息分配到多个通道）<br>输入超过100x100时MLP不如CNN，输入少时mlp更快</p>
<h2 id="torch实现"><a href="#torch实现" class="headerlink" title="torch实现"></a>torch实现</h2><pre><code class="python">import torch
from torch import nn
from d2l import torch as d2l
#使用类可以放在Sequential里
class Reshape(torch.nn.Module):
    def forward(self, x):
        return x.view(-1, 1, 28, 28)

net = torch.nn.Sequential(
    Reshape(),
    nn.Conv2d(1, 6, kernel_size=5, padding=2), nn.Sigmoid(),#窗口5x5，由于数据集是28x28和论文中32x32不同，所以padding了2
    nn.AvgPool2d(kernel_size=2, stride=2),#stride=2防止2x2的窗口重叠
    nn.Conv2d(6, 16, kernel_size=5), nn.Sigmoid(),
    nn.AvgPool2d(kernel_size=2, stride=2),#输出为16*5*5
    nn.Flatten(),#把16x5x5拉长变成1维的1x400
    nn.Linear(16 * 5 * 5, 120), nn.Sigmoid(),
    nn.Linear(120, 84), nn.Sigmoid(),nn.Linear(84, 10))#最后输出1*10的向量
    #去掉了高斯层
batch_size = 256
train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size=batch_size)

def evaluate_accuracy_gpu(net, data_iter, device=None):
    &quot;&quot;&quot;使用GPU计算模型在数据集上的精度。&quot;&quot;&quot;
    if isinstance(net, torch.nn.Module):
        net.eval()  # 设置为评估模式
        if not device: #未设置device就看net的第一个参数的device
            device = next(iter(net.parameters())).device
    # 正确预测的数量，总预测的数量
    metric = d2l.Accumulator(2)
    for X, y in data_iter:
        if isinstance(X, list):
            # BERT微调所需的（之后将介绍）
            X = [x.to(device) for x in X]
        else:
            X = X.to(device)
        y = y.to(device)
        metric.add(d2l.accuracy(net(X), y), y.numel())
    return metric[0] / metric[1] #分类正确的个数/所有
#lr为学习率
def train_ch6(net, train_iter, test_iter, num_epochs, lr, device):
    &quot;&quot;&quot;用GPU训练模型(在第六章定义)&quot;&quot;&quot;
    def init_weights(m): #初始化权重
        if type(m) == nn.Linear or type(m) == nn.Conv2d:
            nn.init.xavier_uniform_(m.weight) #线性回归和二维卷积自动初始化权重（卷积核）
    net.apply(init_weights)
    print(&#39;training on&#39;, device)
    net.to(device)#搬入GPU
    optimizer = torch.optim.SGD(net.parameters(), lr=lr)
    loss = nn.CrossEntropyLoss()
    #使用动画方便查看结果
    animator = d2l.Animator(xlabel=&#39;epoch&#39;, xlim=[1, num_epochs],
                            legend=[&#39;train loss&#39;, &#39;train acc&#39;, &#39;test acc&#39;])
    timer, num_batches = d2l.Timer(), len(train_iter)
    for epoch in range(num_epochs):
        # 训练损失之和，训练准确率之和，范例数
        metric = d2l.Accumulator(3)
        net.train()
        for i, (X, y) in enumerate(train_iter):
            timer.start()
            optimizer.zero_grad()
            X, y = X.to(device), y.to(device)#把输入输出放在GPU上
            y_hat = net(X)
            l = loss(y_hat, y)
            l.backward()
            optimizer.step()
            with torch.no_grad():
                metric.add(l * X.shape[0], d2l.accuracy(y_hat, y), X.shape[0])
            timer.stop()
            train_l = metric[0] / metric[2]
            train_acc = metric[1] / metric[2]
            if (i + 1) % (num_batches // 5) == 0 or i == num_batches - 1:
                animator.add(epoch + (i + 1) / num_batches,
                             (train_l, train_acc, None))
        test_acc = evaluate_accuracy_gpu(net, test_iter)
        animator.add(epoch + 1, (None, None, test_acc))
    print(f&#39;loss {train_l:.3f}, train acc {train_acc:.3f}, &#39;
          f&#39;test acc {test_acc:.3f}&#39;)
    print(f&#39;{metric[2] * num_epochs / timer.sum():.1f} examples/sec &#39;
          f&#39;on {str(device)}&#39;)</code></pre>
<p>图片的学习结果 <a href="http://poloclub.github.io/cnn-explainer/" target="_blank" rel="noopener">http://poloclub.github.io/cnn-explainer/</a></p>
<h1 id="二、AlexNet"><a href="#二、AlexNet" class="headerlink" title="二、AlexNet"></a>二、AlexNet</h1><p>数据集：ImageNet 自然物体彩色图片</p>
<h2 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h2><p>更深更大的LeNet<br>使用了丢弃法（正则化）、ReLU（减缓梯度消失）、MaxPooling（扩大梯度更容易训练）、隐藏全连接层后（Dense/FC 4096后）加入丢弃层<br> <img src="https://cdn.jsdelivr.net/gh/liting1024/PicImage/PicgoGithub/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phbWVzU2h1a2Vy,size_16,color_FFFFFF,t_70-20220528215030179.png" alt="在这里插入图片描述"></p>
<h2 id="torch实现-1"><a href="#torch实现-1" class="headerlink" title="torch实现"></a>torch实现</h2><pre><code class="python">import torch
from torch import nn
from d2l import torch as d2l

net = nn.Sequential(
    # 步幅为4，以减少输出的高度和宽度 输出通道 96
    nn.Conv2d(1, 96, kernel_size=11, stride=4, padding=1), nn.ReLU(),
    nn.MaxPool2d(kernel_size=3, stride=2),
    # 减小卷积窗口，使用填充为2来使得输入与输出的高和宽一致，且增大输出通道数
    nn.Conv2d(96, 256, kernel_size=5, padding=2), nn.ReLU(),
    nn.MaxPool2d(kernel_size=3, stride=2),
    # 使用三个连续的卷积层和较小的卷积窗口 除了最后的卷积层，输出通道的数量进一步增加。
    # 在前两个卷积层之后，汇聚层不用于减少输入的高度和宽度
    nn.Conv2d(256, 384, kernel_size=3, padding=1), nn.ReLU(),
    nn.Conv2d(384, 384, kernel_size=3, padding=1), nn.ReLU(),
    nn.Conv2d(384, 256, kernel_size=3, padding=1), nn.ReLU(),
    nn.MaxPool2d(kernel_size=3, stride=2),
    nn.Flatten(),
    # 这里，全连接层的输出数量是LeNet中的好几倍。使用dropout层来减轻过度拟合
    nn.Linear(6400, 4096), nn.ReLU(),
    nn.Dropout(p=0.5),
    nn.Linear(4096, 4096), nn.ReLU(),
    nn.Dropout(p=0.5), # 丢弃了50%
    # 最后是输出层。使用Fashion-MNIST，类别数为10，论文中是1000
    nn.Linear(4096, 10))

batch_size = 128
train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=224)

lr, num_epochs = 0.01, 10
#train_ch6定义在上
d2l.train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())</code></pre>
<h1 id="三、VGG"><a href="#三、VGG" class="headerlink" title="三、VGG"></a>三、VGG</h1><p>为了让模型更深更大，使用更多的卷积层，将卷积层组成块，重复使用这些卷积块<br>更深的模型 窗口更小 效果更好<br><img src="https://cdn.jsdelivr.net/gh/liting1024/PicImage/PicgoGithub/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phbWVzU2h1a2Vy,size_16,color_FFFFFF,t_70-20220528215030263.png" alt="在这里插入图片描述"></p>
<h2 id="结构"><a href="#结构" class="headerlink" title="结构"></a>结构</h2><p>原始 VGG 网络有 5 个卷积块，其中前两个块各有一个卷积层，后三个块各包含两个卷积层。<br>第一个模块有 64 个输出通道，每个后续模块将输出通道数量翻倍，直到该数字达到 512。由于该网络使用 8 个卷积层和 3 个全连接层，因此它被称为 VGG-11</p>
<h2 id="torch实现-2"><a href="#torch实现-2" class="headerlink" title="torch实现"></a>torch实现</h2><pre><code class="python">import torch
from torch import nn
from d2l import torch as d2l

def vgg_block(num_convs, in_channels, out_channels):
    layers = []
    for _ in range(num_convs):
        layers.append(nn.Conv2d(in_channels, out_channels,
                                kernel_size=3, padding=1))
        layers.append(nn.ReLU())
        in_channels = out_channels
    layers.append(nn.MaxPool2d(kernel_size=2,stride=2))
    return nn.Sequential(*layers)

conv_arch = ((1, 64), (1, 128), (2, 256), (2, 512), (2, 512))

def vgg(conv_arch):
    conv_blks = []
    in_channels = 1
    # 卷积层部分
    for (num_convs, out_channels) in conv_arch:
        conv_blks.append(vgg_block(num_convs, in_channels, out_channels))
        in_channels = out_channels

    return nn.Sequential(
        *conv_blks, nn.Flatten(),
        # 全连接层部分 224
        nn.Linear(out_channels * 7 * 7, 4096), nn.ReLU(), nn.Dropout(0.5),
        nn.Linear(4096, 4096), nn.ReLU(), nn.Dropout(0.5),
        nn.Linear(4096, 10))

net = vgg(conv_arch)

ratio = 4 #将通道数除以4 以方便训练
small_conv_arch = [(pair[0], pair[1] // ratio) for pair in conv_arch]
net = vgg(small_conv_arch)

lr, num_epochs, batch_size = 0.05, 10, 128
train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=224)
d2l.train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())</code></pre>
<h1 id="四、NiN"><a href="#四、NiN" class="headerlink" title="四、NiN"></a>四、NiN</h1><p>网络中的网络</p>
<h2 id="思路、结构"><a href="#思路、结构" class="headerlink" title="思路、结构"></a>思路、结构</h2><p>全连接层会导致过拟合，用卷积层替代全连接层<br>使用NiN块，一个卷积层+两个卷积层（卷积核为1x1、步幅为1、无填充、输出形状和卷积层输出一致（不改变输出和通道数）），来代替全连接层<br>交替使用NiN块和步幅为2的最大池化层（逐步减小高宽 增大通道数），最后用全局平均池化层替代非常大的全连接层得到输出<br><img src="https://cdn.jsdelivr.net/gh/liting1024/PicImage/PicgoGithub/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phbWVzU2h1a2Vy,size_16,color_FFFFFF,t_70-20220528215030176.png" alt="在这里插入图片描述"></p>
<h2 id="torch实现-3"><a href="#torch实现-3" class="headerlink" title="torch实现"></a>torch实现</h2><pre><code class="python">import torch
from torch import nn
from d2l import torch as d2l

def nin_block(in_channels, out_channels, kernel_size, strides, padding):
    return nn.Sequential(
        nn.Conv2d(in_channels, out_channels, kernel_size, strides, padding),nn.ReLU(),
        #输入输出通道数相同
        nn.Conv2d(out_channels, out_channels, kernel_size=1), nn.ReLU(),
        nn.Conv2d(out_channels, out_channels, kernel_size=1), nn.ReLU())

net = nn.Sequential(
    nin_block(1, 96, kernel_size=11, strides=4, padding=0),
    nn.MaxPool2d(3, stride=2),
    nin_block(96, 256, kernel_size=5, strides=1, padding=2),
    nn.MaxPool2d(3, stride=2),
    nin_block(256, 384, kernel_size=3, strides=1, padding=1),
    nn.MaxPool2d(3, stride=2),
    nn.Dropout(0.5),
    # MNIST的类别数是10，输出降到10即可
    nin_block(384, 10, kernel_size=3, strides=1, padding=1),
    nn.AdaptiveAvgPool2d((1, 1)),
    # 将四维的输出转成二维的输出，其形状为(批量大小, 10)
    nn.Flatten())

lr, num_epochs, batch_size = 0.1, 10, 128
train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=224)
#内含有Softmax
d2l.train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())</code></pre>
<h1 id="五、GoogLeNet"><a href="#五、GoogLeNet" class="headerlink" title="五、GoogLeNet"></a>五、GoogLeNet</h1><p>并行连接的网络</p>
<h2 id="Inception块"><a href="#Inception块" class="headerlink" title="Inception块"></a>Inception块</h2><p>将输入的通道分为4份<br>为每个通道使用不同窗口大小和padding的卷积层<br>最后的输出高宽相同<br>减少计算量<br><img src="https://cdn.jsdelivr.net/gh/liting1024/PicImage/PicgoGithub/e1aeffe2ab1243f0a52877f7c9d9242c.png" alt="在这里插入图片描述"></p>
<h2 id="GoogLeNet"><a href="#GoogLeNet" class="headerlink" title="GoogLeNet"></a>GoogLeNet</h2><p>保留更多高宽<br>9个Inception块<br>每个Stage将高宽减半<br>使用全局平均池化<br><img src="https://cdn.jsdelivr.net/gh/liting1024/PicImage/PicgoGithub/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phbWVzU2h1a2Vy,size_16,color_FFFFFF,t_70-20220528215030177.png" alt="在这里插入图片描述"><br>Stage1&amp;2：更小的核 更小的输出通道<br><img src="https://cdn.jsdelivr.net/gh/liting1024/PicImage/PicgoGithub/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phbWVzU2h1a2Vy,size_16,color_FFFFFF,t_70-20220528215030148.png" alt="在这里插入图片描述"></p>
<p>Stage3：输出通道增加<br><img src="https://cdn.jsdelivr.net/gh/liting1024/PicImage/PicgoGithub/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phbWVzU2h1a2Vy,size_16,color_FFFFFF,t_70-20220528215030261.png" alt="在这里插入图片描述"></p>
<p>Stage4&amp;5：增加通道数 最后输出1024维特征</p>
<p><img src="https://cdn.jsdelivr.net/gh/liting1024/PicImage/PicgoGithub/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phbWVzU2h1a2Vy,size_16,color_FFFFFF,t_70-20220528215030254.png" alt="在这里插入图片描述"></p>
<h2 id="Inception变种"><a href="#Inception变种" class="headerlink" title="Inception变种"></a>Inception变种</h2><p>Inception-BN（V2） 加入batch normalization</p>
<p>Inception-V3 替换卷积层，消耗内存较多，精度提升<br>把Inception块中的 5x5 替换为多个 3x3 的卷积层（或者1x7和7x1）、把 3x3 换为 1x3 和 3x1 的卷积层<br><img src="https://cdn.jsdelivr.net/gh/liting1024/PicImage/PicgoGithub/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phbWVzU2h1a2Vy,size_16,color_FFFFFF,t_70-20220528215030261-3745830.png" alt="在这里插入图片描述"><br><img src="watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phbWVzU2h1a2Vy,size_16,color_FFFFFF,t_70-20220528215030260.png" alt="在这里插入图片描述"></p>
<p>Inception-V4 添加残差块连接</p>
<h2 id="torch实现-4"><a href="#torch实现-4" class="headerlink" title="torch实现"></a>torch实现</h2><pre><code class="python">import torch
from torch import nn
from torch.nn import functional as F
from d2l import torch as d2l

class Inception(nn.Module):
    # `c1`--`c4` 是每条路径的输出通道数
    def __init__(self, in_channels, c1, c2, c3, c4, **kwargs):
        super(Inception, self).__init__(**kwargs)
        # 线路1，单1 x 1卷积层
        self.p1_1 = nn.Conv2d(in_channels, c1, kernel_size=1)
        # 线路2，1 x 1卷积层后接3 x 3卷积层
        self.p2_1 = nn.Conv2d(in_channels, c2[0], kernel_size=1)
        self.p2_2 = nn.Conv2d(c2[0], c2[1], kernel_size=3, padding=1)
        # 线路3，1 x 1卷积层后接5 x 5卷积层
        self.p3_1 = nn.Conv2d(in_channels, c3[0], kernel_size=1)
        self.p3_2 = nn.Conv2d(c3[0], c3[1], kernel_size=5, padding=2)
        # 线路4，3 x 3最大汇聚层后接1 x 1卷积层
        self.p4_1 = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)
        self.p4_2 = nn.Conv2d(in_channels, c4, kernel_size=1)
    def forward(self, x):
        p1 = F.relu(self.p1_1(x))
        p2 = F.relu(self.p2_2(F.relu(self.p2_1(x))))
        p3 = F.relu(self.p3_2(F.relu(self.p3_1(x))))
        p4 = F.relu(self.p4_2(self.p4_1(x)))
        # 在通道维度上拼接输出
        return torch.cat((p1, p2, p3, p4), dim=1)

b1 = nn.Sequential(nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3),
                   nn.ReLU(),
                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))
b2 = nn.Sequential(nn.Conv2d(64, 64, kernel_size=1),
                   nn.ReLU(),
                   nn.Conv2d(64, 192, kernel_size=3, padding=1),
                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))
b3 = nn.Sequential(Inception(192, 64, (96, 128), (16, 32), 32),
                   Inception(256, 128, (128, 192), (32, 96), 64),
                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))
b4 = nn.Sequential(Inception(480, 192, (96, 208), (16, 48), 64),
                   Inception(512, 160, (112, 224), (24, 64), 64),
                   Inception(512, 128, (128, 256), (24, 64), 64),
                   Inception(512, 112, (144, 288), (32, 64), 64),
                   Inception(528, 256, (160, 320), (32, 128), 128),
                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))
b5 = nn.Sequential(Inception(832, 256, (160, 320), (32, 128), 128),
                   Inception(832, 384, (192, 384), (48, 128), 128),
                   nn.AdaptiveAvgPool2d((1,1)),
                   nn.Flatten())

net = nn.Sequential(b1, b2, b3, b4, b5, nn.Linear(1024, 10))
lr, num_epochs, batch_size = 0.1, 10, 128
train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=96)
d2l.train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())</code></pre>
<h1 id="六、批量归一化"><a href="#六、批量归一化" class="headerlink" title="六、批量归一化"></a>六、批量归一化</h1><p>对于很深的神经网络，损失出现在最后，但数据在底部；当底部层发生变化所有层都要跟着改变，因此最后的那些层会重新学习很多次，导致loss收敛变慢。<br>一般作用在全连接层和卷积层的输出上，激活函数之前；全连接层和卷积层输入上<br>对于全连接层，作用在特征维；对于卷积层，作用在通道维。<br>由于是在每个小批量里加入噪音控制模型复杂度，因此不必和Dropout混用。 </p>
<h2 id="思想"><a href="#思想" class="headerlink" title="思想"></a>思想</h2><p>固定小批量里的均值和方差，然后学习出适合的偏移和缩放，以加快收敛<br><img src="https://cdn.jsdelivr.net/gh/liting1024/PicImage/PicgoGithub/3524edcea5e443bb9a103cb17ac75a4c.png" alt="在这里插入图片描述"><br>方差和均值是可学习的参数，控制着做小量的调整（线性变换）<br><img src="https://cdn.jsdelivr.net/gh/liting1024/PicImage/PicgoGithub/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phbWVzU2h1a2Vy,size_16,color_FFFFFF,t_70-20220528215030304.png" alt="在这里插入图片描述"></p>
<h1 id="七、残差网络ResNet"><a href="#七、残差网络ResNet" class="headerlink" title="七、残差网络ResNet"></a>七、残差网络ResNet</h1><p>加更多的层不一定能距离最优点更近</p>
<h2 id="残差块"><a href="#残差块" class="headerlink" title="残差块"></a>残差块</h2><p>加入快速通道来得到 f(x) = x + g(x)，由于g(x)在反向传播，层层求梯度之后可能变得非常小，所有将x加在这里，防止变成0而消失。<br><img src="https://cdn.jsdelivr.net/gh/liting1024/PicImage/PicgoGithub/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phbWVzU2h1a2Vy,size_16,color_FFFFFF,t_70-20220528215030342.png" alt="在这里插入图片描述"><br>也可以用1x1的Conv调整通道和分辨率<br><img src="watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phbWVzU2h1a2Vy,size_16,color_FFFFFF,t_70-20220528215030347.png" alt="在这里插入图片描述"></p>
<p>可以有各种各样的排列形式<br><img src="https://cdn.jsdelivr.net/gh/liting1024/PicImage/PicgoGithub/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phbWVzU2h1a2Vy,size_16,color_FFFFFF,t_70-20220528215030318.png" alt="在这里插入图片描述"><br>多个块拼接成ResNet，每个块高宽减半（strides = 2）<br><img src="https://cdn.jsdelivr.net/gh/liting1024/PicImage/PicgoGithub/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phbWVzU2h1a2Vy,size_16,color_FFFFFF,t_70-20220528215030365.png" alt="在这里插入图片描述"></p>
<h2 id="torch实现-5"><a href="#torch实现-5" class="headerlink" title="torch实现"></a>torch实现</h2><pre><code class="python">import torch
from torch import nn
from torch.nn import functional as F
from d2l import torch as d2l


class Residual(nn.Module):  #@save
    def __init__(self, input_channels, num_channels,
                 use_1x1conv=False, strides=1):
        #use1x1是否使用1x1的卷积层
        super().__init__()
        self.conv1 = nn.Conv2d(input_channels, num_channels,
                               kernel_size=3, padding=1, stride=strides)
        self.conv2 = nn.Conv2d(num_channels, num_channels,
                               kernel_size=3, padding=1)
        if use_1x1conv:
            self.conv3 = nn.Conv2d(input_channels, num_channels,
                                   kernel_size=1, stride=strides)
        else:
            self.conv3 = None
        self.bn1 = nn.BatchNorm2d(num_channels)
        self.bn2 = nn.BatchNorm2d(num_channels)
        self.relu = nn.ReLU(inplace=True)

    def forward(self, X):
        Y = F.relu(self.bn1(self.conv1(X)))
        Y = self.bn2(self.conv2(Y))
        if self.conv3:
            X = self.conv3(X)
        Y += X
        return F.relu(Y)
b1 = nn.Sequential(nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3),
                   nn.BatchNorm2d(64), nn.ReLU(),
                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))
#num residuals是表示使用几个block组成一个Stage
def resnet_block(input_channels, num_channels, num_residuals,
                 first_block=False):
    blk = []
    for i in range(num_residuals):
        if i == 0 and not first_block:
            blk.append(Residual(input_channels, num_channels,
                                use_1x1conv=True, strides=2))
        else:
            blk.append(Residual(num_channels, num_channels))
    return blk
b2 = nn.Sequential(*resnet_block(64, 64, 2, first_block=True))
b3 = nn.Sequential(*resnet_block(64, 128, 2))
b4 = nn.Sequential(*resnet_block(128, 256, 2))
b5 = nn.Sequential(*resnet_block(256, 512, 2))
net = nn.Sequential(b1, b2, b3, b4, b5,
                    nn.AdaptiveAvgPool2d((1,1)),
                    nn.Flatten(), nn.Linear(512, 10))</code></pre>
<p>各块输出的Shape<br>Sequential output shape:     torch.Size([1, 64, 56, 56])<br>Sequential output shape:     torch.Size([1, 64, 56, 56])<br>Sequential output shape:     torch.Size([1, 128, 28, 28])<br>Sequential output shape:     torch.Size([1, 256, 14, 14])<br>Sequential output shape:     torch.Size([1, 512, 7, 7])<br>AdaptiveAvgPool2d output shape:      torch.Size([1, 512, 1, 1])<br>Flatten output shape:        torch.Size([1, 512])<br>Linear output shape:         torch.Size([1, 10])</p>
<pre><code class="python">lr, num_epochs, batch_size = 0.05, 10, 256
train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=96)
d2l.train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())</code></pre>
<h1 id="DenseNet-稠密连接网络"><a href="#DenseNet-稠密连接网络" class="headerlink" title="DenseNet 稠密连接网络"></a>DenseNet 稠密连接网络</h1><p>用更高阶的泰勒展开，每一层都加上x<br><img src="https://cdn.jsdelivr.net/gh/liting1024/PicImage/PicgoGithub/f7ac3960291949338e7370cfe6832566.png" alt="在这里插入图片描述"></p>
<h2 id="结构-1"><a href="#结构-1" class="headerlink" title="结构"></a>结构</h2><p>由 稠密块（dense block）和 过渡层 （transition layer）构成。 前者定义如何连接输入和输出，而后者则通过  1×1  的卷积层来减小通道数，并使用步幅为 2 的平均池化层减半高和宽，控制通道数量。</p>
<h2 id="torch实现-6"><a href="#torch实现-6" class="headerlink" title="torch实现"></a>torch实现</h2><pre><code class="python">import torch
from torch import nn
from d2l import torch as d2l

def conv_block(input_channels, num_channels):
    return nn.Sequential(
        nn.BatchNorm2d(input_channels), nn.ReLU(),
        nn.Conv2d(input_channels, num_channels, kernel_size=3, padding=1))
# 稠密层        
class DenseBlock(nn.Module):
    def __init__(self, num_convs, input_channels, num_channels):
        super(DenseBlock, self).__init__()
        layer = []
        for i in range(num_convs):
            layer.append(conv_block(
                num_channels * i + input_channels, num_channels))
        self.net = nn.Sequential(*layer)

    def forward(self, X):
        for blk in self.net:
            Y = blk(X)
            # 连接通道维度上每个块的输入和输出
            X = torch.cat((X, Y), dim=1)
        return X
blk = DenseBlock(2, 3, 10)
X = torch.randn(4, 3, 8, 8)
Y = blk(X)
Y.shape
# 过渡层
def transition_block(input_channels, num_channels):
    return nn.Sequential(
        nn.BatchNorm2d(input_channels), nn.ReLU(),
        nn.Conv2d(input_channels, num_channels, kernel_size=1),
        nn.AvgPool2d(kernel_size=2, stride=2))
blk = transition_block(23, 10)
blk(Y).shape
# DenseNet
b1 = nn.Sequential(
    nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3),
    nn.BatchNorm2d(64), nn.ReLU(),
    nn.MaxPool2d(kernel_size=3, stride=2, padding=1))

num_channels, growth_rate = 64, 32
num_convs_in_dense_blocks = [4, 4, 4, 4]
blks = []
for i, num_convs in enumerate(num_convs_in_dense_blocks):
    blks.append(DenseBlock(num_convs, num_channels, growth_rate))
    # 上一个稠密块的输出通道数
    num_channels += num_convs * growth_rate
    # 在稠密块之间添加一个转换层，使通道数量减半
    if i != len(num_convs_in_dense_blocks) - 1:
        blks.append(transition_block(num_channels, num_channels // 2))
        num_channels = num_channels // 2
#最后加上池化和全连接
net = nn.Sequential(
    b1, *blks,
    nn.BatchNorm2d(num_channels), nn.ReLU(),
    nn.AdaptiveMaxPool2d((1, 1)),
    nn.Flatten(),
    nn.Linear(num_channels, 10))
lr, num_epochs, batch_size = 0.1, 10, 256
train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=96)
d2l.train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu()) </code></pre>

        </div>

    </div>

    

    

    

    

    

    
<nav class="article-nav">
  
    <a href="/2021/05/28/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0Review%E3%80%90%E4%B8%89%E3%80%91%E5%BA%8F%E5%88%97%E3%80%81RNN%E3%80%81LSTM%EF%BC%88GRU%EF%BC%89%E3%80%81DRNN/" id="article-nav-newer" class="article-nav-link-wrap">
      <div class="article-nav-caption">下一篇</div>
      <div class="article-nav-title">
        
          深度学习Review【三】序列、RNN、LSTM（GRU）、DRNN
        
      </div>
    </a>
  
  
    <a href="/2021/05/27/%E5%9F%BA%E7%A1%80%E7%AE%97%E6%B3%95/" id="article-nav-older" class="article-nav-link-wrap">
      <div class="article-nav-caption">上一篇</div>
      <div class="article-nav-title">基础算法</div>
    </a>
  
</nav>


    <section class="share">
        <div class="share-title">分享</div>
        <a class="share-item" target="_blank"
            href="https://twitter.com/share?text=深度学习Review【二】LeNet、AlexNet、VGG、NiN、GoogLeNet、ResNet、DenseNet - Li Ting&url=https%3A%2F%2Fliting1024.github.io%2F2021%2F05%2F28%2F%25E6%25B7%25B1%25E5%25BA%25A6%25E5%25AD%25A6%25E4%25B9%25A0Review%25E3%2580%2590%25E4%25BA%258C%25E3%2580%2591LeNet%25E3%2580%2581AlexNet%25E3%2580%2581VGG%25E3%2580%2581NiN%25E3%2580%2581GoogLeNet%25E3%2580%2581ResNet%25E3%2580%2581DenseNet%2F">
            <box-icon type='logo' name='twitter'></box-icon>
        </a>
        <a class="share-item" target="_blank"
            href="https://service.weibo.com/share/share.php?title=深度学习Review【二】LeNet、AlexNet、VGG、NiN、GoogLeNet、ResNet、DenseNet - Li Ting&url=https://liting1024.github.io/2021/05/28/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0Review%E3%80%90%E4%BA%8C%E3%80%91LeNet%E3%80%81AlexNet%E3%80%81VGG%E3%80%81NiN%E3%80%81GoogLeNet%E3%80%81ResNet%E3%80%81DenseNet/&pic=">
            <div class="n-icon n-icon-weibo"></div>
        </a>
    </section>

</article>








<section class="comments">
    <div id="gitalk-container"></div>
</section>









<script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

</div>
                </section>
            </section>

            
            <aside class="sidebar sidebar-search-fix">
                

    <div class="search">
    <div class="has-icon-right">
        <input type="text" class="form-input" id="search" placeholder="SEARCH" autocomplete="off">
        <div class="form-icon">
            <box-icon name='search' color="#3c4859"></box-icon>
        </div>
    </div>
    <div class="search-result" id="search-ps"></div>
</div>


<div class="widget" id="widget">
    
      
  <div class="widget-wrap">
    <div class="widget-inner">
      <div class="toc post-toc-html"></div>
    </div>
  </div>

    
      
  <div class="widget-wrap widget-recent-posts">
    <div class="widget-title"><span>Recent Posts</span></div>
    <div class="widget-inner">
      <ul>
        
          <li>
            <a href="/2022/08/05/VisTransformer/">VisTransformer</a>
          </li>
        
          <li>
            <a href="/2022/07/10/Bert/">Bert</a>
          </li>
        
          <li>
            <a href="/2022/07/09/GCN/">GCN</a>
          </li>
        
          <li>
            <a href="/2022/07/09/ResNet/">ResNet</a>
          </li>
        
          <li>
            <a href="/2022/07/01/%E5%86%99%E4%BD%9C%E7%9A%84%E8%89%BA%E6%9C%AF/">研究写作的艺术</a>
          </li>
        
      </ul>
    </div>
  </div>

    
      
  <div class="widget-wrap widget-archive">
    <div class="widget-title"><span>Archive</span></div>
    <div class="widget-inner">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/">2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/">2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/">2020</a></li></ul>
    </div>
  </div>


    
      
  <div class="widget-wrap widget-tags">
    <div class="widget-title"><span>Tags</span></div>
    <div class="widget-inner">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/ACM/" rel="tag">ACM</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/C/" rel="tag">C++</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%88%AC%E8%99%AB/" rel="tag">爬虫</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%AF%BB%E8%AE%BA%E6%96%87/" rel="tag">读论文</a></li></ul>
    </div>
  </div>


    
      
  <div class="widget-wrap widget-cate">
    <div class="widget-title"><span>Categories</span></div>
    <div class="widget-inner">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Debug/">Debug</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91/">应用开发</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/">数据挖掘</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1/">程序设计</a></li></ul>
    </div>
  </div>


    
</div>

<div id="backtop"><i class="icon icon-arrow-up"></i></div>
            </aside>
            
        </div>
    </div>

    <footer class="footer">
    <div class="footer-wave">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 1440 320"><path fill="#3c4859" fill-opacity="1" d="M0,160L60,181.3C120,203,240,245,360,240C480,235,600,181,720,186.7C840,192,960,256,1080,261.3C1200,267,1320,213,1380,186.7L1440,160L1440,320L1380,320C1320,320,1200,320,1080,320C960,320,840,320,720,320C600,320,480,320,360,320C240,320,120,320,60,320L0,320Z"></path></svg>
    </div>

    <!-- Please do not remove this -->
    <!-- 开源不易，请勿删除 -->
    <div class="footer-wrap">
        <div class="footer-inner"> 
            Li Ting &copy; 2022<br>
            Powered By Hexo · Theme By <a href="https://linhong.me/" target="_blank">Aomori</a> · <a href="https://github.com/lh1me/hexo-theme-aomori" target="_blank">Github</a>
        </div>
    </div>

</footer>


<script src="https://unpkg.com/gitalk/dist/gitalk.min.js"></script>





<script src="/dist/build.js?1651727875408.js"></script>


<script src="/dist/custom.js?1651727875408.js"></script>



<!-- 百度链接提交 -->
<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        }
        else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>











</body>

</html>